{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.60943791])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 * 0.2 * np.log([0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.69314718])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * 0.5 * np.log([0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_Discrete_SAC_black_and_white_32_q1_only_skip2\n",
      "input channel size :  3\n",
      "fc input size :  384\n",
      "input channel size :  3\n",
      "fc input size :  384\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from dm_control import suite\n",
    "\n",
    "import lib_duju.utils as duju_utils\n",
    "\n",
    "from Model.ReplayBuffer import ReplayBuffer\n",
    "from Model.FrameBuffer import FrameBuffer\n",
    "from Model.SAC_base import target_initialize\n",
    "\n",
    "from Model.DiscreteConv_SAC import DiscreteConvSAC\n",
    "from Model.DiscreteConv_SAC import train_discrete_Conv_SAC_max\n",
    "\n",
    "exp_title = \"Conv_Discrete_SAC_black_and_white_32_q1_only_skip2\"\n",
    "print(exp_title)\n",
    "\n",
    "env = suite.load(domain_name=\"cartpole\",task_name=\"swingup\")\n",
    "\n",
    "action_dim = 2\n",
    "\n",
    "# state related variables\n",
    "step_size = 3\n",
    "channel_size = 1\n",
    "height = 64\n",
    "width = 96\n",
    "skip_frame = 2\n",
    "\n",
    "input_channel_size = step_size * channel_size\n",
    "\n",
    "action_dict = { 0 : -0.5,\n",
    "               1 : 0.5 }\n",
    "\n",
    "reward_compensate = 10 # inverse alpha\n",
    "\n",
    "lr = 3e-4\n",
    "gamma = 0.99\n",
    "device = torch.device(\"cuda\")\n",
    "max_episode = 10000\n",
    "batch_size = 32\n",
    "buffer_size = 1e5\n",
    "\n",
    "replay_buffer = ReplayBuffer(buffer_size)\n",
    "frame_buffer = FrameBuffer(step_size, channel_size, height, width)\n",
    "\n",
    "q_main = DiscreteConvSAC(step_size, channel_size, height, width, action_dim, lr, device)\n",
    "q_target = DiscreteConvSAC(step_size, channel_size, height, width, action_dim, lr, device)\n",
    "\n",
    "target_initialize(q_main, q_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t75.20731548963907 *** (5.032853603363037, 5.380969047546387, 0.6931347846984863)\n",
      "2\t14.890053873749038 *** (10.33411693572998, 10.352701187133789, 0.693071186542511)\n",
      "3\t46.69274459163575 *** (13.895553588867188, 12.641948699951172, 0.6931470632553101)\n",
      "4\t13.227351191526003 *** (25.65631103515625, 22.86658477783203, 0.6929023265838623)\n",
      "5\t17.574116317499463 *** (22.372453689575195, 22.603254318237305, 0.6931460499763489)\n",
      "Eval! ***  133.18635995196803\n",
      "6\t66.19552322040512 *** (35.738037109375, 36.36039352416992, 0.693117082118988)\n",
      "7\t7.692160348961531 *** (42.88447570800781, 44.9186897277832, 0.6931328773498535)\n",
      "8\t22.981758190979015 *** (39.89846420288086, 38.559234619140625, 0.693135678768158)\n",
      "9\t18.787651718502612 *** (54.22481155395508, 55.16899108886719, 0.6931429505348206)\n",
      "10\t55.217475728638235 *** (48.12155532836914, 55.574424743652344, 0.6931464076042175)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a07d857a54e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             a_category = q_main.get_max_action(\n\u001b[0;32m---> 66\u001b[0;31m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_channel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                                                   )\n\u001b[1;32m     68\u001b[0m             \u001b[0ma_deploy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_category\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/animal_ai_olympics/duju_animal_ai_olympics/Model/DiscreteConv_SAC.py\u001b[0m in \u001b[0;36mget_max_action\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_distribution_from_Qs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/animal_ai_olympics/duju_animal_ai_olympics/Model/DiscreteConv_SAC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq1_conv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq1_conv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq1_conv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cd2018-2,p3.5/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cd2018-2,p3.5/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cd2018-2,p3.5/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epi_i in range(1, max_episode + 1):\n",
    "    print(epi_i, end = \"\\t\")\n",
    "\n",
    "    timestep = env.reset()\n",
    "    ep_reward = 0.0\n",
    "\n",
    "    # timestep, reward, discount, observation\n",
    "    end, _, _, _ = timestep\n",
    "    end = end.last()\n",
    "\n",
    "    frame = env.physics.render(camera_id=0, height = height, width =width)\n",
    "    for _ in range(step_size):\n",
    "        frame_buffer.dm_add(frame)\n",
    "    s = frame_buffer.get_buffer()\n",
    "\n",
    "    while not end:\n",
    "        a_category = q_main.get_stochastic_action(\n",
    "                        torch.FloatTensor(s).to(device).view(1, input_channel_size, height, width)\n",
    "                )\n",
    "        a_deploy = action_dict[a_category]\n",
    "\n",
    "        for _ in range(skip_frame):\n",
    "            timestep = env.step(a_deploy)\n",
    "\n",
    "        end, r, _, _ = timestep\n",
    "        end = end.last()\n",
    "        frame = env.physics.render(camera_id=0, height=height, width=width)\n",
    "        frame_buffer.dm_add(frame)\n",
    "\n",
    "        s2 = frame_buffer.get_buffer()\n",
    "\n",
    "        replay_buffer.add(s, np.array([a_category]), np.array([r * reward_compensate]),np.array([end]), s2)\n",
    "\n",
    "        # frame = env.physics.render(camera_id=0, height=480, width=640)  # [height, width, channel]\n",
    "\n",
    "#         cv2.imshow(\"train\", cv2.resize(np.moveaxis(s2,[0,1,2],[2,0,1]),(width*8,height*8)))\n",
    "#         cv2.waitKey(1)\n",
    "\n",
    "        s = s2\n",
    "        ep_reward += r * skip_frame\n",
    "\n",
    "    for _idx in range(int(1000 / skip_frame)):\n",
    "        #print(_idx)\n",
    "        max_q1, max_q2, max_entropy = train_discrete_Conv_SAC_max(q_main, q_target, replay_buffer, batch_size, gamma)\n",
    "\n",
    "    print(ep_reward, \"***\", (float(max_q1), float(max_q2), float(max_entropy)))\n",
    "\n",
    "    #### Eval ####\n",
    "\n",
    "    timestep = env.reset()\n",
    "    eval_ep_reward = 0.0\n",
    "    eval_action = []\n",
    "\n",
    "    end, _, _, _ = timestep\n",
    "    end = end.last()\n",
    "\n",
    "    frame = env.physics.render(camera_id=0, height=height, width=width)\n",
    "    for _ in range(step_size):\n",
    "        frame_buffer.dm_add(frame)\n",
    "    s = frame_buffer.get_buffer()\n",
    "\n",
    "    if (epi_i % 5) == 0 :\n",
    "        while not end:\n",
    "            a_category = q_main.get_max_action(\n",
    "                        torch.FloatTensor(s).to(device).view(1, input_channel_size, height, width)\n",
    "                                                  )\n",
    "            a_deploy = action_dict[a_category]\n",
    "            eval_action.append(a_deploy)\n",
    "\n",
    "            for _ in range(skip_frame):\n",
    "                timestep = env.step(a_deploy)\n",
    "\n",
    "            end, r, _, _ = timestep\n",
    "            end = end.last()\n",
    "            frame = env.physics.render(camera_id=0, height=height, width=width)\n",
    "            frame_buffer.dm_add(frame)\n",
    "\n",
    "            s2 = frame_buffer.get_buffer()\n",
    "\n",
    "            s = s2\n",
    "            eval_ep_reward += r * skip_frame\n",
    "\n",
    "            # frame = env.physics.render(camera_id=0, height=480, width=640) #[height, width, channel]\n",
    "#             cv2.imshow(\"eval\", cv2.resize(np.moveaxis(s2,[0,1,2],[2,0,1]),(width*8,height*8)))\n",
    "#             cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        print(\"Eval! *** \", eval_ep_reward)\n",
    "        #print(eval_action)\n",
    "\n",
    "    if (epi_i % 10) == 0:\n",
    "        print(\"Networks Saved!\")\n",
    "        duju_utils.torch_network_save(q_main,\"../trained/\"+exp_title+\"_q_main_\"+str(epi_i)+\".torch\")\n",
    "        duju_utils.torch_network_save(q_target, \"../trained/\"+exp_title+\"_q_target_\"+str(epi_i)+\".torch\")\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ss, aas, rs, ts, s2s = replay_buffer.sample_batch(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.mean(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duju_utils.torch_network_load(q_main,\"trained/Conv_Discrete_SAC_black_and_white_32_q1_only_skip2_q_main_230.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict = {\n",
    "    0 : -0.5,\n",
    "    1 : 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(torch.FloatTensor(np.array([182.1922, 181.9607])),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical(F.softmax(torch.FloatTensor(np.array([182.1922, 181.9607])),dim=0)).entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "for _ in range(3):\n",
    "    t = env.physics.render(camera_id=0, height = height, width = width)\n",
    "    frame_buffer.dm_add(t)\n",
    "    k = frame_buffer.get_buffer()\n",
    "\n",
    "rc = 0.0\n",
    "for _ in range(1000):\n",
    "    t = env.physics.render(camera_id=0, height = height, width = width)\n",
    "    frame_buffer.dm_add(t)\n",
    "    k = frame_buffer.get_buffer()\n",
    "    \n",
    "    input_ = torch.FloatTensor(k.reshape([1,3,height,width])).to(device)\n",
    "\n",
    "    a1 = q_main.q1_conv1(input_)\n",
    "    aa1 = F.relu(a1)\n",
    "\n",
    "    a2 = q_main.q1_conv2(aa1)\n",
    "    aa2 = F.relu(a2)\n",
    "\n",
    "    a3 = q_main.q1_conv3(aa2)\n",
    "    aa3 = F.relu(a3)\n",
    "    \n",
    "    a4 = q_main.q1_conv4(aa3)\n",
    "    aa4 = F.relu(a4)\n",
    "\n",
    "    fc1 = aa4.view(1,-1)\n",
    "\n",
    "    f1 = q_main.q1_fc1(fc1)\n",
    "    ff1 = F.relu(f1)\n",
    "\n",
    "    f2 = q_main.q1_fc2(ff1)\n",
    "    ff2 = F.relu(f2)\n",
    "    \n",
    "    f3 = q_main.q1_fc3(ff2)\n",
    "    ff3 = f3\n",
    "\n",
    "    action = int(torch.argmax(ff3))\n",
    "    action = action_dict[action]\n",
    "    _, r, _, _ = env.step(action)\n",
    "    rc +=r\n",
    "    \n",
    "    \n",
    "    print(ff3, action)\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ = torch.FloatTensor(k.reshape([1,12,48,64])).to(device)\n",
    "\n",
    "a1 = q_main.q1_conv1(input_)\n",
    "a1\n",
    "\n",
    "aa1 = F.relu(a1)\n",
    "aa1\n",
    "\n",
    "a2 = q_main.q1_conv2(aa1)\n",
    "aa2 = F.relu(a2)\n",
    "\n",
    "a3 = q_main.q1_conv3(aa2)\n",
    "aa3 = F.relu(a3)\n",
    "\n",
    "fc1 = aa3.view(1,-1)\n",
    "\n",
    "f1 = q_main.q1_fc1(fc1)\n",
    "ff1 = F.relu(f1)\n",
    "\n",
    "f2 = q_main.q1_fc2(ff1)\n",
    "ff2 = f2\n",
    "\n",
    "action = int(torch.argmax(ff2))\n",
    "action = action_dict[action]\n",
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.array([\n",
    "    [[0,0,0]],  \n",
    "])\n",
    "test_image.shape\n",
    "\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk = kkk / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkkk = kkk[:,:,0] * 0.2989 + kkk[:,:,1] * 0.5870 + kkk[:,:,2] * 0.1140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = suite.load(domain_name=\"cartpole\",task_name=\"swingup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = env.physics.render(camera_id=0, height = 32, width = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame / 256.0\n",
    "frame = frame[:,:,[0]] * 0.2989 + frame[:,:,[1]] * 0.5870 + frame[:,:,[2]] * 0.1140\n",
    "frame = np.moveaxis(frame, [0, 1, 2], [1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame[0], cmap=plt.get_cmap('gray'), vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.random.randn(64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.moveaxis(t,[0,1,2],[1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt =  np.moveaxis(tt,[0,1,2],[2,0,1])\n",
    "ttt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(env.physics.render(camera_id=0, height=64, width=96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.resize(ttt,(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.07 ** 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
