{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segment_Tree(object):\n",
    "    def __init__(self, capacity, operation, init_value):\n",
    "        assert(capacity > 0 and capacity & (capacity-1) == 0), \"capacity must be positive and a power of 2.\"\n",
    "        \n",
    "        self.capacity = capacity\n",
    "        self.operation = operation\n",
    "        self.tree = [init_value for _ in range(2 * capacity)]\n",
    "    \n",
    "    def __setitem__(self, idx, val):\n",
    "        idx += self.capacity\n",
    "        self.tree[idx] = val\n",
    "        \n",
    "        idx //= 2\n",
    "        while idx >= 1:\n",
    "            self.tree[idx] = self.operation(self.tree[2 * idx], self.tree[2 * idx +1])\n",
    "            idx //= 2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        assert 0 <= idx < self.capacity\n",
    "        \n",
    "        return self.tree[self.capacity + idx]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree(Segment_Tree):\n",
    "    def __init__(self, capacity):\n",
    "        super(SumTree, self).__init__(capacity = capacity,\n",
    "                                     operation = operator.add,\n",
    "                                     init_value = 0.0)\n",
    "    def sum(self):\n",
    "        return self.tree[1]\n",
    "    \n",
    "    def retrieve(self, upperbound):\n",
    "        assert 0 <= upperbound <= self.sum() + 1e-5, \"upperbound: {}\".format(upperbound)\n",
    "        \n",
    "        idx = 1\n",
    "        \n",
    "        while idx < self.capacity:\n",
    "            left = 2 * idx\n",
    "            right = left + 1\n",
    "            if self.tree[left] < upperbound:\n",
    "                upperbound -= self.tree[left]\n",
    "                idx = right\n",
    "            else:\n",
    "                idx = left\n",
    "        \n",
    "        return idx - self.capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinTree(Segment_Tree):\n",
    "    def __init__(self, capacity):\n",
    "        super(MinTree, self).__init__(capacity = capacity,\n",
    "                                     operation = min,\n",
    "                                     init_value = float(\"inf\"))\n",
    "    def min(self):\n",
    "        return self.tree[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_Tree = MinTree(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    sum_Tree[i] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_Tree[4] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1 -1\n",
      "1 3 -1 7\n",
      "1 2 3 4 -1 6 7 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sum_Tree.tree[1])\n",
    "print(sum_Tree.tree[2], sum_Tree.tree[3])\n",
    "print(sum_Tree.tree[4], sum_Tree.tree[5], sum_Tree.tree[6], sum_Tree.tree[7])\n",
    "print(sum_Tree.tree[8], sum_Tree.tree[9], sum_Tree.tree[10], sum_Tree.tree[11],\n",
    "     sum_Tree.tree[12], sum_Tree.tree[13], sum_Tree.tree[14], sum_Tree.tree[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_Tree.retrieve(36.000000000001) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, state_dim, action_dim, buffer_size):  # Image state will be handled at ImageBuffer\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        self.buffer_size = buffer_size\n",
    "        self.count = 0\n",
    "        self.ptr = 0\n",
    "\n",
    "        self.s_buffer = np.zeros([buffer_size, state_dim])\n",
    "        self.a_buffer = np.zeros([buffer_size, action_dim])\n",
    "        self.r_buffer = np.zeros([buffer_size, 1])\n",
    "        self.t_buffer = np.zeros([buffer_size, 1])\n",
    "        self.s2_buffer = np.zeros([buffer_size, state_dim])\n",
    "\n",
    "    def size(self):\n",
    "        return self.count\n",
    "\n",
    "    def add(self, s, a, r, t, s2):\n",
    "        assert s.shape == (self.state_dim,)\n",
    "        assert a.shape == (self.action_dim,)\n",
    "        assert r.shape == (1,)\n",
    "        assert t.shape == (1,)\n",
    "        assert s2.shape == (self.state_dim,)\n",
    "\n",
    "        self.s_buffer[self.ptr] = s\n",
    "        self.a_buffer[self.ptr] = a\n",
    "        self.r_buffer[self.ptr] = r\n",
    "        self.t_buffer[self.ptr] = t\n",
    "        self.s2_buffer[self.ptr] = s2\n",
    "\n",
    "        self.count = min(self.count + 1, self.buffer_size)\n",
    "        self.ptr = (self.ptr + 1) % self.buffer_size\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        batch_size = min(self.count, batch_size)\n",
    "\n",
    "        sample_idx = np.random.choice(self.count, batch_size, replace=False)\n",
    "\n",
    "        return self.s_buffer[sample_idx], self.a_buffer[sample_idx], self.r_buffer[sample_idx], self.t_buffer[\n",
    "            sample_idx], self.s2_buffer[sample_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PERBuffer(ReplayBuffer):\n",
    "    def __init__(self, state_dim, action_dim, buffer_size, alpha, initial_beta):\n",
    "        super(PERBuffer, self).__init__(state_dim = state_dim,\n",
    "                                       action_dim = action_dim,\n",
    "                                       buffer_size = buffer_size)\n",
    "        \n",
    "        assert alpha > 0.0 and initial_beta > 0.0\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.initial_beta = initial_beta\n",
    "        self.beta = self.initial_beta\n",
    "        \n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.buffer_size:\n",
    "            tree_capacity *= 2\n",
    "        \n",
    "        self.sumTree = SumTree(tree_capacity)\n",
    "        self.minTree = MinTree(tree_capacity)\n",
    "        \n",
    "        self.tree_ptr = 0\n",
    "        \n",
    "        self.max_priority = 1.0 # This is containg alpha inside\n",
    "    \n",
    "    def store(self, s, a, r, t, s2):\n",
    "        self.add(s, a, r, t, s2)\n",
    "        self.sumTree[self.tree_ptr] = self.max_priority\n",
    "        self.minTree[self.tree_ptr] = self.max_priority\n",
    "        self.tree_ptr = (self.tree_ptr + 1) % self.buffer_size\n",
    "        \n",
    "    def update_beta(self, current_step, final_step):\n",
    "        self.beta = self.initial_beta + (1 - self.initial_beta) * current_step / final_step\n",
    "    \n",
    "    def sample_batch(self, batch_size):\n",
    "        \n",
    "        assert self.count >= batch_size\n",
    "        \n",
    "        indices = self._sample_proportional(batch_size)\n",
    "        \n",
    "        s = self.s_buffer[indices]\n",
    "        a = self.a_buffer[indices]\n",
    "        r = self.r_buffer[indices]\n",
    "        t = self.t_buffer[indices]\n",
    "        s2 = self.t_buffer[indices]\n",
    "        weights = self._calculate_weights(indices)\n",
    "        \n",
    "        return s, a, r, t, s2, indices, weights\n",
    "    \n",
    "    def update_priorities(self, indices, td_errors):\n",
    "        assert len(indices) == len(td_errors)\n",
    "        \n",
    "        for idx, td in zip(indices, td_errors):\n",
    "            self.sumTree[idx] = td ** self.alpha\n",
    "            self.minTree[idx] = td ** self.alpha\n",
    "            \n",
    "        self.max_priority = max(self.max_priority, max(td_errors) ** self.alpha)\n",
    "        \n",
    "    \n",
    "    def _sample_proportional(self, batch_size):\n",
    "        \n",
    "        indices = []\n",
    "        p_sum = self.sumTree.sum()\n",
    "        upper_bounds = np.random.uniform(0.0, p_sum, batch_size)\n",
    "        \n",
    "        for ub in upper_bounds:\n",
    "            indices.append(self.sumTree.retrieve(ub))\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weights(self, indices):\n",
    "        \n",
    "        tree_min = self.minTree.min()\n",
    "        \n",
    "        weights = (tree_min / np.array([self.sumTree[idx] for idx in indices])) ** self.beta\n",
    "        \n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dim, action_dim, buffer_size, alpha, initial_beta\n",
    "per_buffer = PERBuffer(1,1,10,0.6,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,15):\n",
    "    per_buffer.store(np.array([i]),\n",
    "                np.array([i]),\n",
    "                np.array([i]),\n",
    "                np.array([True]),\n",
    "                np.array([i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s, a, r, t, s2, indices, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6.],\n",
       "        [13.],\n",
       "        [10.]]), array([[ 6.],\n",
       "        [13.],\n",
       "        [10.]]), array([[ 6.],\n",
       "        [13.],\n",
       "        [10.]]), array([[1.],\n",
       "        [1.],\n",
       "        [1.]]), array([[1.],\n",
       "        [1.],\n",
       "        [1.]]), [5, 2, 9], array([1., 1., 1.]))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_buffer.sample_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    per_buffer.update_priorities(np.array([i]),np.array([0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for _ in range(10000):\n",
    "    test.append(per_buffer.sample_batch(1)[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 980.,  991.,  962.,  996.,  979., 1013.,  968., 1041., 1023.,\n",
       "        1047.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones([32,16])\n",
    "b = torch.ones([32]) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 16]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a+b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-299-c97af47a22e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "torch.cat(3*[b],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.28938734e+26, 4.97940813e+27, 5.23016412e+27, 5.20305425e+27,\n",
       "       1.25231764e+27, 4.68537644e+26, 1.23273485e+27, 5.52694996e+27,\n",
       "       4.41570836e+27, 6.03753229e+27, 3.87496797e+27, 2.20851531e+27,\n",
       "       6.54063301e+27, 6.77659646e+27, 2.64310056e+27, 7.01665700e+27,\n",
       "       2.04060385e+27, 7.43301794e+27, 4.06269728e+27, 9.89606054e+27,\n",
       "       8.74050496e+26, 8.35316936e+27, 6.97779274e+27, 5.03456040e+27,\n",
       "       7.23683857e+27, 3.71732011e+27, 7.03077271e+27, 3.20419826e+27,\n",
       "       3.32817414e+27, 4.60575851e+26, 4.04951439e+26, 7.84851987e+27])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(0.0, 100000000, 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
