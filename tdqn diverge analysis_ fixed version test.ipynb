{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_Discrete_TDQN_celu_larger networks\n",
      "reward_compensate 1\n",
      "skip_frame 4\n",
      "input channel size :  3\n",
      "fc input size :  1536\n",
      "input channel size :  3\n",
      "fc input size :  1536\n",
      "Triple_DQN(\n",
      "  (q1_conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (q1_conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (q1_conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (q1_conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (q1_fc1): Linear(in_features=1536, out_features=256, bias=True)\n",
      "  (q1_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (q1_fc3): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (q2_conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (q2_conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (q2_conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (q2_conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (q2_fc1): Linear(in_features=1536, out_features=256, bias=True)\n",
      "  (q2_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (q2_fc3): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from dm_control import suite\n",
    "\n",
    "import lib_duju.utils as duju_utils\n",
    "\n",
    "from Model.ReplayBuffer import ReplayBuffer\n",
    "from Model.ImageBuffer import ImageBuffer\n",
    "from Model.SAC_base import target_initialize\n",
    "\n",
    "from Model.triple_dqn import Triple_DQN\n",
    "from Model.triple_dqn import train_triple_dqn\n",
    "\n",
    "exp_title = \"Conv_Discrete_TDQN_celu_larger networks\"\n",
    "print(exp_title)\n",
    "\n",
    "train_print_flag = False\n",
    "eval_print_flag = False\n",
    "\n",
    "load_flag = False\n",
    "\n",
    "env = suite.load(domain_name=\"cartpole\",task_name=\"swingup\")\n",
    "\n",
    "action_dim = 3\n",
    "\n",
    "# state related variables\n",
    "step_size = 3\n",
    "channel_size = 1\n",
    "height = 48\n",
    "width = 64\n",
    "skip_frame = 4\n",
    "\n",
    "input_channel_size = step_size * channel_size\n",
    "\n",
    "rb_state_dim = 1\n",
    "rb_action_dim = 1\n",
    "\n",
    "action_dict = { 0 : -1.0,\n",
    "                1 : 1.0,\n",
    "                2 : 0.0}\n",
    "\n",
    "reward_compensate = 1\n",
    "\n",
    "print(\"reward_compensate\", reward_compensate)\n",
    "print(\"skip_frame\", skip_frame)\n",
    "\n",
    "lr = 1e-3\n",
    "gamma = 0.99\n",
    "device = torch.device(\"cuda\")\n",
    "max_episode = 10000\n",
    "batch_size = 32\n",
    "buffer_size = int(5e5)\n",
    "\n",
    "replay_buffer = ReplayBuffer(rb_state_dim, rb_action_dim, buffer_size)\n",
    "image_buffer = ImageBuffer(height, width, step_size, channel_size, int(buffer_size * 1.1))\n",
    "eval_image_buffer = ImageBuffer(height, width, step_size, channel_size, 2000)\n",
    "\n",
    "q_main = Triple_DQN(step_size, channel_size, height, width, action_dim, lr, device)\n",
    "q_target = Triple_DQN(step_size, channel_size, height, width, action_dim, lr, device)\n",
    "\n",
    "target_initialize(q_main, q_target)\n",
    "\n",
    "print(q_main)\n",
    "\n",
    "if load_flag:\n",
    "    duju_utils.torch_network_load(q_main, \"../trained/Conv_Discrete_TDQN_celu_larger networks_q_main_250.torch\")\n",
    "    duju_utils.torch_network_load(q_target, \"../trained/Conv_Discrete_TDQN_celu_larger networks_q_target_250.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_main.optimizer.state_dict()[\"param_groups\"][0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "duju_utils.torch_network_load(q_main,\"trained/Conv_Discrete_TDQN_celu_larger networks_q_main_375.torch\")\n",
    "duju_utils.torch_network_load(q_target,\"trained/Conv_Discrete_TDQN_celu_larger networks_q_target_375.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t556 *** (524.4137573242188, -319.7030029296875, 1050.72705078125, 516.1741943359375, 5.585254669189453)\n",
      "2\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-160aae020dbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                           np.array([s2_idx])    )\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [height, width, channel]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_print_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cd2018-2,p3.5/lib/python3.5/site-packages/dm_control/mujoco/engine.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, height, width, camera_id, overlays, depth, segmentation, scene_option)\u001b[0m\n\u001b[1;32m    172\u001b[0m     image = camera.render(\n\u001b[1;32m    173\u001b[0m         \u001b[0moverlays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverlays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         scene_option=scene_option)\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cd2018-2,p3.5/lib/python3.5/site-packages/dm_control/mujoco/engine.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, overlays, depth, segmentation, scene_option)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;31m# Render scene and text overlays, read contents of RGB or depth buffer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_physics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_on_gl_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverlays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cd2018-2,p3.5/lib/python3.5/site-packages/dm_control/_render/executor/render_executor.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleanup_callable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cd2018-2,p3.5/lib/python3.5/site-packages/dm_control/mujoco/engine.py\u001b[0m in \u001b[0;36m_render_on_gl_thread\u001b[0;34m(self, depth, overlays)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth_buffer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         self._physics.contexts.mujoco.ptr)\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m   def render(self, overlays=(), depth=False, segmentation=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epi_i in range(1, max_episode + 1):\n",
    "    print(epi_i, end = \"\\t\")\n",
    "\n",
    "    timestep = env.reset()\n",
    "    ep_reward = 0.0\n",
    "\n",
    "    # timestep, reward, discount, observation\n",
    "    end, _, _, _ = timestep\n",
    "    end = end.last()\n",
    "\n",
    "    frame = env.physics.render(camera_id=0, height = height, width =width)\n",
    "    for _ in range(step_size):\n",
    "        image_buffer.dm_add_gray(frame)\n",
    "    s_idx = image_buffer.get_current_index()\n",
    "    s_frame = image_buffer.get_state(s_idx)\n",
    "\n",
    "    pseudo_sigma = np.maximum(1- epi_i/100.0, 0.1)\n",
    "    epsilon = np.random.sample() * 0.1 # mean 0.05 min 0.0 max 0.1\n",
    "\n",
    "    while not end:\n",
    "        a_category = q_main.epsilon_sample(\n",
    "                        torch.FloatTensor(s_frame).to(device).view(1, input_channel_size, height, width),\n",
    "                        epsilon\n",
    "                )\n",
    "        a_deploy = action_dict[a_category]\n",
    "\n",
    "        for _ in range(skip_frame):\n",
    "            timestep = env.step(a_deploy)\n",
    "\n",
    "        end, r, _, _ = timestep\n",
    "        end = end.last()\n",
    "        frame = env.physics.render(camera_id=0, height=height, width=width)\n",
    "        image_buffer.dm_add_gray(frame)\n",
    "\n",
    "        s2_idx = image_buffer.get_current_index()\n",
    "        s2_frame = image_buffer.get_state(s2_idx)\n",
    "\n",
    "        replay_buffer.add(  np.array([s_idx]),\n",
    "                          np.array([a_category]),\n",
    "                          np.array([r * reward_compensate]),\n",
    "                          np.array([end]),\n",
    "                          np.array([s2_idx])    )\n",
    "\n",
    "        frame = env.physics.render(camera_id=0, height=480, width=640)  # [height, width, channel]\n",
    "\n",
    "        if train_print_flag:\n",
    "            #cv2.imshow(\"train\", cv2.resize(np.moveaxis(s2_frame,[0,1,2],[2,0,1]),(width*4,height*4)))\n",
    "            cv2.imshow(\"train\", frame)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "        s_idx = s2_idx\n",
    "        s_frame = s2_frame\n",
    "\n",
    "        ep_reward += r * skip_frame\n",
    "\n",
    "    for _idx in range(int(1000)):\n",
    "        #print(_idx)\n",
    "            mean_q1, max_q1, min_q1, mean_q2, mean_reward = train_triple_dqn(q_main, q_target, replay_buffer, image_buffer, batch_size, gamma)\n",
    "\n",
    "    print(int(ep_reward), \"***\", (float(mean_q1), float(max_q1), float(min_q1), float(mean_q2), float(mean_reward)))\n",
    "\n",
    "    #### Eval ####\n",
    "\n",
    "    timestep = env.reset()\n",
    "    eval_ep_reward = 0.0\n",
    "    eval_action = []\n",
    "\n",
    "    end, _, _, _ = timestep\n",
    "    end = end.last()\n",
    "\n",
    "    frame = env.physics.render(camera_id=0, height=height, width=width)\n",
    "    for _ in range(step_size):\n",
    "        eval_image_buffer.dm_add_gray(frame)\n",
    "    s_idx = eval_image_buffer.get_current_index()\n",
    "    s_frame = eval_image_buffer.get_state(s_idx)\n",
    "\n",
    "    if (epi_i % 25) == 0 :\n",
    "        while not end:\n",
    "            a_category = q_main.epsilon_sample(\n",
    "                        torch.FloatTensor(s_frame).to(device).view(1, input_channel_size, height, width),\n",
    "                        0.0\n",
    "                                                  )\n",
    "            a_deploy = action_dict[a_category]\n",
    "            eval_action.append(a_deploy)\n",
    "\n",
    "            for _ in range(skip_frame):\n",
    "                timestep = env.step(a_deploy)\n",
    "\n",
    "            end, r, _, _ = timestep\n",
    "            end = end.last()\n",
    "            frame = env.physics.render(camera_id=0, height=height, width=width)\n",
    "            eval_image_buffer.dm_add_gray(frame)\n",
    "\n",
    "            s2_idx = eval_image_buffer.get_current_index()\n",
    "            s2_frame = eval_image_buffer.get_state(s2_idx)\n",
    "\n",
    "            s_idx = s2_idx\n",
    "            s_frame = s2_frame\n",
    "\n",
    "            eval_ep_reward += r * skip_frame\n",
    "\n",
    "            # frame = env.physics.render(camera_id=0, height=480, width=640) #[height, width, channel]\n",
    "            if eval_print_flag:\n",
    "                cv2.imshow(\"eval\", cv2.resize(np.moveaxis(s2_frame,[0,1,2],[2,0,1]),(width*8,height*8)))\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        print(\"Eval! *** \", eval_ep_reward)\n",
    "        #print(eval_action)\n",
    "\n",
    "    if (epi_i % 25) == 0:\n",
    "        print(\"Networks Saved!\")\n",
    "        duju_utils.torch_network_save(q_main,\"../trained/\"+exp_title+\"_q_main_\"+str(epi_i)+\".torch\")\n",
    "        duju_utils.torch_network_save(q_target, \"../trained/\"+exp_title+\"_q_target_\"+str(epi_i)+\".torch\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f59880797b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = image_buffer.get_state(450)\n",
    "\n",
    "plt.imshow(np.moveaxis(f,[0,1,2],[2,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = []\n",
    "for i in range(100,500):\n",
    "    fs.append(image_buffer.get_state(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[123.5664, 122.9472, 118.7792]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[127.4890, 127.4222, 123.6236]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[127.8568, 125.6638, 123.5442]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[133.3371, 133.3248, 129.3734]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[134.4424, 134.0248, 129.3910]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[144.0959, 144.5748, 139.2695]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[148.0049, 147.7655, 143.0349]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[150.5099, 148.3111, 144.9536]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[142.6510, 138.8964, 136.2307]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[137.5677, 135.2110, 131.6022]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[141.3046, 139.9668, 136.2239]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[139.3691, 137.0422, 134.1308]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[161.4971, 159.5983, 157.1442]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[177.8238, 178.4309, 175.4050]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[177.1945, 175.5806, 173.5679]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[170.3887, 169.3094, 166.6106]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[179.6859, 181.3846, 177.5109]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[182.9399, 184.3839, 181.9197]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[193.4673, 197.0697, 195.0924]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[216.3064, 217.9841, 218.5893]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[232.0459, 233.0845, 233.4388]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[246.0835, 246.5581, 248.3358]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[275.8823, 276.8241, 277.5891]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[305.4994, 305.2636, 306.0723]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[331.3802, 329.8061, 331.5045]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[354.2864, 351.9902, 354.7849]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[375.4909, 374.2372, 378.0196]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[382.2709, 385.1521, 390.3073]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[375.5882, 374.9407, 383.0836]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[366.6262, 365.4255, 373.7223]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[358.5876, 354.0345, 365.4694]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[368.3361, 365.5120, 376.0833]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[382.0301, 382.0009, 392.1482]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[382.0493, 378.8798, 391.0226]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[376.5319, 381.6091, 389.5039]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[370.7038, 379.1340, 384.4041]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[384.9500, 389.5088, 396.3939]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[380.7917, 387.5845, 392.8974]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[388.8236, 393.3795, 398.4887]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[390.1832, 398.6481, 402.4011]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[396.2319, 405.8011, 409.0544]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[402.3230, 409.4483, 415.9596]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[410.5899, 420.6760, 424.8691]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[403.9743, 413.8042, 419.9190]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[413.6246, 423.3496, 429.5065]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[411.1028, 419.2566, 425.9187]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[411.5573, 418.3801, 425.2140]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[417.9761, 421.1356, 431.1654]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[417.3342, 423.1196, 431.5441]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[405.7526, 413.6263, 420.9714]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[390.9466, 399.9179, 407.0234]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[379.0420, 383.1958, 391.4820]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[349.3207, 356.6618, 360.4891]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[353.2605, 365.8540, 364.7658]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[370.6053, 379.3571, 380.6685]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[383.8750, 391.4529, 394.2755]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[419.1490, 426.5834, 427.8143]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[443.8093, 454.2188, 452.5748]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[468.4236, 481.2133, 479.7689]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[496.5302, 509.5912, 508.2840]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[529.4306, 542.0974, 541.4075]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[543.5718, 556.4806, 554.1530]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[534.0385, 546.8687, 544.1161]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[530.5593, 540.8023, 539.8539]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[508.2280, 515.0054, 516.3574]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[506.9876, 514.2897, 514.8113]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[503.4851, 509.5004, 510.6040]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[505.8344, 508.0702, 510.4052]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[507.1502, 512.5881, 512.7211]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[497.5302, 503.3981, 502.9654]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[491.3465, 502.6862, 499.5961]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[482.9178, 489.4718, 489.7848]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[483.9236, 495.8873, 494.0397]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[470.9077, 482.4691, 480.3308]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[471.0019, 474.0967, 476.7507]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[471.9222, 467.0283, 473.9576]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[473.6216, 472.6678, 474.9583]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[468.6336, 466.0805, 469.6786]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[467.0924, 470.0379, 469.6889]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[457.5591, 463.3929, 458.3956]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[475.1825, 477.8311, 474.2997]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[475.4636, 471.6573, 469.8277]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[482.8027, 476.7412, 474.3503]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[484.2081, 486.0569, 477.9311]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[494.3736, 486.3320, 482.6596]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[500.8595, 487.6555, 487.3468]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[512.1911, 505.8318, 501.5845]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[511.9955, 505.9211, 501.0357]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[507.1063, 497.1713, 494.8273]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[511.3238, 503.7755, 500.7613]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[524.3690, 520.7189, 515.2259]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[516.1652, 511.3592, 506.8168]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[523.1912, 521.5643, 515.9784]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[530.4563, 519.9340, 520.5323]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[525.4241, 513.8251, 515.8321]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[547.1420, 533.9114, 537.1289]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[554.8701, 541.6448, 544.7620]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[555.1157, 546.9696, 547.1538]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[552.3079, 548.4174, 547.6913]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[553.5328, 552.4678, 550.4005]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[545.4507, 539.0132, 539.2540]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[545.4891, 548.1158, 545.5802]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[542.6373, 546.5308, 542.1886]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[539.0255, 535.8256, 537.1138]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[526.1158, 523.8972, 526.4244]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[522.8962, 528.4768, 526.5081]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[496.7965, 494.1163, 498.1265]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[492.3839, 496.5850, 497.4073]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[481.7507, 479.7515, 485.4980]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[458.1104, 453.1554, 461.8636]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[441.6666, 448.8504, 450.2648]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[420.5386, 424.0362, 427.6741]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[398.0170, 405.2836, 406.7802]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[377.1375, 377.9246, 382.9565]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[352.2195, 345.4629, 355.8035]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[325.1718, 335.1894, 334.4509]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[307.2461, 313.9815, 315.0760]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[306.7479, 302.7441, 310.4832]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[275.7915, 298.9282, 286.1936]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[280.7869, 300.0821, 290.1551]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[268.6744, 284.3703, 277.8212]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[252.7569, 275.8467, 264.6649]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[268.0185, 287.4604, 279.6136]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[260.7500, 274.2032, 270.2883]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[262.7118, 275.5655, 271.9673]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[267.5030, 275.8533, 275.8612]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[274.3104, 281.8387, 282.7893]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[252.5745, 261.8690, 261.2977]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[240.3765, 247.5536, 249.1712]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[227.8703, 237.2451, 237.3700]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[215.8744, 219.1779, 225.5003]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[197.3148, 198.7668, 204.8504]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[166.4977, 171.3195, 175.7363]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[138.4401, 141.1805, 146.2208]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[111.4778, 116.9904, 119.5120]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[80.1539, 85.7069, 87.9082]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[56.0561, 60.0502, 62.2420]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[23.1959, 27.5364, 27.5383]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-11.6648,  -6.9171,  -8.0043]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-23.7375, -18.4234, -19.6604]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-49.0381, -42.1809, -45.0581]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-68.9413, -65.4911, -68.2262]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-76.8035, -73.5246, -76.5724]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-71.6396, -68.6159, -71.4316]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-77.4371, -75.0378, -77.8752]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-54.0046, -51.7578, -54.0098]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-46.8504, -42.4676, -45.6110]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-42.5117, -41.0146, -42.5389]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-44.0334, -41.5201, -43.0991]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-37.1077, -35.3575, -35.5348]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-33.9505, -34.3386, -33.2377]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-23.4846, -23.3714, -21.7527]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-8.5423, -9.8419, -7.3721]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-5.3592, -6.0216, -3.9623]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-12.9137, -13.3367, -11.7365]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[7.3385, 7.9937, 9.7469]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[14.4974, 14.0690, 16.3261]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[5.3232, 3.5932, 6.5104]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[13.2507, 11.7228, 15.2402]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[19.0043, 18.8142, 21.4903]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[25.7011, 26.1398, 28.6407]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[21.8382, 20.7249, 23.6999]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[15.9154, 14.9598, 18.2638]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[12.2467, 10.2252, 13.6611]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[17.3334, 15.7922, 19.6827]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[12.6061,  9.6770, 13.8829]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.9294, -3.7772,  0.4806]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-4.2416, -7.1209, -3.0166]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-19.2687, -23.0281, -18.8658]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-26.9757, -29.8255, -26.1728]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-18.0177, -21.3921, -17.1333]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[ -6.9303, -10.1992,  -5.6180]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-31.0720, -32.8765, -29.1269]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-43.3080, -43.7756, -41.1702]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-45.6596, -44.8177, -43.4503]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-43.4980, -41.5504, -41.1649]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-47.2443, -43.7312, -45.7015]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-42.8618, -38.2849, -41.7442]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-53.8851, -48.9951, -52.7775]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-62.6113, -56.1301, -61.4836]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-58.6666, -51.3975, -57.4007]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-67.4321, -59.3617, -65.9678]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-53.2615, -46.1638, -52.7613]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-64.8088, -57.1435, -64.2005]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-66.3183, -59.0012, -65.3656]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-60.4147, -53.5640, -59.4336]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-67.6540, -59.8975, -65.8317]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-64.9071, -57.5554, -63.2579]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-67.8283, -60.1338, -65.9613]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-73.2587, -65.9964, -70.9633]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-75.6043, -68.5652, -73.5451]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-82.0347, -75.3703, -80.0089]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-90.9447, -85.3903, -89.2841]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-96.4244, -89.5807, -93.2603]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-103.4086,  -97.8967, -102.3856]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-109.0658, -101.9637, -106.6773]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-119.3502, -111.1427, -116.6093]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-127.8086, -118.9934, -125.6948]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-126.8764, -117.4327, -123.5216]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-129.8752, -119.8358, -126.4543]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-128.5084, -119.4636, -124.6895]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-121.8781, -113.3787, -117.7054]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-122.0817, -113.4523, -118.1455]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-118.8340, -110.8481, -115.7418]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-124.0430, -115.8547, -121.2353]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-129.0160, -120.8538, -126.1814]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-135.1062, -126.9885, -132.5270]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-141.5408, -133.8304, -139.6278]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-135.6107, -129.5909, -134.2611]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-143.5313, -138.0325, -142.5930]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-147.1481, -141.3802, -146.3550]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-147.5866, -141.7208, -146.3575]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-154.2198, -147.5401, -152.4845]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-151.7100, -144.2157, -148.9868]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-157.0367, -150.9241, -155.4801]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-160.5530, -154.2183, -157.9880]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-167.3496, -161.1723, -162.6387]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-178.1952, -172.2982, -173.5639]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-176.0800, -170.2098, -172.1012]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-177.1906, -172.8095, -174.1057]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-180.0564, -175.2235, -176.1370]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-178.5910, -173.2646, -175.0672]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-189.3487, -184.1028, -186.3901]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-201.1008, -196.7735, -199.7440]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-204.7888, -200.4483, -204.2569]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-203.3422, -200.0375, -204.0491]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-212.1232, -211.3788, -214.3668]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-236.8523, -234.3769, -241.0161]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-258.2870, -260.3944, -267.0294]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-279.1442, -278.6951, -285.9956]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-279.7396, -277.1966, -285.1512]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-297.6152, -294.4633, -303.4493]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-295.3773, -290.9594, -302.8742]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-285.6714, -281.5542, -292.6804]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-275.9588, -272.3427, -282.8149]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-282.5651, -280.5604, -289.9988]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-291.4443, -290.6726, -299.1625]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-295.8199, -293.1810, -300.5718]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-298.7707, -297.7132, -304.6461]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-297.1942, -297.0758, -304.2556]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-294.7030, -294.4806, -301.3466]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-293.1066, -292.3042, -299.2019]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-281.2736, -279.6651, -287.7944]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-276.1952, -273.0011, -282.0756]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-282.3040, -281.1515, -288.2344]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-284.0705, -282.0058, -289.5673]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-284.5220, -285.0345, -292.8324]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-287.9790, -289.8876, -296.9021]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-283.2552, -284.5195, -290.4049]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-287.8306, -287.8837, -293.7575]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-295.1635, -296.4124, -302.1495]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-297.5092, -299.8161, -305.8327]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-299.6271, -303.2180, -309.4883]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-302.2428, -307.0749, -313.1265]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-303.3867, -308.8239, -314.7254]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-302.7859, -308.0016, -312.9807]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-307.8059, -312.4496, -317.9665]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-303.8161, -309.4984, -315.0623]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-306.1227, -312.4794, -318.6636]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-293.9218, -299.0857, -307.1718]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-283.5564, -286.7275, -296.5531]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-292.0401, -293.5569, -305.9335]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-294.8044, -293.0657, -307.0376]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-282.4033, -284.5713, -296.2184]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-297.8770, -299.3954, -310.4612]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-298.4078, -300.1859, -310.0511]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-296.2325, -298.7803, -307.4121]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-296.5914, -300.9287, -308.3329]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-300.0619, -305.6394, -312.3919]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-311.1331, -317.2181, -323.1916]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-303.7927, -311.6570, -315.0421]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-306.6339, -315.5436, -317.9329]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-305.4133, -314.5666, -316.9419]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-305.0902, -314.8409, -317.9169]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-290.6973, -300.3116, -304.2090]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-285.5237, -294.1409, -298.4495]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-284.7273, -293.6443, -297.6324]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-269.4358, -277.7606, -281.8411]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-257.3167, -264.1486, -268.9146]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-246.6352, -253.1059, -258.0003]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-234.3871, -239.9447, -244.6142]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-222.3088, -226.1770, -230.4135]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-209.3504, -212.1577, -216.3644]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-205.3063, -207.7800, -211.7708]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-191.4869, -193.3561, -196.7068]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-191.1429, -193.3266, -195.9814]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-178.0197, -179.3021, -181.3339]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-158.5190, -159.6352, -161.2840]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-149.9262, -151.5655, -152.6190]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-148.6343, -150.2122, -151.1293]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-161.4793, -162.8683, -164.5499]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-150.3991, -151.6059, -153.1741]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-128.8535, -129.4149, -130.4067]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-125.3672, -125.3553, -126.4581]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-121.8532, -122.4508, -123.0998]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-113.8004, -114.3088, -114.6694]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-113.2619, -113.1459, -113.8773]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-106.4196, -107.3369, -107.8783]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-105.3134, -106.6418, -106.8376]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-100.5200, -100.6174, -102.2736]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-79.4414, -78.6565, -78.7010]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-72.4240, -71.0444, -70.9763]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-71.5592, -68.5641, -69.9400]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-61.5323, -57.5733, -58.6266]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-74.1020, -70.7212, -72.3708]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-85.5054, -80.4969, -84.1754]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-102.0502,  -97.2426, -101.7343]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-102.1193,  -96.8726, -101.6651]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-125.8423, -122.3477, -127.0000]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-107.3221, -102.8791, -106.7306]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-139.9180, -137.9238, -141.7782]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-165.9693, -165.6524, -170.1490]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-188.6685, -187.0218, -192.9729]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-208.9844, -208.7482, -215.3170]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-227.4285, -229.0858, -236.1924]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-234.0544, -236.9789, -244.1210]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-229.3702, -232.0474, -239.7495]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-231.0708, -233.7837, -241.1448]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-231.5605, -233.6614, -240.6115]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-224.6563, -226.9847, -233.2759]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-229.6197, -230.7344, -236.7707]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-214.3454, -215.1030, -220.4264]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-192.9927, -188.6095, -192.0009]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-150.3840, -143.7512, -146.5076]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-125.9483, -116.7556, -121.9931]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-88.2751, -76.6503, -83.1481]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-58.6998, -40.3880, -49.1578]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-17.0752,  -3.0111, -10.0483]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[15.7823, 21.3303, 18.7543]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[22.5251, 21.3485, 21.4270]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[34.5538, 34.6626, 33.8225]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[67.7675, 70.0521, 66.3468]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[89.5654, 93.3407, 88.5297]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[90.4656, 93.5439, 89.3375]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[96.7928, 98.3923, 94.7864]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[106.7605, 105.8878, 102.8649]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[116.2875, 112.3085, 110.3129]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[127.1584, 126.0603, 122.2825]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[138.9367, 133.4391, 130.6921]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[132.0519, 133.0316, 127.3928]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[134.8854, 133.0016, 128.6989]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[137.4705, 133.0462, 130.2122]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[143.3094, 142.2133, 138.6063]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[144.9689, 140.5724, 138.4816]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[146.3466, 141.2739, 139.4088]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[151.6285, 149.0849, 145.8522]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[160.8703, 158.2885, 154.2539]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[160.1032, 157.0970, 154.0514]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[147.5163, 143.2823, 141.7023]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[140.2037, 138.0983, 135.5976]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[142.0465, 138.8702, 136.8769]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[152.6061, 148.4808, 146.9958]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[164.5799, 161.0447, 160.0638]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[163.1928, 161.2377, 159.5009]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[170.4060, 168.2016, 166.5574]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[164.6949, 163.6375, 161.9778]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[163.5049, 162.7626, 160.8934]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[161.0347, 158.1490, 158.3525]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[169.3778, 166.6610, 166.8974]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[178.4642, 174.5207, 175.5315]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[201.9670, 198.5769, 200.4218]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[225.0011, 222.1131, 224.0123]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[259.3093, 257.0798, 258.1829]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[275.7387, 278.0408, 277.1125]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[290.1281, 296.2421, 295.1129]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[299.2663, 308.0892, 306.2137]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[310.6918, 317.6229, 316.6070]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[311.8069, 318.4837, 322.3371]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[297.5839, 296.8622, 304.0251]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[299.4630, 297.1530, 305.7967]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[307.3244, 304.2733, 312.8451]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[299.8405, 295.9954, 305.0901]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[300.8857, 297.6349, 305.9570]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[280.8990, 277.7939, 284.3543]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[282.3346, 279.4790, 286.1907]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[288.6101, 288.1260, 293.3604]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[293.8572, 292.5007, 297.5549]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[287.4999, 285.8331, 292.0141]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[289.9194, 291.6155, 296.7160]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[274.2725, 273.8215, 278.9596]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[282.7740, 284.1606, 288.7405]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[308.3224, 319.1657, 318.8301]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[322.1306, 335.9682, 333.8409]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[331.3492, 340.6782, 342.2789]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[331.7965, 335.5311, 339.3358]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[326.0458, 331.2360, 334.5253]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[311.3663, 319.2672, 320.9099]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[292.4269, 301.9578, 301.7097]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[282.4355, 291.8023, 291.8732]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[257.4458, 266.5298, 264.8595]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[239.0728, 250.2089, 244.2327]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[258.1165, 271.6803, 265.9411]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[261.8217, 275.3528, 266.7540]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[282.6113, 296.4197, 290.2210]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[282.9710, 292.2415, 292.1757]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[296.9901, 312.4420, 306.3293]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[318.7521, 334.5201, 329.5095]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[386.4594, 403.6403, 395.8727]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[443.3366, 456.0257, 452.5654]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[491.1464, 502.7599, 502.4626]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3s = []\n",
    "for f in fs:\n",
    "    c1 = q_main.q1_conv1(torch.FloatTensor(f).view([-1,3,64,96]).to(device))\n",
    "    cc1 = torch.celu(c1)\n",
    "\n",
    "    c2 = q_main.q1_conv2(cc1)\n",
    "    cc2 = torch.celu(c2)\n",
    "\n",
    "    c3 = q_main.q1_conv3(cc2)\n",
    "    cc3 = torch.celu(c3)\n",
    "    \n",
    "    c4 = q_main.q1_conv4(cc3)\n",
    "    cc4 = torch.celu(c4)\n",
    "    \n",
    "    c5 = q_main.q1_conv5(cc4)\n",
    "    cc5 = torch.celu(c5)\n",
    "\n",
    "    i0 = cc5.view([1,-1])\n",
    "\n",
    "    f1 = q_main.q1_fc1(i0)\n",
    "    ff1 = torch.celu(f1)\n",
    "\n",
    "    f2 = q_main.q1_fc2(ff1)\n",
    "    ff2 = torch.celu(f2)\n",
    "    \n",
    "    f3 = q_main.q1_fc3(ff2)\n",
    "    f3s.append(f3)\n",
    "    \n",
    "f3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.8682, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(q_main.q1_fc2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = q_main.q1_conv1(torch.FloatTensor(f).view([-1,3,64,96]).to(device))\n",
    "cc1 = torch.celu(c1)\n",
    "\n",
    "c2 = q_main.q1_conv2(cc1)\n",
    "cc2 = torch.celu(c2)\n",
    "\n",
    "c3 = q_main.q1_conv3(cc2)\n",
    "cc3 = torch.celu(c3)\n",
    "\n",
    "i0 = cc3.view([1,-1])\n",
    "\n",
    "f1 = q_main.q1_fc1(i0)\n",
    "ff1 = torch.celu(f1)\n",
    "\n",
    "f2 = q_main.q1_fc2(ff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(ff1 > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in cc3[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in i0.detach().cpu().numpy()[0]:\n",
    "    print(i, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
