{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from dm_control import suite\n",
    "\n",
    "import lib_duju.utils as duju_utils\n",
    "\n",
    "from Model.ReplayBuffer import ReplayBuffer\n",
    "from Model.SAC_base import target_initialize\n",
    "\n",
    "from Model.Discrete_SAC import DiscreteSAC\n",
    "from Model.Discrete_SAC import train_discrete_SAC_max\n",
    "\n",
    "exp_title = \"SAC_DM_Discrete_internal\"\n",
    "\n",
    "env = suite.load(domain_name=\"cartpole\",task_name=\"swingup\")\n",
    "\n",
    "state_dim = duju_utils.state_1d_dim_calc(env)[-1]\n",
    "action_dim = 5\n",
    "\n",
    "action_dict = { 0 : -1.0,\n",
    "               1 : -0.5,\n",
    "               2 : 0.0,\n",
    "               3 : 0.5,\n",
    "               4 : 1.0 }\n",
    "\n",
    "reward_compensate = 10 # inverse alpha\n",
    "\n",
    "lr = 1e-3\n",
    "gamma = 0.99\n",
    "device = torch.device(\"cuda\")\n",
    "max_episode = 10000\n",
    "batch_size = 100\n",
    "\n",
    "replay_buffer = ReplayBuffer(buffer_size=1e6)\n",
    "\n",
    "q_main = DiscreteSAC(state_dim, action_dim, lr, device)\n",
    "q_target = DiscreteSAC(state_dim, action_dim, lr, device)\n",
    "\n",
    "target_initialize(q_main, q_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t39.77710564276885 *** (4.257420539855957, 4.06746768951416)\n",
      "Eval! ***  151.01335584455404\n",
      "2\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-28ebc692e306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#print(_idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mmax_q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_discrete_Conv_SAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_main\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"***\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_q1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_q2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/animal_ai_olympics/duju_animal_ai_olympics/Model/DiscreteConv_SAC.py\u001b[0m in \u001b[0;36mtrain_discrete_Conv_SAC\u001b[0;34m(Q_main, Q_target, replay_buffer, batch_size, gamma)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mq2_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_main\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mQ_main\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0msoft_target_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_main\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cd2018-2,p3.5/lib/python3.5/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epi_i in range(1, max_episode + 1):\n",
    "    print(epi_i)\n",
    "\n",
    "    timestep = env.reset()\n",
    "    ep_reward = 0.0\n",
    "\n",
    "    # timestep, reward, discount, observation\n",
    "    end, _, _, s = timestep\n",
    "    end = end.last()\n",
    "    s = duju_utils.state_1d_flat(s)\n",
    "\n",
    "    while not end:\n",
    "        a_category = q_main.get_stochastic_action(torch.FloatTensor(s).to(device).view(1,-1))\n",
    "        a_deploy = action_dict[a_category]\n",
    "        timestep = env.step(a_deploy)\n",
    "\n",
    "        end, r, _, s2 = timestep\n",
    "        end = end.last()\n",
    "        s2 = duju_utils.state_1d_flat(s2)\n",
    "\n",
    "        replay_buffer.add(s, np.array([a_category]), np.array([r * reward_compensate]),np.array([end]), s2)\n",
    "\n",
    "        frame = env.physics.render(camera_id=0, width=640, height=480)  # [height, width, channel]\n",
    "        cv2.imshow(\"train\", frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        s = s2\n",
    "        ep_reward += r\n",
    "\n",
    "    for _idx in range(1000):\n",
    "        #print(_idx)\n",
    "        max_q1, max_q2 = train_discrete_SAC_max(q_main, q_target, replay_buffer, batch_size, gamma)\n",
    "\n",
    "    print(ep_reward, \"***\", (max_q1, max_q2))\n",
    "\n",
    "    timestep = env.reset()\n",
    "    end, _, _, s = timestep\n",
    "    end = end.last()\n",
    "    s = duju_utils.state_1d_flat(s)\n",
    "\n",
    "    eval_ep_reward = 0.0\n",
    "    eval_action = []\n",
    "\n",
    "    if (epi_i % 1) == 0 :\n",
    "        while not end:\n",
    "            a_category = q_main.get_max_action(torch.FloatTensor(s).to(device).view(1,-1))\n",
    "            a_deploy = action_dict[a_category]\n",
    "            eval_action.append(a_deploy)\n",
    "\n",
    "            timestep = env.step(a_deploy)\n",
    "\n",
    "            end, r, _, s2 = timestep\n",
    "            end = end.last()\n",
    "            s2 = duju_utils.state_1d_flat(s2)\n",
    "\n",
    "            s = s2\n",
    "            eval_ep_reward += r\n",
    "\n",
    "            frame = env.physics.render(camera_id=0, width=640, height=480) #[height, width, channel]\n",
    "            cv2.imshow(\"eval\", frame)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        print(\"Eval! *** \", eval_ep_reward)\n",
    "        #print(eval_action)\n",
    "\n",
    "    if (epi_i % 10) == 0:\n",
    "        print(\"Networks Saved!\")\n",
    "        duju_utils.torch_network_save(q_main,\"../trained/\"+exp_title+\"_q_main_\"+str(epi_i)+\".torch\")\n",
    "        duju_utils.torch_network_save(q_target, \"../trained/\"+exp_title+\"_q_target_\"+str(epi_i)+\".torch\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(step_type=<StepType.FIRST: 0>, reward=None, discount=None, observation=OrderedDict([('position', array([ 0.02262341, -0.99993682,  0.01124068])), ('velocity', array([0.00264543, 0.01912411]))]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "duju_utils.torch_network_load(q_main,\"trained/SAC_DM_Discrete_internal_q_main_70.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict = {\n",
    "    0 : -1.0,\n",
    "    1 : 0.0,\n",
    "    2 : 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(step_type=<StepType.FIRST: 0>, reward=None, discount=None, observation=OrderedDict([('position', array([ 0.01979013, -0.9999901 ,  0.00444982])), ('velocity', array([-0.02026992,  0.0027148 ]))]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[279.0955, 281.0389, 282.4721, 283.6904, 285.6277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0012, 0.0085, 0.0356, 0.1202, 0.8345]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[281.5633, 283.8334, 285.8289, 287.3828, 289.3858]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[3.4306e-04, 3.3209e-03, 2.4428e-02, 1.1555e-01, 8.5636e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[284.4920, 287.0407, 289.5648, 291.3965, 293.5172]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[1.0549e-04, 1.3493e-03, 1.6838e-02, 1.0515e-01, 8.7656e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[287.1837, 289.9574, 292.9794, 295.0499, 297.3245]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[3.5323e-05, 5.6578e-04, 1.1617e-02, 9.2109e-02, 8.9567e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[290.0552, 292.9897, 296.3793, 298.6148, 301.0010]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[1.5997e-05, 3.0093e-04, 8.9241e-03, 8.3448e-02, 9.0731e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[293.8965, 296.9953, 300.6920, 303.0606, 305.5519]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[7.9503e-06, 1.7628e-04, 7.1061e-03, 7.5917e-02, 9.1679e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[297.6227, 300.8183, 304.7665, 307.2368, 309.8268]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[4.6322e-06, 1.1315e-04, 5.8660e-03, 6.9369e-02, 9.2465e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[299.7626, 302.9253, 306.9945, 309.4680, 312.1113]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[4.0246e-06, 9.5120e-05, 5.5656e-03, 6.6030e-02, 9.2831e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[302.8562, 305.9843, 310.0710, 312.4768, 315.1236]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[4.3649e-06, 9.9649e-05, 5.9340e-03, 6.5791e-02, 9.2817e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[305.9054, 309.0255, 313.1315, 315.4787, 318.1332]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[4.5420e-06, 1.0287e-04, 6.2442e-03, 6.5292e-02, 9.2836e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[309.0395, 312.2036, 316.3752, 318.7020, 321.3571]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[4.1515e-06, 9.8260e-05, 6.3685e-03, 6.5249e-02, 9.2828e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[313.3062, 316.5421, 320.8147, 323.1545, 325.8265]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[3.3941e-06, 8.6316e-05, 6.1896e-03, 6.4244e-02, 9.2948e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[318.6487, 321.9682, 326.3279, 328.6907, 331.3885]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[2.7308e-06, 7.5497e-05, 5.9059e-03, 6.2728e-02, 9.3129e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[323.7646, 327.1400, 331.5418, 333.9157, 336.6287]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[2.4140e-06, 7.0576e-05, 5.7590e-03, 6.1847e-02, 9.3232e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[328.5614, 331.9615, 336.3297, 338.6799, 341.3903]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[2.4997e-06, 7.4907e-05, 5.9103e-03, 6.1986e-02, 9.3203e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[332.4426, 335.8530, 340.1209, 342.4565, 345.2231]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[2.6334e-06, 7.9731e-05, 5.6908e-03, 5.8814e-02, 9.3541e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[335.8371, 339.2612, 343.4182, 345.7433, 348.5728]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[2.7648e-06, 8.4863e-05, 5.4211e-03, 5.5447e-02, 9.3904e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[339.2322, 342.6690, 346.7131, 349.0251, 351.9128]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[2.9312e-06, 9.1124e-05, 5.1996e-03, 5.2489e-02, 9.4222e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[342.6913, 346.1420, 350.0751, 352.3645, 355.3024]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[3.1505e-06, 9.9315e-05, 5.0716e-03, 5.0051e-02, 9.4477e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[346.4170, 349.8875, 353.7136, 355.9844, 358.9767]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[3.3263e-06, 1.0696e-04, 4.9071e-03, 4.7538e-02, 9.4745e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[350.4172, 353.9323, 357.6781, 359.9480, 363.0161]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[3.2105e-06, 1.0793e-04, 4.5705e-03, 4.4235e-02, 9.5108e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[354.7088, 358.2708, 361.9371, 364.2081, 367.3486]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[3.0924e-06, 1.0896e-04, 4.2611e-03, 4.1286e-02, 9.5434e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[359.0177, 362.6289, 366.2108, 368.4838, 371.6966]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[2.9835e-06, 1.1042e-04, 3.9687e-03, 3.8529e-02, 9.5739e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[362.7907, 366.4083, 369.8652, 372.1030, 375.3396]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[3.4006e-06, 1.2666e-04, 4.0174e-03, 3.7654e-02, 9.5820e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[366.1457, 369.7299, 373.0288, 375.1829, 378.3857]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[4.6229e-06, 1.6653e-04, 4.5104e-03, 3.8879e-02, 9.5644e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[369.4377, 372.9902, 376.1396, 378.1966, 381.3639]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[6.3130e-06, 2.2034e-04, 5.1385e-03, 4.0197e-02, 9.5444e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[373.7272, 377.2583, 380.2747, 382.2321, 385.3660]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[8.3976e-06, 2.8686e-04, 5.8572e-03, 4.1476e-02, 9.5237e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[378.0685, 381.5767, 384.4579, 386.3131, 389.4093]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[1.1284e-05, 3.7676e-04, 6.7193e-03, 4.2958e-02, 9.4993e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[382.1051, 385.5440, 388.2457, 389.9662, 392.9734]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[1.7994e-05, 5.6058e-04, 8.3548e-03, 4.6685e-02, 9.4438e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[385.9511, 389.3124, 391.8231, 393.4035, 396.3128]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[2.9643e-05, 8.5454e-04, 1.0522e-02, 5.1107e-02, 9.3749e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[389.3133, 392.5909, 394.8979, 396.3374, 399.1428]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[5.0022e-05, 1.3262e-03, 1.3320e-02, 5.6192e-02, 9.2911e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[392.7050, 395.9217, 398.0435, 399.3640, 402.0938]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[7.7115e-05, 1.9236e-03, 1.6054e-02, 6.0132e-02, 9.2181e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[396.4447, 399.5981, 401.5622, 402.7856, 405.4380]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[1.1353e-04, 2.6586e-03, 1.8951e-02, 6.4409e-02, 9.1387e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[401.0925, 404.1658, 405.9982, 407.1363, 409.6731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[1.6931e-04, 3.6590e-03, 2.2865e-02, 7.1359e-02, 9.0195e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[405.4863, 408.4881, 410.2003, 411.2616, 413.6766]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[2.4626e-04, 4.9554e-03, 2.7458e-02, 7.9356e-02, 8.8798e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[409.4525, 412.3867, 413.9755, 414.9789, 417.2863]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[3.4627e-04, 6.5127e-03, 3.1896e-02, 8.7004e-02, 8.7424e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[412.8391, 415.6535, 417.0901, 418.0078, 420.1506]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[5.6784e-04, 9.4736e-03, 3.9849e-02, 9.9768e-02, 8.5034e-01]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[415.9897, 418.6783, 419.9608, 420.7895, 422.7613]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0009, 0.0138, 0.0499, 0.1143, 0.8210]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[418.7191, 421.2559, 422.3647, 423.0826, 424.8541]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0017, 0.0213, 0.0647, 0.1326, 0.7797]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[421.1803, 423.5567, 424.4847, 425.0857, 426.6494]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0031, 0.0330, 0.0836, 0.1524, 0.7279]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[423.3913, 425.6163, 426.3634, 426.8537, 428.2355]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0053, 0.0490, 0.1035, 0.1690, 0.6731]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[425.5470, 427.6270, 428.1891, 428.5762, 429.7894]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0088, 0.0706, 0.1239, 0.1825, 0.6141]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[427.5338, 429.4733, 429.8576, 430.1496, 431.2028]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0141, 0.0979, 0.1437, 0.1925, 0.5518]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[429.3038, 431.0998, 431.3057, 431.5040, 432.3972]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0220, 0.1324, 0.1627, 0.1984, 0.4846]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[431.6248, 433.4050, 433.5931, 433.7784, 434.7147]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0224, 0.1327, 0.1602, 0.1928, 0.4918]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[434.2668, 436.0787, 436.2948, 436.4988, 437.5504]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0197, 0.1207, 0.1498, 0.1838, 0.5260]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[436.6791, 438.5343, 438.7844, 439.0164, 440.2076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0167, 0.1065, 0.1368, 0.1725, 0.5676]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[438.0304, 439.9012, 440.1733, 440.4258, 441.7379]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0148, 0.0959, 0.1258, 0.1620, 0.6016]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[439.2138, 441.1742, 441.4420, 441.6449, 443.0974]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0129, 0.0918, 0.1200, 0.1470, 0.6282]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[440.9463, 443.0229, 443.2927, 443.4455, 445.0547]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0108, 0.0863, 0.1130, 0.1317, 0.6582]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[443.0757, 445.2889, 445.5897, 445.7127, 447.4962]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0084, 0.0765, 0.1033, 0.1168, 0.6951]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[445.5198, 447.8738, 448.2047, 448.3045, 450.2705]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0063, 0.0666, 0.0927, 0.1025, 0.7319]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[447.8051, 450.2684, 450.5741, 450.6252, 452.6739]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0057, 0.0669, 0.0908, 0.0955, 0.7411]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[449.9721, 452.5356, 452.7957, 452.7913, 454.8920]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0054, 0.0703, 0.0912, 0.0908, 0.7422]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[451.7979, 454.4742, 454.6891, 454.6434, 456.8093]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0050, 0.0723, 0.0897, 0.0857, 0.7473]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[454.2500, 457.0312, 457.1720, 457.1607, 459.3910]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0044, 0.0717, 0.0826, 0.0817, 0.7596]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[458.3115, 461.1380, 461.2152, 461.2587, 463.4838]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0043, 0.0729, 0.0788, 0.0823, 0.7616]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[462.7034, 465.5589, 465.5672, 465.6555, 467.8544]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0044, 0.0764, 0.0770, 0.0841, 0.7582]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[467.1204, 469.9952, 469.9326, 470.0575, 472.2412]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0045, 0.0799, 0.0751, 0.0851, 0.7554]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[471.9221, 474.7929, 474.6471, 474.7920, 476.9477]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0049, 0.0866, 0.0749, 0.0865, 0.7471]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[477.1633, 480.0021, 479.7478, 479.8851, 481.9782]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0059, 0.1006, 0.0780, 0.0895, 0.7259]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[483.5193, 486.3370, 485.9822, 486.1087, 488.1620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0068, 0.1142, 0.0801, 0.0909, 0.7081]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[490.5734, 493.3749, 492.9201, 493.0287, 495.0534]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0078, 0.1289, 0.0818, 0.0912, 0.6904]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[467.5554, 469.8510, 469.2871, 468.9728, 470.8034]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0215, 0.2138, 0.1216, 0.0888, 0.5542]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[438.7388, 439.8924, 439.1665, 438.1384, 438.6940]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.1387, 0.4397, 0.2128, 0.0761, 0.1327]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[413.5648, 414.1574, 413.5020, 412.3156, 412.1023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.2344, 0.4240, 0.2201, 0.0672, 0.0543]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[409.9978, 410.6061, 410.5103, 409.1866, 409.0209]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.1877, 0.3449, 0.3134, 0.0834, 0.0707]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[412.0891, 412.4510, 412.6328, 411.2273, 410.7893]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.2060, 0.2959, 0.3549, 0.0870, 0.0562]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[414.9542, 415.2144, 415.4045, 413.9752, 413.2556]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.2260, 0.2932, 0.3546, 0.0849, 0.0413]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[421.9830, 422.2036, 422.3623, 420.9499, 420.1220]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.2370, 0.2955, 0.3463, 0.0843, 0.0369]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[425.9580, 426.1905, 426.2834, 424.8681, 424.1109]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.2415, 0.3047, 0.3344, 0.0812, 0.0381]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[428.4496, 428.6855, 428.7897, 427.4161, 426.8000]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.2370, 0.3001, 0.3330, 0.0843, 0.0455]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[431.4379, 431.6515, 431.7760, 430.4622, 430.0180]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.2348, 0.2907, 0.3292, 0.0885, 0.0568]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[433.5640, 433.7993, 433.9781, 432.7523, 432.5146]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.2187, 0.2767, 0.3309, 0.0971, 0.0766]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[435.8804, 436.1587, 436.4172, 435.2960, 435.2556]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1951, 0.2578, 0.3338, 0.1088, 0.1045]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[436.2534, 436.5362, 436.8436, 435.7908, 435.8805]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1835, 0.2435, 0.3311, 0.1155, 0.1264]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[436.8993, 437.1744, 437.5095, 436.5200, 436.6950]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1768, 0.2327, 0.3254, 0.1210, 0.1441]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[438.3683, 438.6469, 438.9962, 438.0746, 438.3155]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1698, 0.2243, 0.3182, 0.1266, 0.1611]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[441.2124, 441.6143, 442.0473, 441.2292, 441.6307]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1363, 0.2038, 0.3142, 0.1386, 0.2071]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[444.1153, 444.6392, 445.1614, 444.4483, 445.0118]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1066, 0.1800, 0.3034, 0.1487, 0.2613]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[446.7336, 447.3819, 447.9982, 447.3962, 448.1299]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0804, 0.1538, 0.2848, 0.1560, 0.3249]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[450.1522, 450.8990, 451.5859, 451.0852, 451.9287]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0635, 0.1339, 0.2662, 0.1613, 0.3751]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[453.6648, 454.5183, 455.2792, 454.8892, 455.8594]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0482, 0.1131, 0.2421, 0.1639, 0.4326]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[458.4334, 459.3248, 460.0851, 459.7274, 460.7154]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0453, 0.1104, 0.2360, 0.1651, 0.4433]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[463.5924, 464.5118, 465.2509, 464.9137, 465.9023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0443, 0.1111, 0.2326, 0.1660, 0.4461]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[468.7139, 469.6582, 470.3733, 470.0575, 471.0460]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0436, 0.1120, 0.2289, 0.1669, 0.4486]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[473.6318, 474.5974, 475.2861, 474.9940, 475.9807]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0430, 0.1130, 0.2251, 0.1681, 0.4508]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[478.1671, 479.1494, 479.8094, 479.5419, 480.5248]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0428, 0.1143, 0.2212, 0.1693, 0.4524]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[481.6473, 482.6435, 483.2831, 483.0514, 484.0409]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0419, 0.1135, 0.2151, 0.1706, 0.4589]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[485.2921, 486.2932, 486.9075, 486.7087, 487.6977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0417, 0.1136, 0.2099, 0.1721, 0.4627]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[488.8872, 489.8846, 490.4679, 490.2982, 491.2793]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0424, 0.1149, 0.2058, 0.1737, 0.4633]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[492.2764, 493.2673, 493.8170, 493.6780, 494.6505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0432, 0.1163, 0.2015, 0.1753, 0.4637]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[495.4512, 496.4335, 496.9472, 496.8404, 497.8047]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0441, 0.1178, 0.1969, 0.1770, 0.4642]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[498.9858, 499.9504, 500.4171, 500.3315, 501.2782]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0464, 0.1218, 0.1942, 0.1782, 0.4594]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[502.7636, 503.7004, 504.1082, 504.0311, 504.9474]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0505, 0.1287, 0.1936, 0.1792, 0.4480]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[506.2819, 507.1884, 507.5368, 507.4669, 508.3534]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0550, 0.1361, 0.1928, 0.1798, 0.4363]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[510.5031, 511.3158, 511.6220, 511.5222, 512.4471]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0622, 0.1402, 0.1905, 0.1724, 0.4347]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[514.7311, 515.3991, 515.6805, 515.5351, 516.5662]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0713, 0.1390, 0.1841, 0.1592, 0.4465]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[517.9703, 518.5204, 518.8292, 518.6688, 519.8345]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0738, 0.1279, 0.1741, 0.1483, 0.4759]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[519.5521, 519.9752, 520.2972, 520.0592, 521.3203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0823, 0.1256, 0.1733, 0.1366, 0.4822]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[520.0131, 520.3069, 520.6462, 520.3314, 521.6779]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.0919, 0.1233, 0.1730, 0.1263, 0.4855]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[520.1726, 520.3280, 520.6824, 520.2802, 521.7082]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.1043, 0.1218, 0.1736, 0.1161, 0.4842]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[519.2687, 518.9861, 518.9714, 518.0768, 519.3543]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 1.0 tensor([[0.2571, 0.1938, 0.1910, 0.0781, 0.2801]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[518.1411, 517.4206, 517.0261, 515.6210, 516.7538]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.4663, 0.2269, 0.1529, 0.0375, 0.1165]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[522.8485, 521.7294, 521.0334, 519.2812, 520.1656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.6305, 0.2059, 0.1027, 0.0178, 0.0431]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[531.8766, 530.4372, 529.4672, 527.2424, 527.9055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.7377, 0.1749, 0.0663, 0.0072, 0.0139]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[539.1848, 537.5250, 536.3428, 533.7127, 534.2335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.7938, 0.1510, 0.0463, 0.0033, 0.0056]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[546.3061, 544.4098, 542.9980, 539.9377, 540.3107]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.8397, 0.1261, 0.0307, 0.0014, 0.0021]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[553.3063, 551.1151, 549.3958, 545.8078, 546.0637]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[8.8255e-01, 9.8651e-02, 1.7679e-02, 4.8887e-04, 6.3145e-04]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[561.7184, 558.9917, 556.7856, 552.5357, 552.6540]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.3209e-01, 6.0988e-02, 6.7169e-03, 9.5818e-05, 1.0785e-04]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[570.1347, 566.8424, 564.1266, 559.1840, 559.1541]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.6185e-01, 3.5750e-02, 2.3649e-03, 1.6877e-05, 1.6379e-05]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[579.6910, 575.7911, 572.5367, 566.8686, 566.6619]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.7940e-01, 1.9827e-02, 7.6540e-04, 2.6439e-06, 2.1501e-06]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[588.1318, 583.6202, 579.8414, 573.4581, 573.1068]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.8889e-01, 1.0859e-02, 2.4814e-04, 4.1922e-07, 2.9505e-07]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[594.6931, 589.8825, 585.9113, 578.9831, 578.6029]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.9177e-01, 8.0759e-03, 1.5224e-04, 1.4915e-07, 1.0198e-07]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[603.3505, 598.3837, 594.3349, 587.0366, 586.6078]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.9296e-01, 6.9164e-03, 1.2065e-04, 8.1643e-08, 5.3172e-08]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[613.1821, 608.1611, 604.1292, 596.5233, 596.0343]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.9333e-01, 6.5543e-03, 1.1628e-04, 5.7845e-08, 3.5474e-08]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[625.0476, 620.6594, 617.0444, 609.7017, 609.4509]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.8740e-01, 1.2267e-02, 3.3017e-04, 2.1371e-07, 1.6632e-07]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[633.4526, 630.0135, 627.1000, 620.3696, 620.5350]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.6727e-01, 3.1043e-02, 1.6851e-03, 2.0121e-06, 2.3741e-06]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[641.4688, 639.0147, 636.9430, 631.0312, 631.3991]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[9.1171e-01, 7.8353e-02, 9.8701e-03, 2.6723e-05, 3.8605e-05]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[648.4963, 647.1286, 646.1945, 641.3443, 642.1885]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[7.3673e-01, 1.8763e-01, 7.3724e-02, 5.7705e-04, 1.3423e-03]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[655.0064, 654.6736, 654.8335, 651.0109, 652.2867]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.3784, 0.2713, 0.3183, 0.0070, 0.0249]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[662.5952, 662.6475, 663.3177, 659.9050, 660.7598]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.2304, 0.2427, 0.4745, 0.0156, 0.0368]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[662.1367, 661.3320, 661.3797, 657.3347, 656.6981]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.5184, 0.2319, 0.2432, 0.0043, 0.0023]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[672.5403, 671.8826, 672.1777, 668.3939, 667.1901]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.4475, 0.2318, 0.3114, 0.0071, 0.0021]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[683.9382, 683.4301, 683.9970, 680.5040, 678.7607]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.3704, 0.2228, 0.3928, 0.0119, 0.0021]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[689.7172, 688.0519, 687.7601, 683.5269, 680.2090]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[7.5045e-01, 1.4194e-01, 1.0602e-01, 1.5378e-03, 5.5715e-05]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[701.5351, 700.3002, 700.4313, 696.8781, 693.4461]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[6.1263e-01, 1.7820e-01, 2.0316e-01, 5.8170e-03, 1.8802e-04]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[717.1035, 716.2578, 716.8057, 713.8895, 710.5027]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.4518, 0.1940, 0.3354, 0.0182, 0.0006]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[726.4424, 725.9994, 727.0623, 724.8517, 721.8015]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.2692, 0.1729, 0.5004, 0.0549, 0.0026]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[732.2012, 731.5264, 732.5383, 730.5053, 727.3791]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.3224, 0.1642, 0.4516, 0.0591, 0.0026]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[738.0497, 737.1722, 738.1611, 736.3153, 733.1141]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.3680, 0.1530, 0.4114, 0.0650, 0.0026]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[744.8510, 743.7650, 744.7304, 743.0552, 739.7437]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.4174, 0.1409, 0.3699, 0.0693, 0.0025]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[749.2701, 748.7715, 750.3964, 749.6036, 746.8964]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1618, 0.0983, 0.4990, 0.2258, 0.0151]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[761.0195, 760.4582, 762.0652, 761.7180, 759.3322]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1512, 0.0863, 0.4304, 0.3041, 0.0280]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[776.8656, 776.0755, 777.5423, 777.4920, 775.3157]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1817, 0.0824, 0.3574, 0.3399, 0.0386]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[787.3151, 786.5996, 787.9370, 788.2200, 786.4677]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.1600, 0.0782, 0.2979, 0.3954, 0.0685]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[798.6946, 798.0576, 798.9303, 799.3533, 798.0400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.1906, 0.1008, 0.2413, 0.3683, 0.0990]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[802.9446, 802.3124, 802.8041, 803.2893, 802.2751]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.2313, 0.1229, 0.2010, 0.3265, 0.1184]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[805.5531, 804.6080, 804.6909, 804.8551, 803.4149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.4121, 0.1602, 0.1740, 0.2051, 0.0486]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[812.5019, 812.0118, 812.3206, 812.7643, 811.6346]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.2400, 0.1470, 0.2002, 0.3120, 0.1008]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[822.3280, 821.8807, 822.1049, 822.3555, 821.1494]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.2649, 0.1694, 0.2119, 0.2723, 0.0815]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[831.1232, 830.7347, 830.9249, 831.0291, 829.7508]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -1.0 tensor([[0.2731, 0.1852, 0.2240, 0.2486, 0.0692]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[838.5231, 838.5951, 839.0324, 839.3513, 838.4487]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.1438, 0.1545, 0.2392, 0.3291, 0.1334]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[843.4876, 843.7263, 844.3068, 844.6713, 843.8069]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.1089, 0.1383, 0.2471, 0.3558, 0.1499]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[846.3331, 846.6814, 847.3209, 847.7123, 846.8954]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0923, 0.1308, 0.2480, 0.3668, 0.1621]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[850.2349, 850.6764, 851.3456, 851.7607, 850.9694]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0815, 0.1267, 0.2474, 0.3747, 0.1698]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[855.7208, 856.2480, 856.9442, 857.3777, 856.5951]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0728, 0.1234, 0.2475, 0.3818, 0.1746]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[859.6571, 860.3425, 861.1358, 861.6721, 860.9877]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0536, 0.1064, 0.2352, 0.4021, 0.2028]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[860.1307, 861.0062, 861.9323, 862.6168, 862.0699]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0352, 0.0844, 0.2131, 0.4226, 0.2446]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[859.9056, 860.9225, 861.9402, 862.7136, 862.2510]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0260, 0.0719, 0.1991, 0.4314, 0.2716]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[862.3618, 863.3802, 864.3527, 865.0497, 864.5024]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0292, 0.0807, 0.2135, 0.4286, 0.2480]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[863.1265, 864.1448, 865.0732, 865.7045, 865.0834]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0322, 0.0892, 0.2258, 0.4246, 0.2281]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[864.9188, 865.8664, 866.6844, 867.1816, 866.4079]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0426, 0.1099, 0.2491, 0.4095, 0.1889]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[868.2715, 869.1086, 869.7823, 870.1061, 869.1285]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0608, 0.1403, 0.2753, 0.3805, 0.1432]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[872.0737, 872.7906, 873.3190, 873.4596, 872.2632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0853, 0.1746, 0.2962, 0.3409, 0.1031]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[876.3476, 876.9363, 877.3163, 877.2646, 875.8381]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1171, 0.2110, 0.3085, 0.2930, 0.0704]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[881.5875, 882.2715, 882.6574, 882.6128, 881.1840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1069, 0.2119, 0.3117, 0.2981, 0.0714]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[887.8825, 888.6326, 889.0093, 888.9573, 887.4902]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1020, 0.2159, 0.3146, 0.2987, 0.0689]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[892.9556, 893.8447, 894.2656, 894.2698, 892.8431]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0851, 0.2070, 0.3153, 0.3166, 0.0760]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[896.2322, 896.9927, 897.2654, 897.0724, 895.4288]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.1148, 0.2455, 0.3225, 0.2659, 0.0514]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[900.4650, 901.3760, 901.6989, 901.5562, 899.9659]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0952, 0.2367, 0.3269, 0.2834, 0.0578]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[905.3369, 906.3649, 906.7111, 906.5816, 904.9972]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0838, 0.2343, 0.3312, 0.2910, 0.0597]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[910.0846, 911.1949, 911.5369, 911.3960, 909.7974]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0783, 0.2377, 0.3346, 0.2906, 0.0588]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[915.4817, 916.6149, 916.8990, 916.6934, 915.0267]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0818, 0.2540, 0.3375, 0.2748, 0.0519]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[920.0953, 921.2449, 921.4745, 921.2053, 919.4684]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0855, 0.2699, 0.3395, 0.2594, 0.0457]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[924.8699, 926.0278, 926.2007, 925.8623, 924.0511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0900, 0.2866, 0.3407, 0.2429, 0.0397]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[927.8530, 929.0936, 929.2787, 928.9498, 927.1519]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0826, 0.2855, 0.3436, 0.2473, 0.0410]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[930.1390, 931.4866, 931.7090, 931.4191, 929.6642]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0721, 0.2774, 0.3465, 0.2593, 0.0448]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[934.0141, 935.4597, 935.7105, 935.4449, 933.7143]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0640, 0.2717, 0.3491, 0.2677, 0.0474]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[938.1376, 939.7115, 940.0222, 939.8098, 938.1375]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0534, 0.2576, 0.3515, 0.2842, 0.0534]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[941.8097, 943.5068, 943.8741, 943.7167, 942.1084]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0446, 0.2435, 0.3515, 0.3003, 0.0601]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[945.2500, 947.0645, 947.4810, 947.3782, 945.8340]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0375, 0.2304, 0.3494, 0.3153, 0.0673]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[948.8842, 950.8272, 951.3007, 951.2625, 949.7968]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0308, 0.2150, 0.3452, 0.3323, 0.0767]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[952.8326, 954.9134, 955.4510, 955.4907, 954.1353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0246, 0.1970, 0.3372, 0.3508, 0.0905]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[954.5316, 956.4077, 956.7674, 956.5702, 954.9780]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0383, 0.2499, 0.3581, 0.2940, 0.0598]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[958.8115, 960.8256, 961.2524, 961.1370, 959.6802]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0307, 0.2299, 0.3523, 0.3139, 0.0731]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[962.4005, 964.5634, 965.0662, 965.0465, 963.7401]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0238, 0.2071, 0.3424, 0.3357, 0.0909]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[963.1017, 965.4865, 966.1376, 966.3032, 965.2341]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0152, 0.1653, 0.3170, 0.3741, 0.1284]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.3500, 966.5424, 967.0325, 966.9756, 965.6851]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0237, 0.2123, 0.3465, 0.3274, 0.0901]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.5081, 966.9373, 967.5914, 967.7380, 966.7037]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0146, 0.1658, 0.3190, 0.3693, 0.1313]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.8655, 968.0988, 968.5891, 968.5032, 967.2426]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0230, 0.2144, 0.3502, 0.3213, 0.0911]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.2586, 968.7136, 969.3564, 969.4609, 968.4400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0147, 0.1707, 0.3246, 0.3603, 0.1298]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.9795, 970.2258, 970.6930, 970.5477, 969.2849]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0237, 0.2237, 0.3568, 0.3086, 0.0873]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.6793, 971.1309, 971.7388, 971.7692, 970.7252]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0157, 0.1824, 0.3350, 0.3453, 0.1216]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.4727, 972.6965, 973.1140, 972.8754, 971.5696]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0261, 0.2412, 0.3662, 0.2884, 0.0782]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.4697, 973.8746, 974.4131, 974.3308, 973.2147]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0184, 0.2041, 0.3498, 0.3221, 0.1055]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.3293, 974.8937, 975.5416, 975.6011, 974.6532]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0133, 0.1723, 0.3294, 0.3496, 0.1355]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.9266, 975.2124, 975.6359, 975.3857, 974.1372]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0244, 0.2404, 0.3672, 0.2859, 0.0820]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[973.8572, 976.2849, 976.8032, 976.6797, 975.5749]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0186, 0.2108, 0.3540, 0.3129, 0.1037]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[974.8632, 977.4338, 978.0491, 978.0544, 977.0942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0139, 0.1819, 0.3365, 0.3383, 0.1295]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[975.2433, 977.5098, 977.8806, 977.5558, 976.2608]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0267, 0.2573, 0.3728, 0.2694, 0.0738]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[976.3096, 978.7062, 979.1630, 978.9537, 977.7882]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0209, 0.2299, 0.3630, 0.2944, 0.0918]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[977.3233, 979.8523, 980.3978, 980.3074, 979.2745]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0161, 0.2023, 0.3491, 0.3189, 0.1135]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[978.2821, 980.9473, 981.5844, 981.6165, 980.7183]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0122, 0.1752, 0.3312, 0.3421, 0.1393]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[978.8141, 981.1595, 981.5407, 981.2280, 979.9776]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0243, 0.2540, 0.3718, 0.2720, 0.0779]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.8122, 982.2797, 982.7422, 982.5388, 981.4086]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0193, 0.2279, 0.3620, 0.2954, 0.0954]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[980.8707, 983.4639, 984.0101, 983.9193, 982.9123]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0151, 0.2019, 0.3485, 0.3183, 0.1163]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[982.4955, 985.2286, 985.8735, 985.9086, 985.0400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0113, 0.1732, 0.3301, 0.3419, 0.1434]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[982.9609, 985.3572, 985.7311, 985.4037, 984.1661]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0234, 0.2567, 0.3730, 0.2689, 0.0780]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[984.0719, 986.5945, 987.0634, 986.8538, 985.7418]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0182, 0.2272, 0.3632, 0.2945, 0.0969]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.1659, 987.8180, 988.3898, 988.3075, 987.3219]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0139, 0.1968, 0.3486, 0.3210, 0.1198]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.4495, 989.2262, 989.8943, 989.9338, 989.0666]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0106, 0.1697, 0.3309, 0.3442, 0.1446]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.7258, 989.1633, 989.5561, 989.2256, 987.9932]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0222, 0.2536, 0.3756, 0.2699, 0.0787]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.9583, 990.5090, 990.9894, 990.7689, 989.6439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0177, 0.2266, 0.3664, 0.2939, 0.0954]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.2505, 991.9144, 992.4816, 992.3713, 991.3527]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0140, 0.2007, 0.3539, 0.3169, 0.1145]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.4742, 993.2507, 993.9038, 993.9032, 992.9919]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0110, 0.1762, 0.3385, 0.3383, 0.1360]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.3687, 994.2485, 994.9813, 995.0837, 994.2715]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0087, 0.1547, 0.3218, 0.3566, 0.1583]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.4983, 994.0090, 994.4388, 994.1472, 992.9425]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0198, 0.2433, 0.3739, 0.2793, 0.0837]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.4116, 995.0037, 995.4927, 995.2833, 994.1569]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0168, 0.2244, 0.3659, 0.2967, 0.0962]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.1099, 995.7897, 996.3444, 996.2225, 995.1795]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0140, 0.2043, 0.3558, 0.3149, 0.1110]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.8151, 996.5858, 997.2098, 997.1789, 996.2237]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0115, 0.1840, 0.3434, 0.3330, 0.1281]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.5158, 997.3802, 998.0759, 998.1394, 997.2752]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0093, 0.1640, 0.3288, 0.3503, 0.1476]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.8887, 997.3766, 997.7595, 997.4243, 996.1630]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0213, 0.2567, 0.3765, 0.2692, 0.0763]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.6044, 998.1738, 998.6183, 998.3639, 997.1806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0182, 0.2372, 0.3700, 0.2868, 0.0879]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.4181, 999.0748, 999.5863, 999.4182, 998.3196]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0152, 0.2166, 0.3612, 0.3053, 0.1018]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.5090, 999.2747, 999.8751, 999.8175, 998.8304]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0120, 0.1906, 0.3473, 0.3279, 0.1222]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 996.3741,  999.2559,  999.9531, 1000.0142,  999.1472]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0092, 0.1640, 0.3294, 0.3502, 0.1471]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.5198,  999.9918, 1000.3435,  999.9725,  998.6701]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0225, 0.2664, 0.3787, 0.2613, 0.0710]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.5519, 1000.1245, 1000.5584, 1000.2890,  999.0893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0184, 0.2408, 0.3716, 0.2838, 0.0855]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.6801, 1000.3578, 1000.8793, 1000.7161,  999.6255]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0147, 0.2144, 0.3611, 0.3067, 0.1031]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.6153, 1000.4073, 1001.0256, 1000.9774, 1000.0069]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0114, 0.1867, 0.3465, 0.3302, 0.1251]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 997.4489, 1000.3586, 1001.0792, 1001.1509, 1000.3048]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0087, 0.1596, 0.3281, 0.3524, 0.1512]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.9442, 1001.4229, 1001.7734, 1001.3919, 1000.0833]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0225, 0.2677, 0.3801, 0.2596, 0.0701]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.1480, 1001.7243, 1002.1567, 1001.8741, 1000.6677]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0184, 0.2424, 0.3734, 0.2815, 0.0843]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.0480, 1001.7302, 1002.2537, 1002.0786, 1000.9839]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0147, 0.2152, 0.3632, 0.3049, 0.1020]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.9257, 1001.7167, 1002.3334, 1002.2681, 1001.2885]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0116, 0.1886, 0.3495, 0.3274, 0.1229]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.7939, 1001.6961, 1002.4084, 1002.4565, 1001.5943]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0089, 0.1630, 0.3323, 0.3486, 0.1472]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.6589, 1003.1149, 1003.4426, 1003.0229, 1001.6815]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0237, 0.2759, 0.3829, 0.2517, 0.0658]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.5841, 1003.1375, 1003.5482, 1003.2270, 1001.9872]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0195, 0.2503, 0.3774, 0.2737, 0.0792]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.5005, 1003.1531, 1003.6490, 1003.4285, 1002.2933]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0158, 0.2246, 0.3688, 0.2958, 0.0951]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.4066, 1003.1610, 1003.7443, 1003.6266, 1002.5997]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0127, 0.1992, 0.3570, 0.3174, 0.1137]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.3002, 1003.1595, 1003.8324, 1003.8211, 1002.9041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0100, 0.1745, 0.3421, 0.3382, 0.1352]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.1642, 1003.1312, 1003.8967, 1003.9957, 1003.1929]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0078, 0.1506, 0.3238, 0.3576, 0.1602]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.9813, 1004.4955, 1004.8712, 1004.4975, 1003.2101]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0212, 0.2621, 0.3816, 0.2626, 0.0725]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.9256, 1004.5363, 1004.9932, 1004.7162, 1003.5284]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0174, 0.2373, 0.3747, 0.2840, 0.0866]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.7192, 1004.4320, 1004.9755, 1004.8000, 1003.7191]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0140, 0.2117, 0.3646, 0.3059, 0.1038]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.6794, 1004.4904, 1005.1173, 1005.0420, 1004.0629]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0113, 0.1880, 0.3518, 0.3263, 0.1226]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.6917, 1004.6016, 1005.3123, 1005.3392, 1004.4615]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0090, 0.1653, 0.3364, 0.3456, 0.1437]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.1125, 1005.5611, 1005.8636, 1005.3998, 1004.0370]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0246, 0.2850, 0.3857, 0.2426, 0.0621]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.3363, 1005.8672, 1006.2365, 1005.8543, 1004.5732]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0210, 0.2640, 0.3819, 0.2606, 0.0724]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.5526, 1006.1678, 1006.6059, 1006.3088, 1005.1122]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0177, 0.2426, 0.3759, 0.2793, 0.0844]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.7604, 1006.4636, 1006.9728, 1006.7631, 1005.6541]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0148, 0.2210, 0.3677, 0.2981, 0.0984]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.9157, 1006.7081, 1007.2908, 1007.1716, 1006.1522]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0122, 0.1994, 0.3571, 0.3169, 0.1144]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.6877, 1006.5671, 1007.2226, 1007.1931, 1006.2612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0100, 0.1789, 0.3446, 0.3346, 0.1318]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.3418, 1006.3112, 1007.0423, 1007.1059, 1006.2673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0081, 0.1587, 0.3298, 0.3514, 0.1519]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.2916, 1008.7862, 1009.0779, 1008.6264, 1007.2733]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0236, 0.2862, 0.3832, 0.2440, 0.0630]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.4951, 1009.0718, 1009.4304, 1009.0618, 1007.7913]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0201, 0.2649, 0.3791, 0.2622, 0.0736]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.3375, 1008.9938, 1009.4186, 1009.1318, 1007.9417]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0171, 0.2441, 0.3733, 0.2802, 0.0852]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.1279, 1008.8665, 1009.3602, 1009.1574, 1008.0505]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0144, 0.2231, 0.3655, 0.2984, 0.0986]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.9109, 1008.7343, 1009.2995, 1009.1848, 1008.1638]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0120, 0.2019, 0.3553, 0.3168, 0.1141]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.6336, 1008.5475, 1009.1887, 1009.1668, 1008.2366]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0098, 0.1804, 0.3425, 0.3351, 0.1322]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.3799, 1008.3954, 1009.1234, 1009.2050, 1008.3778]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0077, 0.1575, 0.3261, 0.3539, 0.1547]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.9294, 1010.4615, 1010.7369, 1010.3042, 1008.9553]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0229, 0.2880, 0.3793, 0.2460, 0.0639]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6521, 1010.2708, 1010.6202, 1010.2752, 1009.0121]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0193, 0.2646, 0.3752, 0.2658, 0.0752]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.4475, 1010.1590, 1010.5870, 1010.3353, 1009.1635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0160, 0.2402, 0.3685, 0.2865, 0.0888]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.2434, 1010.0508, 1010.5595, 1010.4045, 1009.3278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0130, 0.2158, 0.3590, 0.3074, 0.1047]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.8959, 1009.8007, 1010.3924, 1010.3378, 1009.3599]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0105, 0.1917, 0.3464, 0.3280, 0.1234]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.5063, 1009.5073, 1010.1811, 1010.2284, 1009.3481]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0084, 0.1689, 0.3313, 0.3474, 0.1440]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.4969, 1011.0040, 1011.2130, 1010.7424, 1009.3308]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0249, 0.3057, 0.3767, 0.2353, 0.0574]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.1194, 1010.7123, 1010.9951, 1010.6143, 1009.2899]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0211, 0.2817, 0.3738, 0.2554, 0.0679]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.7417, 1010.4239, 1010.7820, 1010.4940, 1009.2606]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0176, 0.2575, 0.3683, 0.2762, 0.0804]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.3730, 1010.1461, 1010.5830, 1010.3901, 1009.2500]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0145, 0.2328, 0.3604, 0.2972, 0.0950]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.1006, 1009.9615, 1010.4736, 1010.3740, 1009.3225]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0120, 0.2099, 0.3503, 0.3171, 0.1108]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.8111, 1009.7634, 1010.3537, 1010.3515, 1009.3920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0098, 0.1870, 0.3375, 0.3367, 0.1290]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.3579, 1009.4047, 1010.0770, 1010.1752, 1009.3149]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0078, 0.1644, 0.3221, 0.3553, 0.1503]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.2241, 1010.8068, 1011.0403, 1010.6453, 1009.2830]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0222, 0.2935, 0.3707, 0.2497, 0.0639]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.9658, 1010.6320, 1010.9357, 1010.6283, 1009.3505]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0188, 0.2704, 0.3664, 0.2694, 0.0751]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.7556, 1010.5041, 1010.8785, 1010.6589, 1009.4647]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0158, 0.2476, 0.3600, 0.2890, 0.0876]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.5416, 1010.3762, 1010.8240, 1010.6954, 1009.5884]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0132, 0.2245, 0.3513, 0.3089, 0.1021]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.2405, 1010.1646, 1010.6889, 1010.6559, 1009.6399]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0108, 0.2012, 0.3400, 0.3289, 0.1191]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.8264, 1009.8436, 1010.4490, 1010.5158, 1009.5977]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0087, 0.1779, 0.3259, 0.3484, 0.1391]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.8672, 1011.4273, 1011.5997, 1011.1790, 1009.7655]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0239, 0.3091, 0.3672, 0.2411, 0.0587]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.6426, 1011.2832, 1011.5244, 1011.1887, 1009.8564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0204, 0.2862, 0.3643, 0.2604, 0.0687]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.3821, 1011.1071, 1011.4203, 1011.1732, 1009.9265]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0172, 0.2625, 0.3591, 0.2805, 0.0806]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.1144, 1010.9266, 1011.3151, 1011.1605, 1010.0021]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0143, 0.2384, 0.3515, 0.3012, 0.0946]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6757, 1010.5781, 1011.0456, 1010.9875, 1009.9228]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0117, 0.2139, 0.3413, 0.3220, 0.1111]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.2180, 1010.2147, 1010.7640, 1010.8057, 1009.8394]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0095, 0.1896, 0.3283, 0.3423, 0.1303]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1009.0587, 1011.5880, 1011.6998, 1011.2455, 1009.7824]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0259, 0.3255, 0.3640, 0.2311, 0.0535]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.8756, 1011.4848, 1011.6635, 1011.2935, 1009.9091]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0223, 0.3028, 0.3621, 0.2501, 0.0626]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.6600, 1011.3515, 1011.6007, 1011.3173, 1010.0159]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0189, 0.2793, 0.3584, 0.2699, 0.0735]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.3018, 1011.0786, 1011.4009, 1011.2083, 1009.9940]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0159, 0.2552, 0.3522, 0.2905, 0.0863]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.8610, 1010.7267, 1011.1258, 1011.0268, 1009.9041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0131, 0.2306, 0.3437, 0.3113, 0.1013]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.4019, 1010.3590, 1010.8378, 1010.8370, 1009.8101]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0107, 0.2059, 0.3324, 0.3321, 0.1189]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.9225, 1009.9760, 1010.5377, 1010.6385, 1009.7117]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0086, 0.1815, 0.3184, 0.3521, 0.1394]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.8632, 1011.4550, 1011.5850, 1011.1943, 1009.7737]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0236, 0.3154, 0.3592, 0.2430, 0.0587]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.5289, 1011.2023, 1011.4019, 1011.0977, 1009.7601]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0201, 0.2918, 0.3563, 0.2628, 0.0690]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.1303, 1010.8876, 1011.1605, 1010.9456, 1009.6954]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0170, 0.2673, 0.3512, 0.2833, 0.0812]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.7131, 1010.5588, 1010.9072, 1010.7856, 1009.6259]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0141, 0.2425, 0.3437, 0.3043, 0.0954]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.2776, 1010.2141, 1010.6421, 1010.6169, 1009.5518]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0115, 0.2174, 0.3336, 0.3253, 0.1121]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.8227, 1009.8539, 1010.3640, 1010.4397, 1009.4730]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0093, 0.1926, 0.3207, 0.3459, 0.1316]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.8350, 1011.4039, 1011.4811, 1011.0640, 1009.6018]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0253, 0.3296, 0.3561, 0.2347, 0.0544]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.4802, 1011.1292, 1011.2755, 1010.9426, 1009.5631]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0216, 0.3061, 0.3543, 0.2540, 0.0639]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.1077, 1010.8401, 1011.0582, 1010.8132, 1009.5194]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0183, 0.2818, 0.3504, 0.2743, 0.0752]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.7176, 1010.5359, 1010.8289, 1010.6758, 1009.4711]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0153, 0.2567, 0.3441, 0.2953, 0.0885]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.3090, 1010.2175, 1010.5877, 1010.5296, 1009.4178]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0126, 0.2316, 0.3353, 0.3164, 0.1041]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.8813, 1009.8831, 1010.3344, 1010.3749, 1009.3596]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0103, 0.2063, 0.3239, 0.3373, 0.1222]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.7593, 1011.2931, 1011.3061, 1010.8480, 1009.3305]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0276, 0.3480, 0.3525, 0.2230, 0.0489]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.4948, 1011.1081, 1011.1897, 1010.8156, 1009.3799]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0238, 0.3244, 0.3520, 0.2422, 0.0576]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1008.2120, 1010.9081, 1011.0610, 1010.7740, 1009.4228]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0202, 0.3000, 0.3495, 0.2623, 0.0679]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.8950, 1010.6760, 1010.9029, 1010.7061, 1009.4427]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0170, 0.2748, 0.3448, 0.2832, 0.0801]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.5175, 1010.3859, 1010.6884, 1010.5841, 1009.4112]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0142, 0.2496, 0.3377, 0.3043, 0.0942]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.1218, 1010.0810, 1010.4623, 1010.4536, 1009.3747]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0116, 0.2242, 0.3282, 0.3254, 0.1106]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.7068, 1009.7604, 1010.2234, 1010.3149, 1009.3337]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0094, 0.1988, 0.3159, 0.3462, 0.1298]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6863, 1010.2629, 1010.2773, 1009.8570, 1008.3589]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0262, 0.3441, 0.3491, 0.2293, 0.0513]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.4595, 1010.1151, 1010.1979, 1009.8612, 1008.4442]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0225, 0.3205, 0.3481, 0.2486, 0.0603]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.2144, 1009.9520, 1010.1054, 1009.8550, 1008.5223]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0192, 0.2961, 0.3452, 0.2687, 0.0709]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.9506, 1009.7726, 1009.9999, 1009.8398, 1008.5944]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0161, 0.2708, 0.3400, 0.2897, 0.0834]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.6671, 1009.5777, 1009.8812, 1009.8147, 1008.6605]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0134, 0.2453, 0.3323, 0.3109, 0.0980]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.3455, 1009.3484, 1009.7327, 1009.7637, 1008.7057]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0109, 0.2194, 0.3221, 0.3323, 0.1153]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.8740, 1009.4092, 1009.3549, 1008.8812, 1007.3134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) -0.5 tensor([[0.0289, 0.3651, 0.3458, 0.2153, 0.0449]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.7775, 1008.9543, 1009.4896, 1009.7040, 1008.8253]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0073, 0.1741, 0.2973, 0.3684, 0.1530]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.3198, 1009.0326, 1009.1313, 1008.8461, 1007.4617]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0207, 0.3117, 0.3441, 0.2587, 0.0648]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.0878, 1008.8834, 1009.0537, 1008.8555, 1007.5564]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0175, 0.2870, 0.3403, 0.2791, 0.0761]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.8373, 1008.7183, 1008.9633, 1008.8557, 1007.6447]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0147, 0.2616, 0.3342, 0.3001, 0.0894]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.5674, 1008.5377, 1008.8599, 1008.8459, 1007.7266]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0121, 0.2360, 0.3257, 0.3212, 0.1049]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.2784, 1008.3412, 1008.7434, 1008.8267, 1007.8030]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0098, 0.2105, 0.3147, 0.3421, 0.1229]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.3609, 1007.9434, 1007.9033, 1007.4706, 1005.9294]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) -0.5 tensor([[0.0271, 0.3580, 0.3440, 0.2232, 0.0478]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.7911, 1008.0261, 1008.5778, 1008.8431, 1007.9969]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0065, 0.1664, 0.2889, 0.3766, 0.1616]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.7546, 1007.5178, 1007.6335, 1007.3922, 1006.0365]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0191, 0.3035, 0.3407, 0.2677, 0.0690]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.5003, 1007.3481, 1007.5358, 1007.3827, 1006.1136]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0161, 0.2785, 0.3360, 0.2883, 0.0810]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.2252, 1007.1599, 1007.4229, 1007.3621, 1006.1819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0134, 0.2529, 0.3290, 0.3096, 0.0951]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.9678, 1006.9924, 1007.3331, 1007.3670, 1006.2789]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0110, 0.2273, 0.3196, 0.3306, 0.1114]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.3847, 1006.9458, 1006.8646, 1006.3956, 1004.8032]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) -0.5 tensor([[0.0287, 0.3713, 0.3423, 0.2142, 0.0436]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.5388, 1006.7297, 1007.2142, 1007.4240, 1006.5062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0075, 0.1829, 0.2970, 0.3663, 0.1463]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.7913, 1006.5208, 1006.5854, 1006.2944, 1004.8762]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0209, 0.3203, 0.3416, 0.2554, 0.0618]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.5479, 1006.3555, 1006.4870, 1006.2791, 1004.9406]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0179, 0.2967, 0.3384, 0.2749, 0.0721]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.2830, 1006.1712, 1006.3729, 1006.2496, 1004.9941]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0152, 0.2726, 0.3335, 0.2948, 0.0840]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.9960, 1005.9681, 1006.2415, 1006.2070, 1005.0378]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0127, 0.2482, 0.3262, 0.3151, 0.0979]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.5364, 1005.5970, 1005.9463, 1006.0058, 1004.9283]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0105, 0.2231, 0.3164, 0.3358, 0.1143]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.4679, 1006.0930, 1006.0461, 1005.6276, 1004.0716]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) -0.5 tensor([[0.0260, 0.3588, 0.3424, 0.2253, 0.0475]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.3998, 1004.6283, 1005.1188, 1005.3575, 1004.4556]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0071, 0.1790, 0.2923, 0.3711, 0.1506]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.9183, 1005.7082, 1005.8030, 1005.5587, 1004.1708]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0190, 0.3089, 0.3396, 0.2660, 0.0664]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.6835, 1005.5486, 1005.7088, 1005.5446, 1004.2338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0163, 0.2861, 0.3358, 0.2850, 0.0768]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.2050, 1005.1516, 1005.3804, 1005.3018, 1004.0758]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0138, 0.2623, 0.3297, 0.3048, 0.0894]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.6148, 1004.6466, 1004.9465, 1004.9591, 1003.8210]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0115, 0.2379, 0.3212, 0.3252, 0.1042]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.5784, 1005.1833, 1005.0918, 1004.6261, 1003.0218]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) -0.5 tensor([[0.0276, 0.3739, 0.3412, 0.2142, 0.0431]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.5893, 1003.7770, 1004.2072, 1004.3857, 1003.4094]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0081, 0.1957, 0.3009, 0.3598, 0.1355]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.0289, 1004.7866, 1004.8262, 1004.5206, 1003.0727]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0208, 0.3278, 0.3411, 0.2513, 0.0591]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1001.5827, 1004.4121, 1004.5125, 1004.2835, 1002.9095]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0181, 0.3061, 0.3385, 0.2692, 0.0681]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.0794, 1003.9845, 1004.1476, 1003.9977, 1002.7016]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0155, 0.2839, 0.3342, 0.2877, 0.0787]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.5332, 1003.5156, 1003.7435, 1003.6764, 1002.4606]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0132, 0.2611, 0.3280, 0.3067, 0.0909]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.9609, 1003.0230, 1003.3185, 1003.3364, 1002.2042]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0111, 0.2381, 0.3200, 0.3258, 0.1050]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.2646, 1003.8929, 1003.7950, 1003.3254, 1001.7186]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) -0.5 tensor([[0.0271, 0.3760, 0.3409, 0.2132, 0.0427]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.9700, 1002.1773, 1002.5944, 1002.7660, 1001.7844]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0080, 0.1986, 0.3014, 0.3578, 0.1341]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.2930, 1003.0704, 1003.0992, 1002.7875, 1001.3359]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0206, 0.3310, 0.3406, 0.2494, 0.0584]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.8403, 1002.6858, 1002.7717, 1002.5315, 1001.1500]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0180, 0.3106, 0.3384, 0.2661, 0.0669]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.3688, 1002.2846, 1002.4292, 1002.2626, 1000.9542]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0157, 0.2897, 0.3347, 0.2833, 0.0766]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.8779, 1001.8657, 1002.0714, 1001.9809, 1000.7464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0135, 0.2683, 0.3295, 0.3010, 0.0876]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.3589, 1001.4208, 1001.6895, 1001.6776, 1000.5210]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0115, 0.2466, 0.3227, 0.3188, 0.1003]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.8060, 1000.9447, 1001.2780, 1001.3472, 1000.2706]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0098, 0.2250, 0.3140, 0.3365, 0.1147]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.1926, 1000.9135, 1000.8738, 1000.4713,  998.9449]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) -0.5 tensor([[0.0234, 0.3560, 0.3421, 0.2288, 0.0497]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 996.8391, 1000.1167, 1000.5667, 1000.7822,  999.8492]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0071, 0.1881, 0.2950, 0.3659, 0.1439]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.2114, 1000.0753, 1000.1559,  999.9036,  998.5253]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0179, 0.3129, 0.3392, 0.2636, 0.0664]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.7831, 999.7103, 999.8453, 999.6599, 998.3475]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0157, 0.2937, 0.3362, 0.2793, 0.0752]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.3373, 999.3305, 999.5211, 999.4043, 998.1599]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0137, 0.2742, 0.3318, 0.2952, 0.0850]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.8741, 998.9347, 999.1821, 999.1365, 997.9622]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0119, 0.2545, 0.3259, 0.3114, 0.0962]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.3918, 998.5219, 998.8285, 998.8561, 997.7540]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0103, 0.2346, 0.3187, 0.3276, 0.1088]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.0947, 998.7943, 998.7166, 998.2565, 996.6866]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0249, 0.3707, 0.3429, 0.2165, 0.0450]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.5587, 997.8123, 998.2231, 998.3801, 997.4049]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0078, 0.2009, 0.3030, 0.3545, 0.1337]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.1851, 998.0133, 998.0448, 997.7200, 996.2843]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0196, 0.3317, 0.3424, 0.2474, 0.0589]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.8115, 997.6961, 997.7753, 997.5092, 996.1317]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0176, 0.3148, 0.3407, 0.2611, 0.0659]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.4221, 997.3638, 997.4918, 997.2867, 995.9688]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0157, 0.2974, 0.3380, 0.2753, 0.0737]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.0157, 997.0170, 997.1948, 997.0514, 995.7953]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0139, 0.2798, 0.3342, 0.2896, 0.0825]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.5920, 996.6533, 996.8832, 996.8040, 995.6102]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0123, 0.2617, 0.3294, 0.3043, 0.0922]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.1506, 996.2744, 996.5564, 996.5422, 995.4136]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0107, 0.2439, 0.3234, 0.3188, 0.1031]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.6909, 995.8788, 996.2156, 996.2690, 995.2068]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0093, 0.2258, 0.3162, 0.3335, 0.1153]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.9744, 996.7094, 996.6457, 996.1818, 994.6194]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0239, 0.3681, 0.3454, 0.2172, 0.0455]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.9667, 995.2646, 995.6953, 995.8636, 994.9146]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0072, 0.1961, 0.3016, 0.3569, 0.1382]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.2783, 996.1262, 996.1580, 995.8129, 994.3668]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0194, 0.3341, 0.3448, 0.2442, 0.0575]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.0211, 995.9167, 995.9891, 995.6944, 994.2968]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0177, 0.3196, 0.3436, 0.2559, 0.0633]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.7479, 995.6923, 995.8065, 995.5624, 994.2153]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0160, 0.3049, 0.3417, 0.2677, 0.0696]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.4156, 995.4106, 995.5677, 995.3768, 994.0816]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0145, 0.2897, 0.3390, 0.2801, 0.0767]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.0697, 995.1163, 995.3176, 995.1802, 993.9387]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0130, 0.2744, 0.3356, 0.2925, 0.0845]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.7086, 994.8080, 995.0549, 994.9729, 993.7856]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0117, 0.2588, 0.3313, 0.3052, 0.0931]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.3325, 994.4860, 994.7791, 994.7534, 993.6224]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0104, 0.2432, 0.3261, 0.3178, 0.1026]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.9401, 994.1497, 994.4900, 994.5225, 993.4490]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0092, 0.2276, 0.3199, 0.3304, 0.1129]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.1564, 994.9064, 994.8404, 994.3473, 992.7667]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0238, 0.3718, 0.3481, 0.2126, 0.0438]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.3367, 993.6401, 994.0603, 994.1904, 993.2130]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0074, 0.2022, 0.3078, 0.3506, 0.1319]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.6161, 994.4608, 994.4758, 994.0816, 992.5977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0200, 0.3433, 0.3485, 0.2350, 0.0533]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.4445, 994.3271, 994.3743, 994.0198, 992.5741]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0186, 0.3319, 0.3479, 0.2441, 0.0575]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.2621, 994.1830, 994.2638, 993.9489, 992.5424]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0173, 0.3202, 0.3471, 0.2534, 0.0621]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.0688, 994.0289, 994.1433, 993.8693, 992.5026]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0160, 0.3084, 0.3457, 0.2629, 0.0670]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.8641, 993.8644, 994.0131, 993.7811, 992.4544]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0147, 0.2964, 0.3439, 0.2727, 0.0724]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.6473, 993.6887, 993.8724, 993.6826, 992.3981]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0136, 0.2842, 0.3415, 0.2825, 0.0782]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.3807, 993.4642, 993.6843, 993.5384, 992.2969]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0124, 0.2717, 0.3386, 0.2927, 0.0846]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.0974, 993.2242, 993.4820, 993.3801, 992.1837]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0114, 0.2591, 0.3353, 0.3028, 0.0915]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.8024, 992.9736, 993.2692, 993.2134, 992.0619]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0103, 0.2464, 0.3311, 0.3132, 0.0990]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.4952, 992.7114, 993.0457, 993.0373, 991.9321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0094, 0.2336, 0.3263, 0.3236, 0.1072]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.1752, 992.4374, 992.8121, 992.8511, 991.7937]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0085, 0.2207, 0.3210, 0.3338, 0.1160]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.4902, 993.2922, 993.2581, 992.7673, 991.2032]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0221, 0.3646, 0.3524, 0.2157, 0.0451]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.7313, 992.0676, 992.5057, 992.6200, 991.6376]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0072, 0.2011, 0.3116, 0.3493, 0.1308]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.0963, 992.9697, 992.9982, 992.5818, 991.0895]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0194, 0.3429, 0.3528, 0.2326, 0.0523]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.0095, 992.9085, 992.9593, 992.5698, 991.1023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0185, 0.3351, 0.3526, 0.2388, 0.0550]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.9164, 992.8414, 992.9149, 992.5520, 991.1094]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0176, 0.3273, 0.3522, 0.2450, 0.0579]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.8165, 992.7678, 992.8647, 992.5285, 991.1115]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0167, 0.3193, 0.3518, 0.2513, 0.0609]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[989.7098, 992.6876, 992.8079, 992.4990, 991.1082]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0158, 0.3112, 0.3510, 0.2578, 0.0641]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.5969, 992.6019, 992.7465, 992.4661, 991.1022]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0150, 0.3029, 0.3500, 0.2644, 0.0676]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.4169, 992.4500, 992.6188, 992.3667, 991.0317]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0142, 0.2946, 0.3488, 0.2711, 0.0713]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.1999, 992.2618, 992.4557, 992.2332, 990.9277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0134, 0.2860, 0.3473, 0.2780, 0.0753]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.9778, 992.0692, 992.2882, 992.0955, 990.8203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0126, 0.2775, 0.3454, 0.2849, 0.0796]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.7505, 991.8711, 992.1165, 991.9538, 990.7096]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0119, 0.2687, 0.3435, 0.2919, 0.0841]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.5176, 991.6683, 991.9395, 991.8077, 990.5948]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0111, 0.2600, 0.3410, 0.2989, 0.0889]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.2783, 991.4600, 991.7583, 991.6578, 990.4765]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0104, 0.2511, 0.3384, 0.3061, 0.0939]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.0334, 991.2460, 991.5718, 991.5033, 990.3544]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0097, 0.2422, 0.3355, 0.3133, 0.0993]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.7819, 991.0263, 991.3797, 991.3438, 990.2282]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0091, 0.2333, 0.3322, 0.3205, 0.1050]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.5237, 990.8007, 991.1824, 991.1796, 990.0977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0085, 0.2243, 0.3285, 0.3276, 0.1111]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.2583, 990.5690, 990.9797, 991.0110, 989.9634]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0079, 0.2152, 0.3245, 0.3349, 0.1175]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.3337, 991.1575, 991.1365, 990.6152, 989.0466]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0217, 0.3648, 0.3572, 0.2121, 0.0442]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.9086, 990.2642, 990.7159, 990.7928, 989.7924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0071, 0.2030, 0.3189, 0.3444, 0.1266]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.0121, 990.8807, 990.9000, 990.4253, 988.9026]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0199, 0.3510, 0.3579, 0.2226, 0.0486]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.8904, 990.7736, 990.8058, 990.3438, 988.8349]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0194, 0.3468, 0.3582, 0.2257, 0.0499]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.7703, 990.6671, 990.7117, 990.2626, 988.7670]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0189, 0.3427, 0.3584, 0.2287, 0.0513]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.6306, 990.5416, 990.5981, 990.1621, 988.6804]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0184, 0.3387, 0.3584, 0.2318, 0.0527]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.4707, 990.3952, 990.4643, 990.0402, 988.5724]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0180, 0.3347, 0.3586, 0.2347, 0.0541]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.3126, 990.2507, 990.3312, 989.9200, 988.4653]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0175, 0.3308, 0.3585, 0.2377, 0.0555]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.1557, 990.1078, 990.2002, 989.8002, 988.3586]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0171, 0.3270, 0.3587, 0.2404, 0.0569]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.0007, 989.9659, 990.0699, 989.6819, 988.2527]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0167, 0.3232, 0.3586, 0.2433, 0.0583]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.8480, 989.8259, 989.9412, 989.5640, 988.1475]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0163, 0.3196, 0.3586, 0.2459, 0.0596]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.7037, 989.6930, 989.8191, 989.4524, 988.0476]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0159, 0.3161, 0.3586, 0.2485, 0.0610]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.5606, 989.5620, 989.6989, 989.3420, 987.9481]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0155, 0.3127, 0.3586, 0.2509, 0.0623]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.4191, 989.4319, 989.5784, 989.2320, 987.8492]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0152, 0.3095, 0.3583, 0.2534, 0.0636]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.2784, 989.3024, 989.4589, 989.1219, 987.7502]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0149, 0.3063, 0.3582, 0.2557, 0.0649]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.1387, 989.1736, 989.3401, 989.0124, 987.6512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0146, 0.3032, 0.3581, 0.2580, 0.0661]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.9902, 989.0363, 989.2132, 988.8954, 987.5446]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0143, 0.2999, 0.3579, 0.2605, 0.0675]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.8051, 988.8638, 989.0521, 988.7444, 987.4060]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0139, 0.2964, 0.3578, 0.2630, 0.0690]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.5566, 988.6259, 988.8249, 988.5267, 987.2002]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0136, 0.2930, 0.3576, 0.2654, 0.0704]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.3104, 988.3899, 988.5998, 988.3104, 986.9946]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0133, 0.2898, 0.3575, 0.2676, 0.0718]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.0683, 988.1586, 988.3791, 988.0988, 986.7950]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0130, 0.2866, 0.3572, 0.2699, 0.0733]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[984.8284, 987.9288, 988.1595, 987.8881, 986.5959]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0128, 0.2834, 0.3570, 0.2721, 0.0747]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[984.5897, 987.7011, 987.9419, 987.6791, 986.3981]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0125, 0.2804, 0.3567, 0.2743, 0.0762]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[984.3541, 987.4749, 987.7254, 987.4711, 986.2010]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0122, 0.2774, 0.3564, 0.2764, 0.0776]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[984.1201, 987.2505, 987.5112, 987.2644, 986.0046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0120, 0.2745, 0.3562, 0.2783, 0.0790]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[983.8887, 987.0281, 987.2981, 987.0591, 985.8097]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0118, 0.2717, 0.3559, 0.2803, 0.0803]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[983.6599, 986.8081, 987.0873, 986.8553, 985.6159]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0115, 0.2690, 0.3557, 0.2821, 0.0817]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[983.4332, 986.5901, 986.8786, 986.6533, 985.4232]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0113, 0.2664, 0.3555, 0.2838, 0.0829]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[983.2090, 986.3743, 986.6710, 986.4528, 985.2313]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0111, 0.2640, 0.3552, 0.2855, 0.0842]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[982.9742, 986.1474, 986.4523, 986.2405, 985.0285]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0110, 0.2616, 0.3549, 0.2871, 0.0854]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[982.7247, 985.9056, 986.2192, 986.0134, 984.8106]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0108, 0.2592, 0.3547, 0.2887, 0.0867]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[982.4790, 985.6672, 985.9894, 985.7889, 984.5944]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0106, 0.2569, 0.3545, 0.2901, 0.0879]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[982.2114, 985.4064, 985.7360, 985.5414, 984.3550]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0104, 0.2548, 0.3542, 0.2916, 0.0890]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[981.8981, 985.0987, 985.4359, 985.2463, 984.0678]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0103, 0.2527, 0.3540, 0.2929, 0.0901]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[981.5721, 984.7781, 985.1214, 984.9365, 983.7654]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0102, 0.2509, 0.3537, 0.2940, 0.0912]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[981.1620, 984.3687, 984.7150, 984.5313, 983.3647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2502, 0.3537, 0.2943, 0.0917]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[980.7579, 983.9647, 984.3126, 984.1296, 982.9662]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2497, 0.3536, 0.2945, 0.0920]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[980.3582, 983.5644, 983.9147, 983.7315, 982.5710]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2492, 0.3538, 0.2946, 0.0923]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.9644, 983.1694, 983.5207, 983.3371, 982.1790]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2490, 0.3539, 0.2945, 0.0925]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.5756, 982.7794, 983.1315, 982.9468, 981.7903]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2490, 0.3540, 0.2943, 0.0926]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.1918, 982.3940, 982.7468, 982.5604, 981.4055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2489, 0.3543, 0.2940, 0.0926]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[978.7916, 981.9915, 982.3445, 982.1564, 981.0026]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0102, 0.2490, 0.3545, 0.2937, 0.0926]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[978.3829, 981.5801, 981.9330, 981.7425, 980.5898]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0102, 0.2493, 0.3547, 0.2932, 0.0926]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[977.9803, 981.1743, 981.5269, 981.3333, 980.1806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0102, 0.2496, 0.3551, 0.2926, 0.0924]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[977.5837, 980.7737, 981.1259, 980.9285, 979.7759]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0103, 0.2500, 0.3556, 0.2919, 0.0922]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[977.1937, 980.3798, 980.7302, 980.5287, 979.3754]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0104, 0.2508, 0.3560, 0.2910, 0.0918]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[976.8106, 979.9919, 980.3401, 980.1346, 978.9795]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0104, 0.2516, 0.3564, 0.2902, 0.0914]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[976.4343, 979.6102, 979.9567, 979.7457, 978.5888]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0105, 0.2524, 0.3570, 0.2891, 0.0909]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[976.0660, 979.2360, 979.5792, 979.3623, 978.2028]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0107, 0.2537, 0.3576, 0.2878, 0.0903]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[975.7050, 978.8684, 979.2089, 978.9851, 977.8223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0108, 0.2549, 0.3583, 0.2865, 0.0895]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[975.3522, 978.5087, 978.8448, 978.6139, 977.4473]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0109, 0.2565, 0.3589, 0.2849, 0.0887]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[975.0076, 978.1562, 978.4880, 978.2495, 977.0779]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0111, 0.2581, 0.3597, 0.2833, 0.0878]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[974.6724, 977.8124, 978.1393, 977.8916, 976.7149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0113, 0.2600, 0.3605, 0.2814, 0.0868]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[974.3457, 977.4766, 977.7977, 977.5411, 976.3583]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0114, 0.2621, 0.3613, 0.2795, 0.0857]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[974.0288, 977.1502, 977.4650, 977.1984, 976.0082]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0117, 0.2644, 0.3622, 0.2774, 0.0844]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[973.7218, 976.8326, 977.1404, 976.8625, 975.6647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0119, 0.2669, 0.3631, 0.2750, 0.0830]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[973.4262, 976.5259, 976.8263, 976.5373, 975.3306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0121, 0.2696, 0.3640, 0.2727, 0.0816]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[973.1436, 976.2311, 976.5241, 976.2225, 975.0071]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0124, 0.2724, 0.3651, 0.2700, 0.0801]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.8719, 975.9478, 976.2316, 975.9174, 974.6917]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0127, 0.2755, 0.3660, 0.2673, 0.0785]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.6122, 975.6743, 975.9491, 975.6207, 974.3845]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0130, 0.2788, 0.3670, 0.2643, 0.0768]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.3644, 975.4125, 975.6769, 975.3338, 974.0855]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0134, 0.2825, 0.3680, 0.2611, 0.0749]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.1292, 975.1622, 975.4156, 975.0568, 973.7960]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0138, 0.2864, 0.3690, 0.2577, 0.0731]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.9073, 974.9241, 975.1661, 974.7904, 973.5153]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0142, 0.2905, 0.3701, 0.2542, 0.0710]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.6991, 974.6991, 974.9279, 974.5344, 973.2443]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0147, 0.2951, 0.3710, 0.2503, 0.0689]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.5052, 974.4871, 974.7026, 974.2897, 972.9834]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0152, 0.2999, 0.3720, 0.2462, 0.0667]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.3264, 974.2891, 974.4896, 974.0571, 972.7332]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0158, 0.3051, 0.3728, 0.2419, 0.0644]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.1627, 974.1052, 974.2903, 973.8365, 972.4940]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0164, 0.3105, 0.3737, 0.2374, 0.0620]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.0148, 973.9361, 974.1050, 973.6284, 972.2659]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0170, 0.3163, 0.3745, 0.2325, 0.0595]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.8845, 973.7831, 973.9341, 973.4337, 972.0504]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0178, 0.3226, 0.3752, 0.2274, 0.0570]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.7712, 973.6459, 973.7783, 973.2528, 971.8467]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0186, 0.3291, 0.3757, 0.2221, 0.0544]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.6761, 973.5261, 973.6388, 973.0862, 971.6562]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0194, 0.3361, 0.3762, 0.2165, 0.0518]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.5999, 973.4234, 973.5151, 972.9348, 971.4790]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0204, 0.3434, 0.3764, 0.2107, 0.0491]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.5439, 973.3397, 973.4090, 972.7989, 971.3160]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0214, 0.3512, 0.3764, 0.2045, 0.0464]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.5078, 973.2745, 973.3206, 972.6791, 971.1675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0226, 0.3593, 0.3763, 0.1981, 0.0437]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.4933, 973.2296, 973.2502, 972.5762, 971.0345]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0239, 0.3680, 0.3757, 0.1915, 0.0410]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.5009, 973.2055, 973.1996, 972.4915, 970.9175]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0252, 0.3770, 0.3748, 0.1846, 0.0383]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.5464, 972.8216, 973.3297, 973.2435, 972.2731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0079, 0.2082, 0.3461, 0.3175, 0.1203]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.2856, 972.5471, 973.0455, 972.9451, 971.9639]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0081, 0.2113, 0.3479, 0.3147, 0.1180]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.0357, 972.2828, 972.7708, 972.6561, 971.6624]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0083, 0.2147, 0.3497, 0.3118, 0.1154]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.7969, 972.0289, 972.5061, 972.3756, 971.3693]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0086, 0.2182, 0.3517, 0.3087, 0.1128]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.5694, 971.7853, 972.2509, 972.1046, 971.0852]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0089, 0.2219, 0.3535, 0.3054, 0.1102]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.3538, 971.5533, 972.0069, 971.8436, 970.8099]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0092, 0.2259, 0.3555, 0.3020, 0.1074]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.1497, 971.3321, 971.7734, 971.5923, 970.5438]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0095, 0.2300, 0.3576, 0.2983, 0.1046]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.9587, 971.1233, 971.5510, 971.3519, 970.2873]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0099, 0.2344, 0.3595, 0.2946, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.7807, 970.9267, 971.3403, 971.1220, 970.0406]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0103, 0.2390, 0.3615, 0.2906, 0.0985]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.6167, 970.7430, 971.1415, 970.9031, 969.8040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0107, 0.2440, 0.3635, 0.2864, 0.0954]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.4661, 970.5724, 970.9553, 970.6959, 969.5780]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0112, 0.2492, 0.3655, 0.2820, 0.0922]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.3190, 970.4037, 970.7699, 970.4874, 969.3494]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0117, 0.2549, 0.3676, 0.2771, 0.0888]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.1475, 970.2081, 970.5544, 970.2468, 969.0858]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0122, 0.2614, 0.3696, 0.2717, 0.0851]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.9921, 970.0279, 970.3531, 970.0189, 968.8339]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0129, 0.2684, 0.3715, 0.2659, 0.0813]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.8531, 969.8628, 970.1663, 969.8044, 968.5943]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0136, 0.2756, 0.3733, 0.2600, 0.0775]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.7311, 969.7131, 969.9947, 969.6036, 968.3673]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0144, 0.2831, 0.3751, 0.2537, 0.0737]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.6270, 969.5808, 969.8386, 969.4175, 968.1537]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0152, 0.2911, 0.3767, 0.2472, 0.0699]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.5411, 969.4658, 969.6990, 969.2466, 967.9536]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0161, 0.2994, 0.3780, 0.2405, 0.0660]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.4594, 969.3539, 969.5616, 969.0770, 967.7540]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0170, 0.3081, 0.3792, 0.2335, 0.0622]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.3857, 969.2496, 969.4312, 968.9130, 967.5591]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0181, 0.3170, 0.3801, 0.2264, 0.0585]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.3325, 969.1638, 969.3188, 968.7663, 967.3795]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0192, 0.3261, 0.3808, 0.2191, 0.0548]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.3013, 969.0989, 969.2253, 968.6363, 967.2148]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0205, 0.3359, 0.3811, 0.2115, 0.0510]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.2913, 969.0544, 969.1510, 968.5245, 967.0672]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0218, 0.3460, 0.3811, 0.2037, 0.0474]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.3053, 969.0320, 969.0977, 968.4316, 966.9368]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0233, 0.3565, 0.3807, 0.1956, 0.0439]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.3430, 969.0317, 969.0650, 968.3577, 966.8237]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0250, 0.3675, 0.3799, 0.1873, 0.0404]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.4059, 969.0549, 969.0544, 968.3038, 966.7285]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0268, 0.3788, 0.3786, 0.1788, 0.0370]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.7581, 968.9621, 969.4592, 969.3159, 968.3300]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0087, 0.2155, 0.3543, 0.3070, 0.1145]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.5704, 968.7527, 969.2328, 969.0666, 968.0602]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0092, 0.2209, 0.3571, 0.3024, 0.1105]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.3911, 968.5519, 969.0136, 968.8246, 967.7971]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0096, 0.2266, 0.3596, 0.2977, 0.1065]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.2264, 968.3640, 968.8077, 968.5944, 967.5449]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2325, 0.3623, 0.2927, 0.1025]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.0762, 968.1902, 968.6145, 968.3765, 967.3043]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0106, 0.2387, 0.3648, 0.2875, 0.0984]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.9417, 968.0312, 968.4355, 968.1716, 967.0754]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0112, 0.2452, 0.3673, 0.2821, 0.0943]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[964.8224, 967.8870, 968.2705, 967.9796, 966.8585]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0118, 0.2520, 0.3698, 0.2764, 0.0901]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.7197, 967.7581, 968.1199, 967.8012, 966.6541]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0124, 0.2591, 0.3721, 0.2705, 0.0859]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.6340, 967.6454, 967.9846, 967.6367, 966.4626]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0131, 0.2666, 0.3743, 0.2643, 0.0817]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.5656, 967.5488, 967.8648, 967.4871, 966.2844]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0139, 0.2744, 0.3763, 0.2579, 0.0775]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.5153, 967.4691, 967.7610, 967.3518, 966.1201]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0147, 0.2825, 0.3783, 0.2512, 0.0733]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.4839, 967.4078, 967.6737, 967.2320, 965.9698]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0156, 0.2912, 0.3798, 0.2442, 0.0691]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.4720, 967.3643, 967.6036, 967.1284, 965.8339]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0166, 0.3001, 0.3812, 0.2371, 0.0650]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.4803, 967.3400, 967.5519, 967.0419, 965.7133]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0177, 0.3094, 0.3824, 0.2296, 0.0608]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.5094, 967.3354, 967.5187, 966.9714, 965.6086]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0189, 0.3192, 0.3834, 0.2218, 0.0568]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.5605, 967.3510, 967.5043, 966.9192, 965.5198]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0202, 0.3293, 0.3839, 0.2138, 0.0528]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.6342, 967.3884, 967.5102, 966.8858, 965.4482]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0216, 0.3399, 0.3840, 0.2056, 0.0488]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.7311, 967.4471, 967.5361, 966.8714, 965.3936]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0232, 0.3509, 0.3836, 0.1973, 0.0450]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.8246, 967.5004, 967.5549, 966.8459, 965.3265]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0250, 0.3625, 0.3828, 0.1884, 0.0412]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.9263, 967.5593, 967.5768, 966.8225, 965.2590]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0269, 0.3748, 0.3814, 0.1794, 0.0376]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.0544, 967.6429, 967.6218, 966.8207, 965.2111]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0291, 0.3874, 0.3793, 0.1702, 0.0340]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.5640, 967.7079, 968.1852, 967.9897, 966.9674]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0097, 0.2244, 0.3616, 0.2974, 0.1070]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.4807, 967.5999, 968.0571, 967.8353, 966.7891]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0102, 0.2308, 0.3645, 0.2920, 0.1026]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.4123, 967.5063, 967.9425, 967.6943, 966.6227]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0108, 0.2374, 0.3672, 0.2865, 0.0981]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.3600, 967.4274, 967.8421, 967.5663, 966.4685]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0114, 0.2443, 0.3699, 0.2807, 0.0937]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.3235, 967.3641, 967.7565, 967.4523, 966.3271]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0120, 0.2516, 0.3725, 0.2748, 0.0892]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.3041, 967.3167, 967.6858, 967.3518, 966.1985]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0127, 0.2592, 0.3749, 0.2684, 0.0847]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.3021, 967.2863, 967.6312, 967.2664, 966.0840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0135, 0.2671, 0.3772, 0.2619, 0.0803]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.3179, 967.2726, 967.5925, 967.1961, 965.9834]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0143, 0.2754, 0.3792, 0.2551, 0.0759]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.3528, 967.2764, 967.5703, 967.1415, 965.8969]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0153, 0.2840, 0.3810, 0.2482, 0.0715]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.4068, 967.2986, 967.5659, 967.1026, 965.8250]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0163, 0.2930, 0.3828, 0.2408, 0.0671]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.4811, 967.3404, 967.5791, 967.0806, 965.7690]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0173, 0.3025, 0.3840, 0.2333, 0.0628]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.5762, 967.4011, 967.6110, 967.0760, 965.7286]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0185, 0.3122, 0.3851, 0.2255, 0.0586]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.6929, 967.4824, 967.6620, 967.0889, 965.7046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0198, 0.3224, 0.3858, 0.2175, 0.0545]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.8043, 967.5561, 967.7033, 967.0903, 965.6665]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0213, 0.3332, 0.3861, 0.2091, 0.0504]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.9277, 967.6400, 967.7532, 967.0986, 965.6344]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0229, 0.3445, 0.3858, 0.2005, 0.0464]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.0755, 967.7468, 967.8250, 967.1266, 965.6201]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0246, 0.3562, 0.3851, 0.1916, 0.0425]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.2486, 967.8776, 967.9186, 967.1759, 965.6249]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0266, 0.3683, 0.3838, 0.1826, 0.0387]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.4478, 968.0328, 968.0361, 967.2465, 965.6496]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0287, 0.3807, 0.3820, 0.1734, 0.0351]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.6741, 968.2141, 968.1779, 967.3394, 965.6949]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0310, 0.3936, 0.3796, 0.1641, 0.0317]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.8868, 967.9915, 968.4614, 968.2374, 967.1891]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0103, 0.2287, 0.3660, 0.2925, 0.1025]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.9061, 967.9849, 968.4329, 968.1808, 967.1062]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0108, 0.2357, 0.3689, 0.2867, 0.0979]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.9404, 967.9922, 968.4178, 968.1376, 967.0350]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0115, 0.2428, 0.3716, 0.2808, 0.0932]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[964.9909, 968.0148, 968.4171, 968.1074, 966.9766]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0122, 0.2503, 0.3743, 0.2746, 0.0886]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.0576, 968.0530, 968.4312, 968.0911, 966.9306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0129, 0.2581, 0.3768, 0.2681, 0.0840]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.1409, 968.1068, 968.4601, 968.0889, 966.8984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0137, 0.2662, 0.3790, 0.2615, 0.0795]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.2418, 968.1770, 968.5051, 968.1015, 966.8789]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0146, 0.2746, 0.3812, 0.2546, 0.0750]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.3608, 968.2648, 968.5660, 968.1293, 966.8741]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0155, 0.2834, 0.3830, 0.2475, 0.0705]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.4982, 968.3701, 968.6437, 968.1725, 966.8835]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0166, 0.2926, 0.3846, 0.2401, 0.0662]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.6447, 968.4831, 968.7280, 968.2209, 966.8970]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0177, 0.3021, 0.3859, 0.2324, 0.0618]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.7985, 968.6017, 968.8166, 968.2720, 966.9111]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0189, 0.3121, 0.3869, 0.2245, 0.0576]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[965.9706, 968.7371, 968.9211, 968.3378, 966.9389]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0203, 0.3224, 0.3876, 0.2163, 0.0534]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.1569, 968.8857, 969.0372, 968.4139, 966.9753]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0218, 0.3333, 0.3878, 0.2079, 0.0493]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.3354, 969.0246, 969.1411, 968.4756, 966.9954]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0234, 0.3448, 0.3874, 0.1991, 0.0453]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.5013, 969.1490, 969.2307, 968.5213, 966.9987]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0252, 0.3563, 0.3867, 0.1902, 0.0415]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.6611, 969.2668, 969.3116, 968.5576, 966.9911]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0272, 0.3684, 0.3853, 0.1813, 0.0378]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.8409, 969.4022, 969.4092, 968.6088, 966.9966]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0294, 0.3807, 0.3834, 0.1722, 0.0343]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.0403, 969.5562, 969.5244, 968.6757, 967.0162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0318, 0.3932, 0.3810, 0.1630, 0.0310]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.1462, 969.2386, 969.7225, 969.4996, 968.4472]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0103, 0.2263, 0.3671, 0.2938, 0.1026]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.2408, 969.3068, 969.7687, 969.5185, 968.4395]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0109, 0.2331, 0.3700, 0.2881, 0.0979]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.3355, 969.3752, 969.8149, 969.5365, 968.4300]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0115, 0.2402, 0.3728, 0.2822, 0.0933]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.4440, 969.4559, 969.8723, 969.5651, 968.4301]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0122, 0.2475, 0.3754, 0.2761, 0.0887]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.5654, 969.5493, 969.9417, 969.6049, 968.4407]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0129, 0.2552, 0.3778, 0.2698, 0.0842]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.7006, 969.6551, 970.0233, 969.6559, 968.4612]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0137, 0.2631, 0.3802, 0.2633, 0.0797]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[966.8499, 969.7749, 970.1180, 969.7183, 968.4926]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0146, 0.2713, 0.3824, 0.2564, 0.0753]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.0149, 969.9087, 970.2250, 969.7932, 968.5350]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0155, 0.2800, 0.3842, 0.2495, 0.0709]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.1663, 970.0287, 970.3184, 969.8532, 968.5622]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0165, 0.2888, 0.3858, 0.2423, 0.0666]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.3156, 970.1458, 970.4081, 969.9084, 968.5835]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0176, 0.2979, 0.3872, 0.2349, 0.0624]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.4791, 970.2757, 970.5099, 969.9748, 968.6150]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0187, 0.3072, 0.3883, 0.2274, 0.0584]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.6578, 970.4197, 970.6247, 970.0527, 968.6563]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0200, 0.3170, 0.3891, 0.2196, 0.0543]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[967.8516, 970.5777, 970.7523, 970.1425, 968.7082]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0214, 0.3271, 0.3894, 0.2116, 0.0504]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.0613, 970.7505, 970.8935, 970.2446, 968.7715]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0229, 0.3375, 0.3894, 0.2035, 0.0466]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.2880, 970.9385, 971.0490, 970.3592, 968.8461]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0246, 0.3483, 0.3890, 0.1951, 0.0430]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.5312, 971.1426, 971.2193, 970.4869, 968.9318]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0264, 0.3595, 0.3881, 0.1866, 0.0394]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.7928, 971.3633, 971.4050, 970.6288, 969.0302]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0284, 0.3710, 0.3867, 0.1780, 0.0360]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.0831, 971.6113, 971.6170, 970.7957, 969.1523]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0305, 0.3826, 0.3848, 0.1693, 0.0327]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.3999, 971.8845, 971.8528, 970.9851, 969.2955]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0329, 0.3946, 0.3823, 0.1605, 0.0296]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.1814, 971.2399, 971.7204, 971.4771, 970.3991]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0108, 0.2292, 0.3706, 0.2906, 0.0989]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.3306, 971.3638, 971.8228, 971.5528, 970.4486]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0114, 0.2359, 0.3733, 0.2850, 0.0945]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.4895, 971.4961, 971.9334, 971.6365, 970.5045]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0120, 0.2427, 0.3759, 0.2793, 0.0900]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.6581, 971.6381, 972.0526, 971.7276, 970.5677]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0127, 0.2499, 0.3783, 0.2734, 0.0857]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[968.8366, 971.7896, 972.1809, 971.8271, 970.6381]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0134, 0.2574, 0.3806, 0.2672, 0.0814]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.0259, 971.9505, 972.3183, 971.9354, 970.7162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0142, 0.2650, 0.3827, 0.2610, 0.0771]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.2266, 972.1221, 972.4653, 972.0515, 970.8020]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0151, 0.2729, 0.3847, 0.2544, 0.0729]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.4384, 972.3040, 972.6221, 972.1772, 970.8953]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0160, 0.2811, 0.3865, 0.2477, 0.0687]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.6619, 972.4969, 972.7894, 972.3121, 970.9977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0170, 0.2896, 0.3880, 0.2407, 0.0647]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[969.8983, 972.7020, 972.9669, 972.4566, 971.1085]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0181, 0.2986, 0.3891, 0.2336, 0.0607]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.1470, 972.9185, 973.1561, 972.6107, 971.2282]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0192, 0.3077, 0.3902, 0.2261, 0.0568]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.4097, 973.1475, 973.3564, 972.7759, 971.3572]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0205, 0.3171, 0.3908, 0.2187, 0.0529]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.6864, 973.3893, 973.5686, 972.9512, 971.4957]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0219, 0.3269, 0.3911, 0.2109, 0.0492]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.9776, 973.6448, 973.7936, 973.1382, 971.6441]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0234, 0.3370, 0.3910, 0.2030, 0.0456]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.2933, 973.9241, 974.0414, 973.3473, 971.8137]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0250, 0.3473, 0.3905, 0.1951, 0.0421]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.6307, 974.2233, 974.3085, 973.5739, 971.9995]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0268, 0.3579, 0.3897, 0.1869, 0.0387]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.9810, 974.5350, 974.5867, 973.8113, 972.1951]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0287, 0.3687, 0.3883, 0.1788, 0.0355]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.3782, 974.8936, 974.9120, 974.0946, 972.4363]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0307, 0.3795, 0.3866, 0.1707, 0.0325]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.8082, 975.2833, 975.2676, 974.4073, 972.7058]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0329, 0.3905, 0.3844, 0.1626, 0.0297]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.5745, 973.6368, 974.1448, 973.9213, 972.8580]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0104, 0.2224, 0.3696, 0.2956, 0.1021]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.7592, 973.7982, 974.2870, 974.0397, 972.9517]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0109, 0.2283, 0.3722, 0.2907, 0.0979]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[970.9523, 973.9681, 974.4368, 974.1651, 973.0519]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0115, 0.2345, 0.3747, 0.2855, 0.0938]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.1547, 974.1462, 974.5948, 974.2982, 973.1591]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0121, 0.2408, 0.3771, 0.2803, 0.0897]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.3663, 974.3329, 974.7607, 974.4387, 973.2731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0127, 0.2473, 0.3793, 0.2749, 0.0857]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.5872, 974.5287, 974.9357, 974.5867, 973.3945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0134, 0.2540, 0.3816, 0.2692, 0.0817]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[971.8181, 974.7341, 975.1185, 974.7433, 973.5233]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0141, 0.2611, 0.3835, 0.2635, 0.0778]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.0591, 974.9489, 975.3112, 974.9077, 973.6594]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0149, 0.2683, 0.3854, 0.2575, 0.0739]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.3113, 975.1736, 975.5129, 975.0812, 973.8035]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0158, 0.2757, 0.3871, 0.2514, 0.0701]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.5744, 975.4089, 975.7242, 975.2632, 973.9554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0167, 0.2835, 0.3885, 0.2451, 0.0663]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[972.8490, 975.6548, 975.9459, 975.4544, 974.1158]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0176, 0.2914, 0.3899, 0.2385, 0.0625]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[973.1492, 975.9260, 976.1926, 975.6705, 974.3001]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0186, 0.2995, 0.3910, 0.2320, 0.0589]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[973.4810, 976.2285, 976.4700, 975.9172, 974.5151]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0197, 0.3077, 0.3918, 0.2254, 0.0555]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[973.8258, 976.5436, 976.7592, 976.1744, 974.7391]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0209, 0.3162, 0.3923, 0.2186, 0.0520]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[974.1848, 976.8715, 977.0602, 976.4420, 974.9737]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0221, 0.3250, 0.3926, 0.2115, 0.0487]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[974.5668, 977.2219, 977.3839, 976.7318, 975.2283]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0235, 0.3339, 0.3926, 0.2045, 0.0455]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[974.9661, 977.5881, 977.7224, 977.0350, 975.4959]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0249, 0.3431, 0.3924, 0.1973, 0.0423]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[975.3808, 977.9694, 978.0745, 977.3506, 975.7748]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0265, 0.3526, 0.3917, 0.1899, 0.0393]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[975.8121, 978.3655, 978.4404, 977.6795, 976.0649]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0282, 0.3624, 0.3906, 0.1825, 0.0363]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[976.2604, 978.7779, 978.8220, 978.0217, 976.3675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0300, 0.3724, 0.3892, 0.1748, 0.0334]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[976.7265, 979.2066, 979.2186, 978.3778, 976.6827]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0321, 0.3828, 0.3874, 0.1671, 0.0307]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[977.2115, 979.6527, 979.6311, 978.7488, 977.0111]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0342, 0.3934, 0.3850, 0.1593, 0.0280]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[974.5674, 977.5868, 978.0801, 977.8298, 976.7220]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0111, 0.2282, 0.3737, 0.2909, 0.0961]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[974.8121, 977.8100, 978.2859, 978.0132, 976.8831]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0117, 0.2336, 0.3760, 0.2863, 0.0925]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[975.0638, 978.0404, 978.4979, 978.2033, 977.0493]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0122, 0.2393, 0.3781, 0.2816, 0.0888]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[975.3327, 978.2875, 978.7272, 978.4098, 977.2324]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0128, 0.2449, 0.3802, 0.2768, 0.0853]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[975.6243, 978.5578, 978.9794, 978.6394, 977.4384]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0133, 0.2507, 0.3821, 0.2720, 0.0818]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[975.9242, 978.8358, 979.2386, 978.8754, 977.6508]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0140, 0.2566, 0.3840, 0.2670, 0.0785]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[976.2321, 979.1214, 979.5049, 979.1186, 977.8691]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0146, 0.2627, 0.3856, 0.2620, 0.0751]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[976.5487, 979.4152, 979.7795, 979.3685, 978.0937]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0153, 0.2690, 0.3872, 0.2567, 0.0717]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[976.8743, 979.7175, 980.0615, 979.6258, 978.3253]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0160, 0.2755, 0.3886, 0.2514, 0.0685]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[977.2101, 980.0284, 980.3520, 979.8907, 978.5635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0168, 0.2821, 0.3900, 0.2459, 0.0652]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[977.5109, 980.3040, 980.6058, 980.1174, 978.7625]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0177, 0.2892, 0.3912, 0.2400, 0.0619]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[977.8197, 980.5860, 980.8657, 980.3491, 978.9662]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0186, 0.2965, 0.3922, 0.2340, 0.0587]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[978.1376, 980.8768, 981.1334, 980.5883, 979.1761]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0196, 0.3040, 0.3930, 0.2278, 0.0555]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[978.4651, 981.1761, 981.4086, 980.8348, 979.3923]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0207, 0.3118, 0.3934, 0.2216, 0.0524]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[978.8024, 981.4849, 981.6934, 981.0886, 979.6148]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0219, 0.3198, 0.3939, 0.2151, 0.0493]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.1502, 981.8026, 981.9858, 981.3501, 979.8445]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0231, 0.3280, 0.3940, 0.2086, 0.0463]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.5087, 982.1310, 982.2877, 981.6200, 980.0814]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0244, 0.3366, 0.3937, 0.2019, 0.0433]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.8788, 982.4689, 982.5992, 981.8977, 980.3254]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0259, 0.3453, 0.3933, 0.1950, 0.0405]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[980.2601, 982.8184, 982.9205, 982.1847, 980.5770]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0274, 0.3544, 0.3925, 0.1880, 0.0377]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[980.6544, 983.1788, 983.2520, 982.4808, 980.8370]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0291, 0.3637, 0.3913, 0.1810, 0.0350]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[981.0635, 983.5529, 983.5968, 982.7889, 981.1077]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0310, 0.3731, 0.3898, 0.1738, 0.0324]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[981.4920, 983.9459, 983.9597, 983.1133, 981.3936]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0329, 0.3828, 0.3881, 0.1665, 0.0298]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[981.8965, 984.3138, 984.2961, 983.4115, 981.6528]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0350, 0.3926, 0.3857, 0.1593, 0.0274]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.4083, 982.4203, 982.9328, 982.6959, 981.5833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0110, 0.2238, 0.3736, 0.2948, 0.0969]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.6616, 982.6554, 983.1534, 982.8989, 981.7665]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0114, 0.2282, 0.3755, 0.2911, 0.0938]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[979.9182, 982.8943, 983.3772, 983.1039, 981.9529]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0119, 0.2328, 0.3774, 0.2871, 0.0908]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[980.1788, 983.1364, 983.6042, 983.3127, 982.1422]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0123, 0.2375, 0.3791, 0.2833, 0.0879]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[980.4436, 983.3830, 983.8350, 983.5244, 982.3340]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0128, 0.2423, 0.3808, 0.2791, 0.0849]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[980.7125, 983.6331, 984.0692, 983.7393, 982.5286]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0133, 0.2473, 0.3825, 0.2750, 0.0819]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[980.9859, 983.8872, 984.3075, 983.9579, 982.7269]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0139, 0.2523, 0.3841, 0.2708, 0.0791]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[981.2640, 984.1457, 984.5494, 984.1799, 982.9277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0144, 0.2575, 0.3855, 0.2664, 0.0762]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[981.5472, 984.4089, 984.7958, 984.4056, 983.1317]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0150, 0.2628, 0.3870, 0.2619, 0.0733]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[981.8352, 984.6768, 985.0464, 984.6351, 983.3394]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0157, 0.2683, 0.3883, 0.2573, 0.0704]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[982.1285, 984.9490, 985.3013, 984.8685, 983.5506]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0163, 0.2739, 0.3895, 0.2527, 0.0676]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[982.4276, 985.2265, 985.5609, 985.1061, 983.7651]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0170, 0.2796, 0.3906, 0.2479, 0.0648]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[982.7322, 985.5097, 985.8253, 985.3480, 983.9836]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0178, 0.2856, 0.3916, 0.2430, 0.0621]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[983.0428, 985.7982, 986.0949, 985.5940, 984.2060]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0186, 0.2917, 0.3925, 0.2379, 0.0594]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[983.3603, 986.0924, 986.3698, 985.8450, 984.4324]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0194, 0.2980, 0.3933, 0.2327, 0.0567]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[983.6839, 986.3924, 986.6498, 986.1009, 984.6627]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0203, 0.3044, 0.3938, 0.2275, 0.0540]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[984.0145, 986.6991, 986.9359, 986.3616, 984.8973]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0212, 0.3111, 0.3943, 0.2220, 0.0513]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[984.3524, 987.0121, 987.2278, 986.6276, 985.1369]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0222, 0.3180, 0.3945, 0.2165, 0.0488]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[984.6956, 987.3298, 987.5239, 986.8973, 985.3789]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0233, 0.3250, 0.3946, 0.2109, 0.0462]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[984.9766, 987.5856, 987.7573, 987.1044, 985.5594]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0244, 0.3321, 0.3944, 0.2053, 0.0438]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.2642, 987.8472, 987.9964, 987.3163, 985.7437]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0256, 0.3394, 0.3940, 0.1996, 0.0414]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.5587, 988.1151, 988.2408, 987.5328, 985.9313]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0269, 0.3469, 0.3934, 0.1938, 0.0391]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.8608, 988.3890, 988.4909, 987.7545, 986.1237]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0283, 0.3545, 0.3925, 0.1879, 0.0368]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.1703, 988.6703, 988.7471, 987.9808, 986.3201]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0298, 0.3624, 0.3914, 0.1819, 0.0346]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.4904, 988.9610, 989.0124, 988.2159, 986.5236]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0313, 0.3705, 0.3900, 0.1759, 0.0324]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.8290, 989.2704, 989.2964, 988.4691, 986.7456]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0329, 0.3785, 0.3884, 0.1698, 0.0303]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.1768, 989.5883, 989.5876, 988.7285, 986.9728]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0347, 0.3868, 0.3865, 0.1637, 0.0283]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.7327, 988.7727, 989.3361, 989.1554, 988.0698]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0100, 0.2098, 0.3686, 0.3077, 0.1039]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[985.9775, 989.0060, 989.5601, 989.3688, 988.2705]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0103, 0.2125, 0.3699, 0.3055, 0.1019]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.2238, 989.2408, 989.7856, 989.5827, 988.4723]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0105, 0.2153, 0.3712, 0.3031, 0.0998]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.4717, 989.4779, 990.0137, 989.7998, 988.6771]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0108, 0.2180, 0.3725, 0.3008, 0.0979]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.7233, 989.7183, 990.2448, 990.0198, 988.8849]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0110, 0.2208, 0.3738, 0.2985, 0.0959]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[986.9759, 989.9594, 990.4766, 990.2408, 989.0937]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0113, 0.2235, 0.3749, 0.2962, 0.0941]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.2290, 990.2015, 990.7094, 990.4625, 989.3034]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0116, 0.2263, 0.3761, 0.2938, 0.0922]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.4833, 990.4448, 990.9435, 990.6857, 989.5139]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0119, 0.2291, 0.3772, 0.2915, 0.0903]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.7382, 990.6891, 991.1782, 990.9092, 989.7255]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0121, 0.2320, 0.3783, 0.2891, 0.0885]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[987.9949, 990.9343, 991.4139, 991.1339, 989.9380]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0124, 0.2348, 0.3794, 0.2867, 0.0867]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.2524, 991.1804, 991.6511, 991.3596, 990.1514]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0127, 0.2376, 0.3805, 0.2843, 0.0849]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.5112, 991.4281, 991.8891, 991.5864, 990.3658]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0130, 0.2406, 0.3815, 0.2818, 0.0832]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[988.7712, 991.6769, 992.1283, 991.8143, 990.5812]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0133, 0.2435, 0.3824, 0.2794, 0.0814]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.0331, 991.9271, 992.3691, 992.0432, 990.7978]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0136, 0.2464, 0.3834, 0.2768, 0.0797]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.2960, 992.1785, 992.6108, 992.2737, 991.0152]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0140, 0.2494, 0.3843, 0.2743, 0.0779]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.5329, 992.4044, 992.8265, 992.4780, 991.2075]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0143, 0.2525, 0.3851, 0.2718, 0.0763]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.7603, 992.6205, 993.0333, 992.6736, 991.3909]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0146, 0.2554, 0.3859, 0.2693, 0.0747]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[989.9899, 992.8381, 993.2414, 992.8706, 991.5754]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0150, 0.2584, 0.3867, 0.2669, 0.0731]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.2209, 993.0585, 993.4512, 993.0690, 991.7617]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0153, 0.2616, 0.3873, 0.2643, 0.0715]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.4547, 993.2802, 993.6632, 993.2689, 991.9490]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0157, 0.2646, 0.3881, 0.2617, 0.0699]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.6902, 993.5042, 993.8765, 993.4708, 992.1376]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0161, 0.2679, 0.3887, 0.2591, 0.0683]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[990.9285, 993.7305, 994.0925, 993.6746, 992.3288]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0165, 0.2711, 0.3893, 0.2564, 0.0667]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.1702, 993.9602, 994.3118, 993.8821, 992.5229]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0169, 0.2743, 0.3899, 0.2537, 0.0652]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.4144, 994.1921, 994.5334, 994.0908, 992.7185]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0173, 0.2776, 0.3906, 0.2509, 0.0636]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.6614, 994.4264, 994.7566, 994.3016, 992.9156]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0177, 0.2811, 0.3911, 0.2481, 0.0620]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[991.9102, 994.6628, 994.9816, 994.5139, 993.1140]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0181, 0.2846, 0.3915, 0.2452, 0.0605]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.1614, 994.9014, 995.2091, 994.7281, 993.3143]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0186, 0.2882, 0.3920, 0.2423, 0.0589]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.4155, 995.1424, 995.4387, 994.9442, 993.5161]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0191, 0.2918, 0.3924, 0.2393, 0.0574]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.6725, 995.3859, 995.6701, 995.1622, 993.7194]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0196, 0.2955, 0.3927, 0.2363, 0.0558]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[992.9318, 995.6314, 995.9039, 995.3818, 993.9243]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0201, 0.2993, 0.3931, 0.2332, 0.0543]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.1750, 995.8602, 996.1206, 995.5844, 994.1113]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0207, 0.3032, 0.3933, 0.2301, 0.0527]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.3989, 996.0701, 996.3175, 995.7670, 994.2783]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0212, 0.3072, 0.3935, 0.2269, 0.0512]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.6154, 996.2720, 996.5060, 995.9407, 994.4359]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0219, 0.3114, 0.3935, 0.2236, 0.0496]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.8351, 996.4765, 996.6968, 996.1158, 994.5956]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0225, 0.3157, 0.3935, 0.2201, 0.0481]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.0572, 996.6830, 996.8900, 996.2937, 994.7561]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0232, 0.3200, 0.3935, 0.2168, 0.0466]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.2822, 996.8919, 997.0848, 996.4723, 994.9182]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0239, 0.3244, 0.3934, 0.2132, 0.0451]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.5103, 997.1042, 997.2823, 996.6534, 995.0814]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0246, 0.3290, 0.3932, 0.2096, 0.0435]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.7414, 997.3185, 997.4820, 996.8359, 995.2462]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0254, 0.3337, 0.3930, 0.2059, 0.0420]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.9755, 997.5355, 997.6837, 997.0207, 995.4124]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0262, 0.3385, 0.3926, 0.2023, 0.0405]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.2131, 997.7555, 997.8883, 997.2068, 995.5800]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0270, 0.3434, 0.3922, 0.1984, 0.0390]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.4540, 997.9788, 998.0952, 997.3954, 995.7495]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0279, 0.3485, 0.3916, 0.1945, 0.0375]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.6988, 998.2047, 998.3044, 997.5861, 995.9196]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0289, 0.3537, 0.3909, 0.1906, 0.0360]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.9473, 998.4338, 998.5165, 997.7787, 996.0917]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0299, 0.3591, 0.3900, 0.1865, 0.0345]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.1989, 998.6659, 998.7316, 997.9733, 996.2654]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0309, 0.3645, 0.3892, 0.1823, 0.0330]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.4551, 998.9018, 998.9489, 998.1701, 996.4406]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0321, 0.3702, 0.3881, 0.1781, 0.0316]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.6624, 999.0884, 999.1171, 998.3173, 996.5654]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0332, 0.3759, 0.3869, 0.1738, 0.0302]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.8683, 999.2722, 999.2824, 998.4602, 996.6866]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0345, 0.3817, 0.3856, 0.1695, 0.0288]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[997.0765, 999.4584, 999.4487, 998.6044, 996.8079]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) -0.5 tensor([[0.0358, 0.3877, 0.3840, 0.1651, 0.0274]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.6337, 1000.6598, 1001.2326, 1001.0721,  999.9503]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2073, 0.3676, 0.3131, 0.1020]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.7495, 1000.7751, 1001.3470, 1001.1860, 1000.0635]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2075, 0.3676, 0.3129, 0.1019]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.8502, 1000.8749, 1001.4453, 1001.2842, 1000.1606]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2078, 0.3676, 0.3129, 0.1017]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.9507, 1000.9753, 1001.5445, 1001.3836, 1000.2591]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2080, 0.3675, 0.3128, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.0511, 1001.0756, 1001.6442, 1001.4841, 1000.3594]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2080, 0.3673, 0.3130, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.1512, 1001.1763, 1001.7445, 1001.5854, 1000.4611]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2080, 0.3671, 0.3131, 0.1017]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.2508, 1001.2769, 1001.8452, 1001.6875, 1000.5640]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2078, 0.3669, 0.3133, 0.1019]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.3500, 1001.3774, 1001.9459, 1001.7909, 1000.6683]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0101, 0.2076, 0.3664, 0.3138, 0.1021]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.4482, 1001.4780, 1002.0472, 1001.8945, 1000.7736]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0100, 0.2072, 0.3661, 0.3142, 0.1024]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.5455, 1001.5772, 1002.1480, 1001.9986, 1000.8796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0100, 0.2066, 0.3657, 0.3149, 0.1028]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.6418, 1001.6766, 1002.2490, 1002.1037, 1000.9872]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0099, 0.2060, 0.3651, 0.3157, 0.1034]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.7368, 1001.7750, 1002.3500, 1002.2082, 1001.0952]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0098, 0.2052, 0.3646, 0.3164, 0.1040]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.8308, 1001.8729, 1002.4503, 1002.3134, 1001.2041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0098, 0.2043, 0.3639, 0.3174, 0.1047]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.9230, 1001.9697, 1002.5500, 1002.4185, 1001.3134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0097, 0.2033, 0.3632, 0.3184, 0.1055]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.0132, 1002.0652, 1002.6493, 1002.5235, 1001.4234]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0096, 0.2021, 0.3624, 0.3196, 0.1064]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.1021, 1002.1595, 1002.7479, 1002.6288, 1001.5338]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0094, 0.2007, 0.3615, 0.3209, 0.1074]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.1888, 1002.2525, 1002.8456, 1002.7339, 1001.6449]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0093, 0.1992, 0.3605, 0.3224, 0.1085]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.2733, 1002.3441, 1002.9426, 1002.8381, 1001.7561]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0092, 0.1976, 0.3595, 0.3239, 0.1098]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.3555, 1002.4340, 1003.0377, 1002.9423, 1001.8673]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0090, 0.1959, 0.3583, 0.3257, 0.1111]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 999.4353, 1002.5220, 1003.1323, 1003.0459, 1001.9790]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0089, 0.1939, 0.3570, 0.3275, 0.1127]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.5126, 1002.6080, 1003.2253, 1003.1486, 1002.0908]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0087, 0.1918, 0.3557, 0.3294, 0.1144]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.5868, 1002.6917, 1003.3171, 1003.2509, 1002.2025]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0085, 0.1895, 0.3542, 0.3315, 0.1162]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.6580, 1002.7730, 1003.4073, 1003.3524, 1002.3141]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0083, 0.1870, 0.3527, 0.3338, 0.1182]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.7260, 1002.8525, 1003.4951, 1003.4524, 1002.4256]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0081, 0.1845, 0.3508, 0.3362, 0.1204]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.7908, 1002.9292, 1003.5815, 1003.5520, 1002.5367]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0079, 0.1817, 0.3489, 0.3388, 0.1227]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.8520, 1003.0033, 1003.6656, 1003.6501, 1002.6474]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0077, 0.1788, 0.3468, 0.3415, 0.1253]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.9090, 1003.0742, 1003.7476, 1003.7471, 1002.7579]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0074, 0.1757, 0.3445, 0.3443, 0.1281]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.9625, 1003.1417, 1003.8273, 1003.8423, 1002.8684]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0072, 0.1723, 0.3421, 0.3473, 0.1311]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.0652, 1002.5949, 1002.6943, 1002.0223, 1000.3625]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0279, 0.3502, 0.3868, 0.1975, 0.0376]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.2332, 1002.7570, 1002.8502, 1002.1718, 1000.5047]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0282, 0.3521, 0.3865, 0.1961, 0.0370]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.4020, 1002.9196, 1003.0059, 1002.3208, 1000.6465]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0286, 0.3542, 0.3861, 0.1946, 0.0365]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.5712, 1003.0820, 1003.1621, 1002.4697, 1000.7879]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0289, 0.3562, 0.3859, 0.1931, 0.0359]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.7410, 1003.2452, 1003.3185, 1002.6191, 1000.9290]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0293, 0.3583, 0.3855, 0.1916, 0.0353]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.9111, 1003.4081, 1003.4744, 1002.7679, 1001.0702]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0297, 0.3604, 0.3851, 0.1900, 0.0348]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.0820, 1003.5720, 1003.6309, 1002.9172, 1001.2109]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0301, 0.3627, 0.3846, 0.1884, 0.0342]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.2537, 1003.7360, 1003.7878, 1003.0662, 1001.3514]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0305, 0.3649, 0.3843, 0.1867, 0.0336]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.4260, 1003.9005, 1003.9449, 1003.2156, 1001.4917]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0309, 0.3671, 0.3838, 0.1851, 0.0330]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.5989, 1004.0660, 1004.1023, 1003.3641, 1001.6322]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0314, 0.3697, 0.3833, 0.1832, 0.0324]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.7728, 1004.2316, 1004.2599, 1003.5140, 1001.7722]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0318, 0.3721, 0.3828, 0.1815, 0.0318]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.9471, 1004.3980, 1004.4180, 1003.6630, 1001.9120]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0323, 0.3746, 0.3822, 0.1796, 0.0312]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.1196, 1004.5615, 1004.5734, 1003.8094, 1002.0489]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0328, 0.3771, 0.3817, 0.1778, 0.0306]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.2627, 1004.6957, 1004.6990, 1003.9258, 1002.1558]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0333, 0.3798, 0.3810, 0.1759, 0.0300]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.4062, 1004.8300, 1004.8248, 1004.0420, 1002.2618]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) -0.5 tensor([[0.0339, 0.3824, 0.3805, 0.1739, 0.0293]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.7281, 1005.7994, 1006.3768, 1006.2806, 1005.1806]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0093, 0.2006, 0.3574, 0.3246, 0.1081]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.7779, 1005.8622, 1006.4507, 1006.3686, 1005.2819]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0090, 0.1974, 0.3556, 0.3275, 0.1105]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.8245, 1005.9227, 1006.5223, 1006.4556, 1005.3829]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0088, 0.1941, 0.3534, 0.3306, 0.1131]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.8666, 1005.9800, 1006.5917, 1006.5416, 1005.4842]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0085, 0.1905, 0.3511, 0.3340, 0.1160]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.8976, 1006.0269, 1006.6519, 1006.6196, 1005.5781]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0082, 0.1866, 0.3486, 0.3375, 0.1191]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.9189, 1006.0658, 1006.7057, 1006.6914, 1005.6674]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0078, 0.1825, 0.3460, 0.3411, 0.1225]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.9095, 1006.0749, 1006.7305, 1006.7362, 1005.7314]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0075, 0.1781, 0.3431, 0.3450, 0.1263]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.9244, 1005.4536, 1005.5339, 1004.8655, 1003.1891]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0282, 0.3543, 0.3839, 0.1968, 0.0368]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.0675, 1005.5944, 1005.6719, 1005.0008, 1003.3218]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0284, 0.3551, 0.3838, 0.1962, 0.0366]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.2108, 1005.7347, 1005.8096, 1005.1360, 1003.4534]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0285, 0.3559, 0.3836, 0.1956, 0.0364]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.3533, 1005.8749, 1005.9467, 1005.2704, 1003.5845]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0287, 0.3568, 0.3834, 0.1950, 0.0361]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.4949, 1006.0146, 1006.0833, 1005.4044, 1003.7151]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0288, 0.3578, 0.3832, 0.1944, 0.0359]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.6369, 1006.1533, 1006.2194, 1005.5377, 1003.8453]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0290, 0.3586, 0.3831, 0.1937, 0.0357]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.7780, 1006.2920, 1006.3551, 1005.6713, 1003.9750]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0291, 0.3594, 0.3828, 0.1932, 0.0354]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.9189, 1006.4303, 1006.4904, 1005.8035, 1004.1042]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0292, 0.3604, 0.3827, 0.1925, 0.0352]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.0590, 1006.5682, 1006.6250, 1005.9357, 1004.2328]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0294, 0.3613, 0.3824, 0.1919, 0.0350]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.1989, 1006.7057, 1006.7594, 1006.0671, 1004.3612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0295, 0.3622, 0.3822, 0.1913, 0.0347]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.3383, 1006.8423, 1006.8928, 1006.1986, 1004.4889]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0297, 0.3631, 0.3819, 0.1908, 0.0345]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.4777, 1006.9788, 1007.0266, 1006.3292, 1004.6164]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0298, 0.3640, 0.3818, 0.1901, 0.0343]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.6130, 1007.1122, 1007.1569, 1006.4572, 1004.7407]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0300, 0.3649, 0.3816, 0.1895, 0.0341]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.7350, 1007.2310, 1007.2727, 1006.5707, 1004.8512]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0301, 0.3657, 0.3813, 0.1890, 0.0339]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.8566, 1007.3502, 1007.3889, 1006.6838, 1004.9612]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0303, 0.3667, 0.3811, 0.1883, 0.0336]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.9778, 1007.4688, 1007.5040, 1006.7966, 1005.0710]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0305, 0.3676, 0.3808, 0.1877, 0.0334]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.0986, 1007.5871, 1007.6195, 1006.9095, 1005.1809]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0306, 0.3685, 0.3806, 0.1871, 0.0332]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.2195, 1007.7055, 1007.7349, 1007.0224, 1005.2905]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0307, 0.3693, 0.3804, 0.1865, 0.0330]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.3400, 1007.8232, 1007.8499, 1007.1345, 1005.4003]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0309, 0.3702, 0.3802, 0.1859, 0.0328]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.4576, 1007.9384, 1007.9620, 1007.2448, 1005.5066]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0310, 0.3710, 0.3799, 0.1854, 0.0326]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.5748, 1008.0524, 1008.0735, 1007.3536, 1005.6119]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0312, 0.3718, 0.3797, 0.1848, 0.0324]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.6913, 1008.1672, 1008.1850, 1007.4623, 1005.7177]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0313, 0.3728, 0.3795, 0.1842, 0.0322]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.8080, 1008.2811, 1008.2962, 1007.5707, 1005.8228]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0315, 0.3736, 0.3793, 0.1836, 0.0320]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.9243, 1008.3948, 1008.4066, 1007.6792, 1005.9278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0317, 0.3745, 0.3790, 0.1831, 0.0318]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.0405, 1008.5081, 1008.5170, 1007.7872, 1006.0325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0318, 0.3754, 0.3787, 0.1825, 0.0316]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.1558, 1008.6212, 1008.6276, 1007.8953, 1006.1376]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0320, 0.3761, 0.3785, 0.1820, 0.0314]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.2712, 1008.7342, 1008.7380, 1008.0032, 1006.2422]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0321, 0.3769, 0.3784, 0.1814, 0.0312]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.3797, 1008.8403, 1008.8409, 1008.1037, 1006.3395]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0323, 0.3778, 0.3780, 0.1809, 0.0310]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.4643, 1008.9207, 1008.9179, 1008.1771, 1006.4086]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) -0.5 tensor([[0.0325, 0.3789, 0.3778, 0.1801, 0.0307]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.4208, 1009.5146, 1010.0842, 1010.0201, 1008.9189]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0090, 0.1991, 0.3520, 0.3301, 0.1098]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.3336, 1009.4468, 1010.0337, 1009.9913, 1008.9111]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0086, 0.1941, 0.3491, 0.3346, 0.1136]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.2377, 1009.3724, 1009.9766, 1009.9578, 1008.8993]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0082, 0.1890, 0.3457, 0.3393, 0.1177]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.1327, 1009.2900, 1009.9130, 1009.9192, 1008.8846]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0078, 0.1835, 0.3421, 0.3442, 0.1223]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.6081, 1009.1471, 1009.2126, 1008.5613, 1006.8740]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0281, 0.3563, 0.3805, 0.1984, 0.0367]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.6791, 1009.2205, 1009.2863, 1008.6374, 1006.9515]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0280, 0.3561, 0.3803, 0.1987, 0.0368]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.7490, 1009.2919, 1009.3589, 1008.7125, 1007.0286]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0280, 0.3556, 0.3802, 0.1992, 0.0370]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.8167, 1009.3617, 1009.4302, 1008.7865, 1007.1045]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0279, 0.3550, 0.3802, 0.1997, 0.0372]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.8823, 1009.4302, 1009.5004, 1008.8596, 1007.1796]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0277, 0.3544, 0.3802, 0.2003, 0.0373]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.9464, 1009.4973, 1009.5689, 1008.9317, 1007.2542]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0276, 0.3538, 0.3801, 0.2010, 0.0375]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.0082, 1009.5625, 1009.6360, 1009.0023, 1007.3277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0275, 0.3531, 0.3800, 0.2017, 0.0378]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.0684, 1009.6260, 1009.7020, 1009.0721, 1007.4009]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0273, 0.3522, 0.3800, 0.2024, 0.0381]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.1262, 1009.6874, 1009.7662, 1009.1409, 1007.4727]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0271, 0.3512, 0.3800, 0.2033, 0.0383]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.1820, 1009.7471, 1009.8285, 1009.2084, 1007.5445]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0269, 0.3502, 0.3799, 0.2043, 0.0387]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.2354, 1009.8049, 1009.8901, 1009.2746, 1007.6148]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0267, 0.3489, 0.3800, 0.2053, 0.0390]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.2862, 1009.8611, 1009.9498, 1009.3397, 1007.6845]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0265, 0.3477, 0.3799, 0.2064, 0.0394]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.3351, 1009.9147, 1010.0074, 1009.4033, 1007.7532]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0262, 0.3463, 0.3799, 0.2076, 0.0399]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.3809, 1009.9670, 1010.0635, 1009.4659, 1007.8213]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0260, 0.3449, 0.3798, 0.2090, 0.0403]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.4249, 1010.0165, 1010.1180, 1009.5273, 1007.8884]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0257, 0.3432, 0.3798, 0.2104, 0.0409]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.4659, 1010.0638, 1010.1705, 1009.5869, 1007.9545]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0254, 0.3414, 0.3798, 0.2119, 0.0414]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.5041, 1010.1088, 1010.2213, 1009.6456, 1008.0201]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0251, 0.3394, 0.3798, 0.2136, 0.0420]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.5395, 1010.1519, 1010.2703, 1009.7025, 1008.0839]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0248, 0.3375, 0.3798, 0.2153, 0.0427]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.5715, 1010.1926, 1010.3170, 1009.7581, 1008.1476]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0244, 0.3353, 0.3798, 0.2172, 0.0434]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6010, 1010.2301, 1010.3617, 1009.8118, 1008.2100]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0240, 0.3329, 0.3798, 0.2191, 0.0442]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6271, 1010.2653, 1010.4038, 1009.8643, 1008.2714]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0236, 0.3305, 0.3796, 0.2213, 0.0450]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6500, 1010.2979, 1010.4442, 1009.9155, 1008.3315]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0232, 0.3278, 0.3794, 0.2236, 0.0459]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6693, 1010.3272, 1010.4823, 1009.9642, 1008.3912]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0228, 0.3249, 0.3794, 0.2260, 0.0469]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6855, 1010.3541, 1010.5178, 1010.0116, 1008.4492]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0223, 0.3220, 0.3792, 0.2286, 0.0479]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6962, 1010.3765, 1010.5493, 1010.0554, 1008.5052]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0219, 0.3188, 0.3790, 0.2313, 0.0491]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.7028, 1010.3953, 1010.5783, 1010.0977, 1008.5595]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0214, 0.3154, 0.3787, 0.2342, 0.0503]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.7054, 1010.4106, 1010.6046, 1010.1377, 1008.6124]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0208, 0.3118, 0.3785, 0.2373, 0.0516]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.7036, 1010.4229, 1010.6279, 1010.1760, 1008.6645]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0203, 0.3080, 0.3781, 0.2406, 0.0531]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6982, 1010.4312, 1010.6483, 1010.2120, 1008.7145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0198, 0.3039, 0.3776, 0.2441, 0.0546]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6880, 1010.4363, 1010.6661, 1010.2460, 1008.7640]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0192, 0.2997, 0.3771, 0.2477, 0.0563]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6732, 1010.4374, 1010.6807, 1010.2778, 1008.8123]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0186, 0.2952, 0.3765, 0.2516, 0.0581]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6536, 1010.4347, 1010.6917, 1010.3072, 1008.8586]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0180, 0.2905, 0.3756, 0.2557, 0.0601]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.6292, 1010.4278, 1010.7000, 1010.3340, 1008.9036]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0174, 0.2856, 0.3749, 0.2600, 0.0622]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.5994, 1010.4165, 1010.7046, 1010.3582, 1008.9472]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0168, 0.2803, 0.3739, 0.2645, 0.0645]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.5641, 1010.4012, 1010.7053, 1010.3806, 1008.9893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0161, 0.2749, 0.3727, 0.2693, 0.0670]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.5237, 1010.3809, 1010.7031, 1010.3998, 1009.0295]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0155, 0.2691, 0.3714, 0.2743, 0.0697]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.4776, 1010.3564, 1010.6964, 1010.4166, 1009.0681]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0148, 0.2632, 0.3698, 0.2796, 0.0726]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.4250, 1010.3266, 1010.6862, 1010.4302, 1009.1050]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0141, 0.2570, 0.3682, 0.2850, 0.0757]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.3077, 1010.2339, 1010.6142, 1010.3846, 1009.0849]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0134, 0.2503, 0.3661, 0.2910, 0.0793]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.1791, 1010.1313, 1010.5333, 1010.3314, 1009.0587]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0127, 0.2433, 0.3636, 0.2972, 0.0832]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1007.0414, 1010.0206, 1010.4453, 1010.2725, 1009.0278]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0120, 0.2360, 0.3609, 0.3036, 0.0875]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.8937, 1009.9015, 1010.3502, 1010.2073, 1008.9923]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0113, 0.2285, 0.3579, 0.3102, 0.0921]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.7358, 1009.7733, 1010.2468, 1010.1361, 1008.9520]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0106, 0.2207, 0.3544, 0.3172, 0.0971]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.5673, 1009.6357, 1010.1358, 1010.0584, 1008.9062]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0099, 0.2126, 0.3506, 0.3244, 0.1025]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.3879, 1009.4887, 1010.0163, 1009.9741, 1008.8560]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0092, 0.2043, 0.3462, 0.3319, 0.1085]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.1968, 1009.3320, 1009.8886, 1009.8823, 1008.8004]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0085, 0.1957, 0.3415, 0.3393, 0.1150]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.9943, 1009.1650, 1009.7518, 1009.7835, 1008.7389]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0078, 0.1869, 0.3361, 0.3470, 0.1221]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.6974, 1009.2755, 1009.3256, 1008.7184, 1007.0441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0270, 0.3562, 0.3745, 0.2041, 0.0382]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.6917, 1009.2844, 1009.3469, 1008.7547, 1007.0955]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0263, 0.3521, 0.3748, 0.2073, 0.0394]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.6807, 1009.2890, 1009.3641, 1008.7886, 1007.1441]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0256, 0.3478, 0.3750, 0.2109, 0.0407]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.6655, 1009.2896, 1009.3781, 1008.8187, 1007.1904]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0249, 0.3434, 0.3752, 0.2144, 0.0421]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.6454, 1009.2859, 1009.3881, 1008.8460, 1007.2341]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0242, 0.3388, 0.3753, 0.2182, 0.0435]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.6202, 1009.2775, 1009.3944, 1008.8703, 1007.2756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0234, 0.3339, 0.3753, 0.2222, 0.0451]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.5900, 1009.2651, 1009.3967, 1008.8911, 1007.3145]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0227, 0.3290, 0.3752, 0.2263, 0.0468]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1006.5549, 1009.2479, 1009.3954, 1008.9087, 1007.3510]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0219, 0.3237, 0.3752, 0.2306, 0.0486]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.5137, 1009.2260, 1009.3897, 1008.9233, 1007.3843]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0211, 0.3183, 0.3749, 0.2352, 0.0505]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.4672, 1009.1990, 1009.3796, 1008.9341, 1007.4156]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0204, 0.3127, 0.3745, 0.2399, 0.0525]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.4147, 1009.1673, 1009.3655, 1008.9413, 1007.4437]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0196, 0.3068, 0.3741, 0.2448, 0.0547]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.2955, 1009.0700, 1009.2867, 1008.8868, 1007.4122]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0187, 0.3005, 0.3732, 0.2502, 0.0573]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.1651, 1008.9630, 1009.1992, 1008.8233, 1007.3727]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0179, 0.2940, 0.3724, 0.2557, 0.0599]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1006.0266, 1008.8486, 1009.1051, 1008.7549, 1007.3289]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0171, 0.2873, 0.3713, 0.2616, 0.0628]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.8798, 1008.7269, 1009.0043, 1008.6802, 1007.2811]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0163, 0.2803, 0.3699, 0.2675, 0.0660]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.7244, 1008.5973, 1008.8966, 1008.6004, 1007.2277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0154, 0.2730, 0.3683, 0.2739, 0.0694]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.5594, 1008.4591, 1008.7816, 1008.5140, 1007.1698]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0146, 0.2654, 0.3664, 0.2804, 0.0731]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.3852, 1008.3129, 1008.6591, 1008.4216, 1007.1069]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0138, 0.2576, 0.3642, 0.2872, 0.0771]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.2007, 1008.1577, 1008.5288, 1008.3226, 1007.0382]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0130, 0.2496, 0.3617, 0.2943, 0.0815]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.0061, 1007.9936, 1008.3907, 1008.2169, 1006.9641]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0122, 0.2412, 0.3588, 0.3016, 0.0862]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.8010, 1007.8203, 1008.2443, 1008.1039, 1006.8847]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0114, 0.2327, 0.3556, 0.3090, 0.0913]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.5843, 1007.6370, 1008.0889, 1007.9838, 1006.7994]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0106, 0.2239, 0.3518, 0.3168, 0.0969]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.3565, 1007.4431, 1007.9247, 1007.8559, 1006.7077]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0098, 0.2148, 0.3477, 0.3246, 0.1030]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.1170, 1007.2390, 1007.7512, 1007.7206, 1006.6098]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0091, 0.2056, 0.3431, 0.3328, 0.1096]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.8679, 1007.0281, 1007.5721, 1007.5814, 1006.5105]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0083, 0.1961, 0.3378, 0.3410, 0.1168]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.3950, 1007.9973, 1008.0373, 1007.4378, 1005.7623]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0265, 0.3580, 0.3726, 0.2046, 0.0383]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.3587, 1007.9787, 1008.0330, 1007.4515, 1005.7932]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0257, 0.3532, 0.3729, 0.2085, 0.0397]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.3176, 1007.9549, 1008.0247, 1007.4612, 1005.8211]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0249, 0.3481, 0.3733, 0.2125, 0.0412]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.2092, 1007.8654, 1007.9511, 1007.4077, 1005.7871]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0241, 0.3428, 0.3734, 0.2169, 0.0429]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1005.0950, 1007.7706, 1007.8732, 1007.3499, 1005.7496]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0232, 0.3371, 0.3736, 0.2214, 0.0447]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.9753, 1007.6708, 1007.7903, 1007.2884, 1005.7090]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0224, 0.3314, 0.3735, 0.2261, 0.0466]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.8493, 1007.5660, 1007.7025, 1007.2227, 1005.6643]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0215, 0.3256, 0.3732, 0.2310, 0.0486]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.7170, 1007.4551, 1007.6101, 1007.1525, 1005.6164]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0207, 0.3195, 0.3730, 0.2360, 0.0508]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.5784, 1007.3385, 1007.5121, 1007.0779, 1005.5648]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0198, 0.3132, 0.3726, 0.2413, 0.0531]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.4334, 1007.2160, 1007.4089, 1006.9984, 1005.5093]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0190, 0.3067, 0.3719, 0.2467, 0.0557]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.2806, 1007.0870, 1007.2998, 1006.9142, 1005.4494]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0181, 0.3000, 0.3711, 0.2524, 0.0583]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1004.1208, 1006.9517, 1007.1848, 1006.8249, 1005.3857]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0173, 0.2931, 0.3701, 0.2582, 0.0612]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.9532, 1006.8089, 1007.0642, 1006.7307, 1005.3176]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0164, 0.2859, 0.3690, 0.2643, 0.0643]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.7777, 1006.6593, 1006.9371, 1006.6307, 1005.2449]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0156, 0.2785, 0.3676, 0.2706, 0.0677]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.5938, 1006.5027, 1006.8030, 1006.5251, 1005.1678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0148, 0.2709, 0.3659, 0.2771, 0.0713]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.4012, 1006.3383, 1006.6624, 1006.4139, 1005.0857]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0140, 0.2631, 0.3639, 0.2838, 0.0752]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1003.2001, 1006.1658, 1006.5147, 1006.2968, 1004.9990]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0131, 0.2551, 0.3616, 0.2908, 0.0794]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.9890, 1005.9850, 1006.3594, 1006.1736, 1004.9072]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0123, 0.2468, 0.3589, 0.2980, 0.0840]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.7690, 1005.7956, 1006.1969, 1006.0438, 1004.8101]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0116, 0.2383, 0.3559, 0.3054, 0.0889]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.5383, 1005.5977, 1006.0263, 1005.9074, 1004.7072]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0108, 0.2296, 0.3525, 0.3129, 0.0942]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.2973, 1005.3903, 1005.8478, 1005.7638, 1004.5992]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0100, 0.2207, 0.3487, 0.3206, 0.1000]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.0457, 1005.1732, 1005.6604, 1005.6134, 1004.4853]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0093, 0.2115, 0.3443, 0.3285, 0.1063]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.7824, 1004.9460, 1005.4640, 1005.4555, 1004.3652]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0085, 0.2022, 0.3395, 0.3366, 0.1131]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.5078, 1004.7087, 1005.2592, 1005.2897, 1004.2388]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0079, 0.1928, 0.3343, 0.3446, 0.1205]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.8129, 1005.4734, 1005.5370, 1004.9738, 1003.3384]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0244, 0.3496, 0.3725, 0.2121, 0.0413]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.6930, 1005.3716, 1005.4507, 1004.9062, 1003.2893]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0236, 0.3444, 0.3728, 0.2163, 0.0429]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.5818, 1005.2780, 1005.3719, 1004.8456, 1003.2468]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0229, 0.3394, 0.3729, 0.2203, 0.0445]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.4661, 1005.1800, 1005.2892, 1004.7814, 1003.2012]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0222, 0.3343, 0.3729, 0.2244, 0.0462]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.3451, 1005.0778, 1005.2028, 1004.7141, 1003.1528]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0214, 0.3290, 0.3729, 0.2287, 0.0480]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.2195, 1004.9709, 1005.1117, 1004.6429, 1003.1013]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0207, 0.3237, 0.3726, 0.2332, 0.0499]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1002.0883, 1004.8592, 1005.0165, 1004.5684, 1003.0464]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0199, 0.3181, 0.3723, 0.2378, 0.0519]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.9521, 1004.7428, 1004.9174, 1004.4893, 1002.9880]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0192, 0.3124, 0.3720, 0.2424, 0.0540]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.8103, 1004.6214, 1004.8132, 1004.4066, 1002.9264]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0184, 0.3066, 0.3714, 0.2473, 0.0563]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.6623, 1004.4948, 1004.7040, 1004.3195, 1002.8613]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0177, 0.3007, 0.3706, 0.2523, 0.0587]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.5087, 1004.3624, 1004.5907, 1004.2287, 1002.7929]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0170, 0.2944, 0.3699, 0.2575, 0.0613]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.3482, 1004.2243, 1004.4717, 1004.1331, 1002.7206]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0162, 0.2880, 0.3688, 0.2629, 0.0640]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.1818, 1004.0803, 1004.3475, 1004.0329, 1002.6446]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0155, 0.2814, 0.3677, 0.2684, 0.0670]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1001.0082, 1003.9309, 1004.2180, 1003.9283, 1002.5646]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0148, 0.2748, 0.3662, 0.2741, 0.0701]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.8277, 1003.7748, 1004.0828, 1003.8188, 1002.4805]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0141, 0.2679, 0.3646, 0.2800, 0.0734]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.6397, 1003.6120, 1003.9420, 1003.7042, 1002.3923]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0134, 0.2608, 0.3628, 0.2860, 0.0770]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.4443, 1003.4426, 1003.7948, 1003.5846, 1002.2998]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0126, 0.2536, 0.3606, 0.2923, 0.0809]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.2411, 1003.2661, 1003.6417, 1003.4597, 1002.2034]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0120, 0.2461, 0.3583, 0.2987, 0.0850]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1000.0295, 1003.0824, 1003.4819, 1003.3292, 1002.1019]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0113, 0.2385, 0.3556, 0.3052, 0.0895]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.8098, 1002.8912, 1003.3154, 1003.1931, 1001.9955]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0106, 0.2307, 0.3526, 0.3120, 0.0942]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.5808, 1002.6921, 1003.1422, 1003.0508, 1001.8848]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0099, 0.2227, 0.3493, 0.3188, 0.0993]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.3430, 1002.4850, 1002.9614, 1002.9027, 1001.7692]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0093, 0.2146, 0.3455, 0.3258, 0.1049]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.0957, 1002.2698, 1002.7733, 1002.7485, 1001.6480]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0086, 0.2063, 0.3413, 0.3330, 0.1108]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.8372, 1002.0435, 1002.5766, 1002.5861, 1001.5206]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.5 tensor([[0.0080, 0.1977, 0.3369, 0.3401, 0.1172]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.9013, 1002.5792, 1002.6353, 1002.0599, 1000.4272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0242, 0.3524, 0.3727, 0.2097, 0.0410]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.7908, 1002.4827, 1002.5504, 1001.9894, 1000.3712]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0236, 0.3485, 0.3729, 0.2128, 0.0422]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.6785, 1002.3842, 1002.4642, 1001.9172, 1000.3134]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0230, 0.3445, 0.3732, 0.2159, 0.0434]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.5638, 1002.2846, 1002.3762, 1001.8437, 1000.2549]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0224, 0.3405, 0.3732, 0.2191, 0.0447]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.4477, 1002.1823, 1002.2867, 1001.7687, 1000.1946]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0218, 0.3363, 0.3733, 0.2224, 0.0461]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.3292, 1002.0784, 1002.1952, 1001.6913, 1000.1325]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0213, 0.3323, 0.3734, 0.2256, 0.0475]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.2084, 1001.9721, 1002.1013, 1001.6129, 1000.0687]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0207, 0.3281, 0.3733, 0.2291, 0.0489]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 999.0851, 1001.8636, 1002.0059, 1001.5320, 1000.0035]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0201, 0.3238, 0.3733, 0.2324, 0.0504]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.9684, 1001.7607, 1001.9159, 1001.4565,  999.9428]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0196, 0.3196, 0.3732, 0.2358, 0.0519]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.8528, 1001.6599, 1001.8268, 1001.3821,  999.8832]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0191, 0.3156, 0.3729, 0.2390, 0.0534]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.7342, 1001.5558, 1001.7352, 1001.3055,  999.8215]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0185, 0.3114, 0.3726, 0.2425, 0.0550]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.6122, 1001.4489, 1001.6407, 1001.2263,  999.7580]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0180, 0.3072, 0.3722, 0.2459, 0.0566]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.4865, 1001.3380, 1001.5438, 1001.1443,  999.6920]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0175, 0.3028, 0.3719, 0.2494, 0.0584]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.3577, 1001.2245, 1001.4430, 1001.0601,  999.6237]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0170, 0.2984, 0.3713, 0.2532, 0.0602]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.2245, 1001.1072, 1001.3396, 1000.9727,  999.5530]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0165, 0.2939, 0.3707, 0.2569, 0.0621]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 998.0880, 1000.9867, 1001.2334, 1000.8828,  999.4794]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0159, 0.2892, 0.3701, 0.2607, 0.0641]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.9472, 1000.8624, 1001.1230, 1000.7900,  999.4041]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0154, 0.2845, 0.3692, 0.2647, 0.0662]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.8022, 1000.7343, 1001.0101, 1000.6942,  999.3262]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0149, 0.2796, 0.3684, 0.2686, 0.0684]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.6530, 1000.6025, 1000.8929, 1000.5952,  999.2454]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0144, 0.2748, 0.3674, 0.2728, 0.0707]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.4995, 1000.4666, 1000.7725, 1000.4933,  999.1619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0139, 0.2697, 0.3662, 0.2770, 0.0732]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.3408, 1000.3264, 1000.6479, 1000.3879,  999.0756]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0134, 0.2646, 0.3649, 0.2814, 0.0757]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.1778, 1000.1819, 1000.5201, 1000.2795,  998.9868]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0129, 0.2592, 0.3636, 0.2858, 0.0785]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 997.0096, 1000.0328, 1000.3879, 1000.1674,  998.8948]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0123, 0.2538, 0.3621, 0.2904, 0.0813]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 996.8361,  999.8792, 1000.2512, 1000.0515,  998.7999]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0118, 0.2484, 0.3603, 0.2951, 0.0844]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 996.6575,  999.7205, 1000.1108,  999.9321,  998.7021]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) 0.0 tensor([[0.0113, 0.2426, 0.3585, 0.2998, 0.0876]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.4726, 999.5574, 999.9657, 999.8090, 998.6010]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0108, 0.2369, 0.3564, 0.3047, 0.0911]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.2826, 999.3886, 999.8161, 999.6818, 998.4966]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0103, 0.2310, 0.3542, 0.3097, 0.0947]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.0863, 999.2147, 999.6615, 999.5505, 998.3887]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0099, 0.2250, 0.3518, 0.3148, 0.0985]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.8837, 999.0351, 999.5017, 999.4151, 998.2777]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0094, 0.2189, 0.3490, 0.3201, 0.1026]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.6753, 998.8500, 999.3374, 999.2755, 998.1625]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0089, 0.2126, 0.3462, 0.3254, 0.1069]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.4590, 998.6585, 999.1677, 999.1310, 998.0446]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0084, 0.2062, 0.3431, 0.3307, 0.1116]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.2364, 998.4612, 998.9921, 998.9820, 997.9221]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0079, 0.1997, 0.3396, 0.3362, 0.1165]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.0068, 998.2571, 998.8111, 998.8281, 997.7957]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.5 tensor([[0.0075, 0.1931, 0.3360, 0.3417, 0.1217]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.2104, 998.9169, 998.9811, 998.3988, 996.7830]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0235, 0.3512, 0.3745, 0.2092, 0.0416]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.1407, 998.8533, 998.9233, 998.3463, 996.7366]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0232, 0.3495, 0.3748, 0.2105, 0.0421]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.0724, 998.7908, 998.8655, 998.2943, 996.6906]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0230, 0.3479, 0.3749, 0.2117, 0.0426]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[996.0055, 998.7292, 998.8090, 998.2426, 996.6445]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0227, 0.3463, 0.3750, 0.2129, 0.0431]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.9338, 998.6624, 998.7465, 998.1846, 996.5915]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0225, 0.3449, 0.3752, 0.2139, 0.0435]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.8474, 998.5801, 998.6674, 998.1095, 996.5208]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0224, 0.3438, 0.3752, 0.2148, 0.0439]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.7622, 998.4984, 998.5896, 998.0345, 996.4502]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0222, 0.3427, 0.3754, 0.2155, 0.0442]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.6783, 998.4180, 998.5123, 997.9604, 996.3797]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0221, 0.3417, 0.3755, 0.2162, 0.0445]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.5956, 998.3384, 998.4360, 997.8870, 996.3098]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0219, 0.3407, 0.3756, 0.2169, 0.0448]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.5143, 998.2602, 998.3604, 997.8138, 996.2402]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0218, 0.3399, 0.3757, 0.2175, 0.0451]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.4343, 998.1827, 998.2852, 997.7415, 996.1707]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0217, 0.3391, 0.3757, 0.2181, 0.0453]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.3561, 998.1066, 998.2112, 997.6696, 996.1015]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0216, 0.3384, 0.3758, 0.2186, 0.0456]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.2786, 998.0313, 998.1383, 997.5980, 996.0327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0215, 0.3378, 0.3759, 0.2190, 0.0458]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.2026, 997.9574, 998.0659, 997.5275, 995.9641]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0215, 0.3373, 0.3759, 0.2194, 0.0460]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.1283, 997.8849, 997.9951, 997.4579, 995.8963]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0214, 0.3368, 0.3760, 0.2197, 0.0461]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[995.0552, 997.8129, 997.9247, 997.3886, 995.8289]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0213, 0.3363, 0.3761, 0.2200, 0.0462]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.9839, 997.7426, 997.8558, 997.3200, 995.7620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0213, 0.3360, 0.3762, 0.2202, 0.0464]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.9142, 997.6736, 997.7880, 997.2526, 995.6957]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0213, 0.3357, 0.3763, 0.2203, 0.0464]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.8462, 997.6061, 997.7209, 997.1861, 995.6299]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0212, 0.3355, 0.3763, 0.2204, 0.0465]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[994.7798, 997.5398, 997.6552, 997.1202, 995.5646]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0212, 0.3354, 0.3764, 0.2205, 0.0465]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.7150, 997.4755, 997.5908, 997.0555, 995.5001]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0212, 0.3354, 0.3764, 0.2204, 0.0465]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.6523, 997.4122, 997.5276, 996.9915, 995.4360]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0212, 0.3355, 0.3765, 0.2203, 0.0465]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.5912, 997.3508, 997.4659, 996.9290, 995.3733]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0212, 0.3356, 0.3766, 0.2201, 0.0465]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.5324, 997.2908, 997.4058, 996.8672, 995.3112]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0213, 0.3358, 0.3767, 0.2198, 0.0464]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.4758, 997.2326, 997.3469, 996.8066, 995.2496]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0213, 0.3361, 0.3768, 0.2195, 0.0463]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.4209, 997.1765, 997.2896, 996.7475, 995.1891]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0214, 0.3365, 0.3768, 0.2191, 0.0461]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.3682, 997.1218, 997.2335, 996.6896, 995.1294]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0215, 0.3370, 0.3768, 0.2187, 0.0460]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.3177, 997.0694, 997.1794, 996.6329, 995.0709]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0215, 0.3376, 0.3769, 0.2182, 0.0458]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.2697, 997.0188, 997.1277, 996.5778, 995.0135]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0216, 0.3382, 0.3771, 0.2176, 0.0455]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.2243, 996.9704, 997.0769, 996.5238, 994.9570]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0218, 0.3390, 0.3771, 0.2169, 0.0453]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.1813, 996.9244, 997.0278, 996.4716, 994.9016]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0219, 0.3400, 0.3770, 0.2162, 0.0450]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.1408, 996.8802, 996.9814, 996.4211, 994.8475]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0220, 0.3408, 0.3772, 0.2154, 0.0446]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.1033, 996.8384, 996.9371, 996.3720, 994.7949]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0222, 0.3418, 0.3773, 0.2144, 0.0443]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.0684, 996.7996, 996.8942, 996.3247, 994.7432]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0224, 0.3431, 0.3772, 0.2134, 0.0439]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.0367, 996.7631, 996.8541, 996.2797, 994.6936]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0225, 0.3444, 0.3772, 0.2124, 0.0435]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[994.0074, 996.7292, 996.8163, 996.2358, 994.6450]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0227, 0.3458, 0.3773, 0.2111, 0.0430]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.9819, 996.6981, 996.7808, 996.1940, 994.5981]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0230, 0.3474, 0.3773, 0.2098, 0.0425]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.9594, 996.6697, 996.7479, 996.1550, 994.5527]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0232, 0.3489, 0.3773, 0.2085, 0.0420]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([[993.9412, 996.6446, 996.7175, 996.1176, 994.5090]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>) 0.0 tensor([[0.0235, 0.3507, 0.3773, 0.2071, 0.0415]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "836.5682383889795\n"
     ]
    }
   ],
   "source": [
    "_, r, _, s = env.reset()\n",
    "\n",
    "\n",
    "rc = 0.0\n",
    "for _ in range(1000):\n",
    "    s = duju_utils.state_1d_flat(s)\n",
    "    input_ = torch.FloatTensor(s.reshape([1,5])).to(device)\n",
    "\n",
    "    a1 = q_main.fc1(input_)\n",
    "    a1\n",
    "\n",
    "    aa1 = F.relu(a1)\n",
    "    aa1\n",
    "\n",
    "    a2 = q_main.fc2(aa1)\n",
    "    aa2 = F.relu(a2)\n",
    "\n",
    "    a3 = q_main.fc3(aa2)\n",
    "    aa3 = a3\n",
    "    t = F.softmax(aa3,dim=1)\n",
    "\n",
    "    action = int(torch.argmax(aa3))\n",
    "    action = action_dict[action]\n",
    "    _, r, _, s = env.step(action)\n",
    "    rc +=r\n",
    "    \n",
    "    \n",
    "    print(aa3, action, t)\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ = torch.FloatTensor(k.reshape([1,12,48,64])).to(device)\n",
    "\n",
    "a1 = q_main.q1_conv1(input_)\n",
    "a1\n",
    "\n",
    "aa1 = F.relu(a1)\n",
    "aa1\n",
    "\n",
    "a2 = q_main.q1_conv2(aa1)\n",
    "aa2 = F.relu(a2)\n",
    "\n",
    "a3 = q_main.q1_conv3(aa2)\n",
    "aa3 = F.relu(a3)\n",
    "\n",
    "fc1 = aa3.view(1,-1)\n",
    "\n",
    "f1 = q_main.q1_fc1(fc1)\n",
    "ff1 = F.relu(f1)\n",
    "\n",
    "f2 = q_main.q1_fc2(ff1)\n",
    "ff2 = f2\n",
    "\n",
    "action = int(torch.argmax(ff2))\n",
    "action = action_dict[action]\n",
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1ba9e467f0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = np.array([\n",
    "    [[0,0,0]],  \n",
    "])\n",
    "test_image.shape\n",
    "\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk = kkk / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkkk = kkk[:,:,0] * 0.2989 + kkk[:,:,1] * 0.5870 + kkk[:,:,2] * 0.1140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = env.physics.render(camera_id=0, height = 48, width = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 64, 3)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame / 256.0\n",
    "frame = frame[:,:,[0]] * 0.2989 + frame[:,:,[1]] * 0.5870 + frame[:,:,[2]] * 0.1140\n",
    "frame = np.moveaxis(frame, [0, 1, 2], [1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkkk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1ba951dbe0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(frame[0], cmap=plt.get_cmap('gray'), vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
